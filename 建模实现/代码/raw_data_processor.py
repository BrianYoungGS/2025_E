#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸå§‹æ•°æ®å¤„ç†å™¨ - ç”Ÿæˆå®Œæ•´çš„åŸå§‹æ•°æ®å’Œå»å™ªæ•°æ®
ç›®æ ‡ï¼š161ä¸ªåŸå§‹æ–‡ä»¶ â†’ 322ä¸ªå®Œæ•´æ•°æ®æ–‡ä»¶ï¼ˆ161ä¸ªåŸå§‹ + 161ä¸ªå»å™ªï¼‰
"""

import os
import numpy as np
import scipy.io as sio
import scipy.signal as signal
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import json
from datetime import datetime

class RawDataProcessor:
    """åŸå§‹æ•°æ®å¤„ç†å™¨ - ä¿ç•™å®Œæ•´æ•°æ®ä¸åšåˆ†æ®µ"""
    
    def __init__(self, source_base_path, output_base_path):
        self.source_base = Path(source_base_path)
        self.output_base = Path(output_base_path)
        self.processed_count = 0
        
        # è½´æ‰¿å‚æ•°
        self.bearing_params = {
            'SKF6205': {'n': 9, 'd': 0.3126, 'D': 1.537},  # DEè½´æ‰¿
            'SKF6203': {'n': 9, 'd': 0.2656, 'D': 1.122}   # FEè½´æ‰¿
        }
    
    def load_mat_file(self, file_path):
        """åŠ è½½.matæ–‡ä»¶"""
        try:
            return sio.loadmat(str(file_path))
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None
    
    def downsample_signal(self, data, original_fs, target_fs):
        """é™é‡‡æ ·ä¿¡å·"""
        if original_fs == target_fs:
            return data
        
        # è®¡ç®—é™é‡‡æ ·æ¯”ä¾‹
        downsample_factor = int(original_fs / target_fs)
        
        # ä½¿ç”¨scipyçš„decimateå‡½æ•°è¿›è¡Œé™é‡‡æ ·
        downsampled = signal.decimate(data.flatten(), downsample_factor, ftype='iir')
        
        return downsampled.reshape(-1, 1)
    
    def apply_denoising(self, data, fs):
        """åº”ç”¨å»å™ªæ»¤æ³¢å™¨"""
        data_flat = data.flatten()
        
        # 1. é«˜é€šæ»¤æ³¢ (10Hz)
        sos_hp = signal.butter(4, 10, btype='highpass', fs=fs, output='sos')
        data_filtered = signal.sosfilt(sos_hp, data_flat)
        
        # 2. ä½é€šæ»¤æ³¢ (5000Hz)
        sos_lp = signal.butter(4, 5000, btype='lowpass', fs=fs, output='sos')
        data_filtered = signal.sosfilt(sos_lp, data_filtered)
        
        # 3. é™·æ³¢æ»¤æ³¢ (50Hzå·¥é¢‘åŠå…¶è°æ³¢)
        for freq in [50, 100, 150]:
            if freq < fs/2:
                b_notch, a_notch = signal.iirnotch(freq, 30, fs)
                data_filtered = signal.filtfilt(b_notch, a_notch, data_filtered)
        
        # 4. ä¸­å€¼æ»¤æ³¢å»é™¤è„‰å†²å™ªå£°
        data_filtered = signal.medfilt(data_filtered, kernel_size=3)
        
        return data_filtered.reshape(-1, 1)
    
    def extract_time_features(self, data):
        """æå–æ—¶åŸŸç‰¹å¾"""
        data_flat = data.flatten()
        
        features = {
            'P1_Mean': float(np.mean(data_flat)),
            'P2_RMS': float(np.sqrt(np.mean(data_flat**2))),
            'P3_Variance': float(np.var(data_flat)),
            'P4_Std': float(np.std(data_flat)),
            'P5_Skewness': float(self._skewness(data_flat)),
            'P6_Kurtosis': float(self._kurtosis(data_flat)),
            'P7_Peak': float(np.max(np.abs(data_flat))),
            'P8_Peak2Peak': float(np.max(data_flat) - np.min(data_flat)),
            'P9_CrestFactor': float(np.max(np.abs(data_flat)) / np.sqrt(np.mean(data_flat**2))),
            'P10_ShapeFactor': float(np.sqrt(np.mean(data_flat**2)) / np.mean(np.abs(data_flat))),
            'P11_ImpulseFactor': float(np.max(np.abs(data_flat)) / np.mean(np.abs(data_flat))),
            'P12_MarginFactor': float(np.max(np.abs(data_flat)) / (np.mean(np.sqrt(np.abs(data_flat))))**2),
            'P13_Energy': float(np.sum(data_flat**2)),
            'P14_Entropy': float(self._calculate_entropy(data_flat)),
            'P15_ZeroCrossing': int(np.sum(np.diff(np.sign(data_flat)) != 0)),
            'P16_MeanFreq': float(self._mean_frequency(data_flat))
        }
        
        return features
    
    def compute_fft_features(self, data, fs):
        """è®¡ç®—FFTç‰¹å¾"""
        data_flat = data.flatten()
        
        # è®¡ç®—FFT
        fft_data = np.fft.fft(data_flat)
        fft_magnitude = np.abs(fft_data[:len(fft_data)//2])
        frequencies = np.fft.fftfreq(len(data_flat), 1/fs)[:len(fft_data)//2]
        
        # é¢‘åŸŸç‰¹å¾
        freq_mean = float(np.sum(frequencies * fft_magnitude) / np.sum(fft_magnitude))
        freq_var = float(np.sum((frequencies - freq_mean)**2 * fft_magnitude) / np.sum(fft_magnitude))
        
        features = {
            'P17_FreqMean': freq_mean,
            'P18_FreqVar': freq_var,
            'P19_FreqStd': float(np.sqrt(freq_var)),
            'P20_FreqSkew': float(self._freq_skewness(frequencies, fft_magnitude)),
            'P21_FreqKurt': float(self._freq_kurtosis(frequencies, fft_magnitude)),
            'P22_FreqRMS': float(np.sqrt(np.mean(fft_magnitude**2))),
            'P23_SpectralCentroid': float(np.sum(frequencies * fft_magnitude) / np.sum(fft_magnitude)),
            'P24_SpectralRolloff': float(self._spectral_rolloff(frequencies, fft_magnitude)),
            'P25_SpectralFlatness': float(self._spectral_flatness(fft_magnitude)),
            'P26_SpectralBandwidth': float(self._spectral_bandwidth(frequencies, fft_magnitude)),
            'P27_DominantFreq': float(frequencies[np.argmax(fft_magnitude)]),
            'P28_FreqPeak': float(np.max(fft_magnitude)),
            'P29_TotalPower': float(np.sum(fft_magnitude**2))
        }
        
        return features, fft_magnitude, frequencies
    
    def calculate_theoretical_fault_frequencies(self, rpm, bearing_type):
        """è®¡ç®—ç†è®ºæ•…éšœé¢‘ç‡"""
        fr = rpm / 60  # è½¬é¢‘(Hz)
        
        if bearing_type not in self.bearing_params:
            return {}
        
        params = self.bearing_params[bearing_type]
        n, d, D = params['n'], params['d'], params['D']
        
        # è®¡ç®—ç‰¹å¾é¢‘ç‡
        bpfo = (n * fr / 2) * (1 - d * np.cos(0) / D)  # å¤–åœˆæ•…éšœé¢‘ç‡
        bpfi = (n * fr / 2) * (1 + d * np.cos(0) / D)  # å†…åœˆæ•…éšœé¢‘ç‡
        bsf = (D * fr / (2 * d)) * (1 - (d * np.cos(0) / D)**2)  # æ»šåŠ¨ä½“æ•…éšœé¢‘ç‡
        ftf = (fr / 2) * (1 - d * np.cos(0) / D)  # ä¿æŒæ¶æ•…éšœé¢‘ç‡
        
        return {
            'BPFO': float(bpfo),
            'BPFI': float(bpfi),
            'BSF': float(bsf),
            'FTF': float(ftf),
            'FR': float(fr)
        }
    
    def analyze_frequency_components(self, fft_magnitude, frequencies, fs, rpm, bearing_type):
        """åˆ†æé¢‘ç‡æˆåˆ†"""
        # ä¸»é¢‘æ£€æµ‹
        peak_indices, _ = signal.find_peaks(fft_magnitude, height=np.max(fft_magnitude)*0.1)
        
        if len(peak_indices) > 0:
            main_peak_idx = peak_indices[np.argmax(fft_magnitude[peak_indices])]
            main_frequency = frequencies[main_peak_idx]
            main_amplitude = fft_magnitude[main_peak_idx]
        else:
            main_frequency = frequencies[np.argmax(fft_magnitude)]
            main_amplitude = np.max(fft_magnitude)
        
        # è°æ³¢æ£€æµ‹
        harmonics = []
        for h in range(2, 6):  # æ£€æµ‹2-5æ¬¡è°æ³¢
            harmonic_freq = main_frequency * h
            if harmonic_freq < fs/2:
                # æŸ¥æ‰¾è°æ³¢é™„è¿‘çš„å³°å€¼
                freq_range = 5  # Hz
                mask = (frequencies >= harmonic_freq - freq_range) & (frequencies <= harmonic_freq + freq_range)
                if np.any(mask):
                    harmonic_idx = np.argmax(fft_magnitude[mask])
                    actual_idx = np.where(mask)[0][harmonic_idx]
                    harmonics.append({
                        'order': h,
                        'frequency': float(frequencies[actual_idx]),
                        'amplitude': float(fft_magnitude[actual_idx])
                    })
        
        # ç†è®ºæ•…éšœé¢‘ç‡
        theoretical_freqs = self.calculate_theoretical_fault_frequencies(rpm, bearing_type)
        
        analysis_result = {
            'main_frequency': float(main_frequency),
            'main_amplitude': float(main_amplitude),
            'harmonics': harmonics,
            'theoretical_frequencies': theoretical_freqs,
            'peak_count': len(peak_indices)
        }
        
        return analysis_result
    
    def plot_time_domain(self, data, fs, output_path, data_name, data_type):
        """ç»˜åˆ¶æ—¶åŸŸä¿¡å·"""
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        data_flat = data.flatten()
        time = np.arange(len(data_flat)) / fs
        
        fig, ax = plt.subplots(figsize=(15, 6))
        ax.plot(time, data_flat, 'b-', linewidth=0.8)
        ax.set_xlabel('æ—¶é—´ (ç§’)')
        ax.set_ylabel('æŒ¯å¹…')
        ax.set_title(f'{data_name} - {data_type} - æ—¶åŸŸä¿¡å·')
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        rms = np.sqrt(np.mean(data_flat**2))
        peak = np.max(np.abs(data_flat))
        peak2peak = np.max(data_flat) - np.min(data_flat)
        
        info_text = f'ç±»å‹: {data_type}\nRMS: {rms:.4f}\nPeak: {peak:.4f}\nP-P: {peak2peak:.4f}\nç‚¹æ•°: {len(data_flat):,}\næ—¶é•¿: {len(data_flat)/fs:.1f}ç§’'
        ax.text(0.02, 0.98, info_text, transform=ax.transAxes, 
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_frequency_domain(self, fft_magnitude, frequencies, output_path, data_name, data_type, freq_analysis):
        """ç»˜åˆ¶é¢‘åŸŸä¿¡å·"""
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, ax = plt.subplots(figsize=(15, 6))
        ax.plot(frequencies, fft_magnitude, 'b-', linewidth=0.8)
        ax.set_xlabel('é¢‘ç‡ (Hz)')
        ax.set_ylabel('å¹…å€¼')
        ax.set_title(f'{data_name} - {data_type} - é¢‘åŸŸä¿¡å·')
        ax.grid(True, alpha=0.3)
        
        # æ ‡æ³¨ä¸»é¢‘
        main_freq = freq_analysis['main_frequency']
        main_amp = freq_analysis['main_amplitude']
        ax.plot(main_freq, main_amp, 'ro', markersize=8)
        ax.annotate(f'ä¸»é¢‘: {main_freq:.1f}Hz', 
                   xy=(main_freq, main_amp), xytext=(main_freq+50, main_amp),
                   arrowprops=dict(arrowstyle='->', color='red'))
        
        # æ ‡æ³¨è°æ³¢
        for harmonic in freq_analysis['harmonics'][:3]:  # åªæ ‡æ³¨å‰3ä¸ªè°æ³¢
            h_freq = harmonic['frequency']
            h_amp = harmonic['amplitude']
            ax.plot(h_freq, h_amp, 'go', markersize=6)
            ax.annotate(f'{harmonic["order"]}æ¬¡è°æ³¢', 
                       xy=(h_freq, h_amp), xytext=(h_freq+30, h_amp*0.8),
                       arrowprops=dict(arrowstyle='->', color='green'))
        
        # æ ‡æ³¨ç†è®ºæ•…éšœé¢‘ç‡
        theoretical = freq_analysis['theoretical_frequencies']
        colors = {'BPFO': 'orange', 'BPFI': 'purple', 'BSF': 'brown', 'FTF': 'pink'}
        for fault_type, freq_val in theoretical.items():
            if fault_type != 'FR' and freq_val < max(frequencies):
                ax.axvline(x=freq_val, color=colors.get(fault_type, 'gray'), 
                          linestyle='--', alpha=0.7, label=f'{fault_type}: {freq_val:.1f}Hz')
        
        ax.legend()
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def process_single_file(self, file_path, category, file_index):
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶ï¼Œç”ŸæˆåŸå§‹æ•°æ®å’Œå»å™ªæ•°æ®ä¸¤ä¸ªç‰ˆæœ¬
        """
        print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {file_index+1}/161: {file_path.name}")
        
        # åŠ è½½æ•°æ®
        mat_data = self.load_mat_file(file_path)
        if mat_data is None:
            return []
        
        # ç¡®å®šé‡‡æ ·é¢‘ç‡å’Œé™é‡‡æ ·ç­–ç•¥
        if '48kHz' in category:
            original_fs = 48000
            target_fs = 12000
            need_downsample = True
        else:
            original_fs = 12000
            target_fs = 12000
            need_downsample = False
        
        # æŸ¥æ‰¾æ•°æ®å˜é‡
        time_vars = [k for k in mat_data.keys() if not k.startswith('__') and 'time' in k.lower()]
        rpm_vars = [k for k in mat_data.keys() if not k.startswith('__') and 'rpm' in k.lower()]
        
        if not time_vars:
            print(f"âŒ æœªæ‰¾åˆ°æ—¶åŸŸæ•°æ®å˜é‡")
            return []
        
        # è·å–RPM
        rpm = 1760  # é»˜è®¤è½¬é€Ÿ
        if rpm_vars:
            rpm_data = mat_data[rpm_vars[0]]
            if isinstance(rpm_data, np.ndarray):
                rpm = float(rpm_data.flatten()[0])
        
        processed_files = []
        
        # é€‰æ‹©ä¸»è¦çš„æ—¶åŸŸå˜é‡ï¼ˆé€šå¸¸æ˜¯DE_timeï¼‰
        primary_var = time_vars[0]
        for var_name in time_vars:
            if 'DE_time' in var_name:
                primary_var = var_name
                break
        
        data = mat_data[primary_var]
        if not isinstance(data, np.ndarray) or len(data.shape) < 1:
            print(f"âŒ æ•°æ®æ ¼å¼é”™è¯¯: {primary_var}")
            return []
        
        print(f"  å¤„ç†å˜é‡: {primary_var}, é•¿åº¦: {len(data):,}")
        
        # é™é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if need_downsample:
            data_downsampled = self.downsample_signal(data, original_fs, target_fs)
            print(f"  é™é‡‡æ ·åé•¿åº¦: {len(data_downsampled):,}")
        else:
            data_downsampled = data
        
        # ç¡®å®šæ•…éšœç±»å‹
        fault_type = self._determine_fault_type(file_path.name, category)
        
        # ç¡®å®šè½´æ‰¿ç±»å‹
        bearing_type = 'SKF6205' if 'DE' in primary_var else 'SKF6203'
        
        # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŠ ä¸Šç±»åˆ«å‰ç¼€é¿å…é‡åï¼‰
        category_prefix = category.replace('_data', '').replace('kHz_', 'k_')
        base_name = f"{category_prefix}_{file_path.stem}"
        
        # 1. å¤„ç†åŸå§‹æ•°æ®ï¼ˆé™é‡‡æ ·åï¼Œä½†æœªå»å™ªï¼‰
        print(f"    ğŸ“ ç”ŸæˆåŸå§‹æ•°æ®æ–‡ä»¶...")
        
        # æå–ç‰¹å¾
        raw_time_features = self.extract_time_features(data_downsampled)
        raw_freq_features, raw_fft_magnitude, raw_frequencies = self.compute_fft_features(data_downsampled, target_fs)
        raw_freq_analysis = self.analyze_frequency_components(raw_fft_magnitude, raw_frequencies, target_fs, rpm, bearing_type)
        
        # åˆ›å»ºåŸå§‹æ•°æ®æ–‡ä»¶å¤¹
        raw_data_dir = self.output_base / f"{base_name}"
        raw_data_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜åŸå§‹æ•°æ®
        np.save(raw_data_dir / f"{base_name}_raw_data.npy", data_downsampled)
        
        # ç»˜åˆ¶åŸå§‹æ•°æ®å›¾åƒ
        self.plot_time_domain(data_downsampled, target_fs, 
                            raw_data_dir / f"{base_name}_time_domain.png", 
                            base_name, "åŸå§‹æ•°æ®")
        self.plot_frequency_domain(raw_fft_magnitude, raw_frequencies, 
                                 raw_data_dir / f"{base_name}_frequency_domain.png", 
                                 base_name, "åŸå§‹æ•°æ®", raw_freq_analysis)
        
        # ä¿å­˜åŸå§‹æ•°æ®ç‰¹å¾
        raw_all_features = {**raw_time_features, **raw_freq_features, 'fault_type': fault_type, 'data_type': 'raw'}
        raw_features_df = pd.DataFrame([raw_all_features])
        raw_features_df.to_csv(raw_data_dir / f"{base_name}_features.csv", index=False, encoding='utf-8-sig')
        
        # ä¿å­˜åŸå§‹æ•°æ®é¢‘ç‡åˆ†æ
        raw_freq_analysis['data_type'] = 'raw'
        raw_freq_df = pd.DataFrame([raw_freq_analysis])
        raw_freq_df.to_csv(raw_data_dir / f"{base_name}_frequency_analysis.csv", index=False, encoding='utf-8-sig')
        
        processed_files.append({
            'file_name': base_name,
            'original_file': str(file_path),
            'variable': primary_var,
            'data_type': 'raw',
            'original_length': len(data),
            'processed_length': len(data_downsampled),
            'fault_type': fault_type,
            'rpm': rpm,
            'sampling_rate': target_fs,
            'bearing_type': bearing_type
        })
        
        # 2. å¤„ç†å»å™ªæ•°æ®
        print(f"    ğŸ”§ ç”Ÿæˆå»å™ªæ•°æ®æ–‡ä»¶...")
        
        # å»å™ªå¤„ç†
        data_denoised = self.apply_denoising(data_downsampled, target_fs)
        
        # æå–å»å™ªæ•°æ®ç‰¹å¾
        denoised_time_features = self.extract_time_features(data_denoised)
        denoised_freq_features, denoised_fft_magnitude, denoised_frequencies = self.compute_fft_features(data_denoised, target_fs)
        denoised_freq_analysis = self.analyze_frequency_components(denoised_fft_magnitude, denoised_frequencies, target_fs, rpm, bearing_type)
        
        # åˆ›å»ºå»å™ªæ•°æ®æ–‡ä»¶å¤¹
        denoised_name = f"{base_name}_denoised"
        denoised_data_dir = self.output_base / denoised_name
        denoised_data_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜å»å™ªæ•°æ®
        np.save(denoised_data_dir / f"{denoised_name}_raw_data.npy", data_denoised)
        
        # ç»˜åˆ¶å»å™ªæ•°æ®å›¾åƒ
        self.plot_time_domain(data_denoised, target_fs, 
                            denoised_data_dir / f"{denoised_name}_time_domain.png", 
                            base_name, "å»å™ªæ•°æ®")
        self.plot_frequency_domain(denoised_fft_magnitude, denoised_frequencies, 
                                 denoised_data_dir / f"{denoised_name}_frequency_domain.png", 
                                 base_name, "å»å™ªæ•°æ®", denoised_freq_analysis)
        
        # ä¿å­˜å»å™ªæ•°æ®ç‰¹å¾
        denoised_all_features = {**denoised_time_features, **denoised_freq_features, 'fault_type': fault_type, 'data_type': 'denoised'}
        denoised_features_df = pd.DataFrame([denoised_all_features])
        denoised_features_df.to_csv(denoised_data_dir / f"{denoised_name}_features.csv", index=False, encoding='utf-8-sig')
        
        # ä¿å­˜å»å™ªæ•°æ®é¢‘ç‡åˆ†æ
        denoised_freq_analysis['data_type'] = 'denoised'
        denoised_freq_df = pd.DataFrame([denoised_freq_analysis])
        denoised_freq_df.to_csv(denoised_data_dir / f"{denoised_name}_frequency_analysis.csv", index=False, encoding='utf-8-sig')
        
        processed_files.append({
            'file_name': denoised_name,
            'original_file': str(file_path),
            'variable': primary_var,
            'data_type': 'denoised',
            'original_length': len(data),
            'processed_length': len(data_denoised),
            'fault_type': fault_type,
            'rpm': rpm,
            'sampling_rate': target_fs,
            'bearing_type': bearing_type
        })
        
        self.processed_count += 2  # æ¯ä¸ªåŸå§‹æ–‡ä»¶ç”Ÿæˆ2ä¸ªå¤„ç†åæ–‡ä»¶
        print(f"    âœ… å®Œæˆ: {base_name} (åŸå§‹) + {denoised_name} (å»å™ª)")
        
        return processed_files
    
    def _determine_fault_type(self, filename, category):
        """ç¡®å®šæ•…éšœç±»å‹"""
        filename_upper = filename.upper()
        if 'OR' in filename_upper or 'OUTER' in filename_upper:
            return 'OR'
        elif 'IR' in filename_upper or 'INNER' in filename_upper:
            return 'IR'
        elif 'B' in filename_upper and any(x in filename for x in ['007', '014', '021', '028']):
            return 'B'
        elif 'N' in filename_upper or 'NORMAL' in filename_upper:
            return 'N'
        else:
            return 'Unknown'
    
    # è¾…åŠ©å‡½æ•°
    def _skewness(self, data):
        """è®¡ç®—ååº¦"""
        return np.mean(((data - np.mean(data)) / np.std(data)) ** 3)
    
    def _kurtosis(self, data):
        """è®¡ç®—å³­åº¦"""
        return np.mean(((data - np.mean(data)) / np.std(data)) ** 4) - 3
    
    def _calculate_entropy(self, data):
        """è®¡ç®—ç†µ"""
        hist, _ = np.histogram(data, bins=50)
        hist = hist[hist > 0]
        prob = hist / np.sum(hist)
        return -np.sum(prob * np.log2(prob))
    
    def _mean_frequency(self, data):
        """è®¡ç®—å¹³å‡é¢‘ç‡"""
        fft_data = np.fft.fft(data)
        magnitude = np.abs(fft_data[:len(fft_data)//2])
        freqs = np.arange(len(magnitude))
        return np.sum(freqs * magnitude) / np.sum(magnitude)
    
    def _freq_skewness(self, frequencies, magnitude):
        """é¢‘åŸŸååº¦"""
        mean_freq = np.sum(frequencies * magnitude) / np.sum(magnitude)
        variance = np.sum((frequencies - mean_freq)**2 * magnitude) / np.sum(magnitude)
        if variance == 0:
            return 0
        std_freq = np.sqrt(variance)
        return np.sum(((frequencies - mean_freq) / std_freq)**3 * magnitude) / np.sum(magnitude)
    
    def _freq_kurtosis(self, frequencies, magnitude):
        """é¢‘åŸŸå³­åº¦"""
        mean_freq = np.sum(frequencies * magnitude) / np.sum(magnitude)
        variance = np.sum((frequencies - mean_freq)**2 * magnitude) / np.sum(magnitude)
        if variance == 0:
            return 0
        std_freq = np.sqrt(variance)
        return np.sum(((frequencies - mean_freq) / std_freq)**4 * magnitude) / np.sum(magnitude) - 3
    
    def _spectral_rolloff(self, frequencies, magnitude, rolloff_percent=0.85):
        """è°±æ»šé™"""
        total_energy = np.sum(magnitude)
        rolloff_energy = rolloff_percent * total_energy
        cumulative_energy = np.cumsum(magnitude)
        rolloff_idx = np.where(cumulative_energy >= rolloff_energy)[0]
        return frequencies[rolloff_idx[0]] if len(rolloff_idx) > 0 else frequencies[-1]
    
    def _spectral_flatness(self, magnitude):
        """è°±å¹³å¦åº¦"""
        geometric_mean = np.exp(np.mean(np.log(magnitude + 1e-10)))
        arithmetic_mean = np.mean(magnitude)
        return geometric_mean / arithmetic_mean if arithmetic_mean > 0 else 0
    
    def _spectral_bandwidth(self, frequencies, magnitude):
        """è°±å¸¦å®½"""
        centroid = np.sum(frequencies * magnitude) / np.sum(magnitude)
        return np.sqrt(np.sum((frequencies - centroid)**2 * magnitude) / np.sum(magnitude))


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ åŸå§‹æ•°æ®å¤„ç†å™¨")
    print("=" * 60)
    print("ç›®æ ‡: 161ä¸ªåŸå§‹æ–‡ä»¶ â†’ 322ä¸ªå®Œæ•´æ•°æ®æ–‡ä»¶")
    print("æ–¹æ¡ˆ: æ¯ä¸ªæ–‡ä»¶ç”ŸæˆåŸå§‹ç‰ˆæœ¬ + å»å™ªç‰ˆæœ¬")
    print("=" * 60)
    
    # è·¯å¾„è®¾ç½®
    source_base = "/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/æ•°æ®é›†/æ•°æ®é›†/æºåŸŸæ•°æ®é›†"
    output_base = "/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/raw_data"
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = RawDataProcessor(source_base, output_base)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_base).mkdir(parents=True, exist_ok=True)
    
    # åˆ é™¤æ—§çš„å¤„ç†ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if Path(output_base).exists():
        import shutil
        for item in Path(output_base).iterdir():
            if item.is_dir():
                shutil.rmtree(item)
            else:
                item.unlink()
    
    all_processed_files = []
    processing_stats = {}
    total_input_files = 0
    
    # å¤„ç†æ‰€æœ‰ç±»åˆ«
    categories = ['12kHz_DE_data', '12kHz_FE_data', '48kHz_DE_data', '48kHz_Normal_data']
    
    for category in categories:
        category_path = Path(source_base) / category
        if not category_path.exists():
            print(f"âš ï¸ ç±»åˆ«è·¯å¾„ä¸å­˜åœ¨: {category_path}")
            continue
        
        print(f"\nğŸ“ å¤„ç†ç±»åˆ«: {category}")
        
        # æŸ¥æ‰¾æ‰€æœ‰.matæ–‡ä»¶
        mat_files = list(category_path.rglob("*.mat"))
        print(f"æ‰¾åˆ° {len(mat_files)} ä¸ª.matæ–‡ä»¶")
        
        category_files = []
        
        for file_idx, mat_file in enumerate(mat_files):
            files = processor.process_single_file(mat_file, category, file_idx)
            category_files.extend(files)
            all_processed_files.extend(files)
            total_input_files += 1
        
        processing_stats[category] = {
            'input_files': len(mat_files),
            'output_files': len(category_files),
            'files_per_input': len(category_files) / len(mat_files) if len(mat_files) > 0 else 0
        }
        
        print(f"ğŸ“Š {category} ç»Ÿè®¡:")
        print(f"  è¾“å…¥æ–‡ä»¶: {len(mat_files)} ä¸ª")
        print(f"  è¾“å‡ºæ–‡ä»¶: {len(category_files)} ä¸ª")
        print(f"  è½¬æ¢æ¯”ä¾‹: 1:{len(category_files) / len(mat_files):.1f}")
    
    # ä¿å­˜å¤„ç†ç»Ÿè®¡
    stats_summary = {
        'processing_time': datetime.now().isoformat(),
        'total_input_files': total_input_files,
        'total_output_files': len(all_processed_files),
        'target_output_files': 322,  # 161 * 2
        'category_stats': processing_stats,
        'files_detail': all_processed_files
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    reports_dir = Path(output_base).parent / "reports"
    reports_dir.mkdir(exist_ok=True)
    
    with open(reports_dir / "raw_data_processing_report.json", 'w', encoding='utf-8') as f:
        json.dump(stats_summary, f, ensure_ascii=False, indent=2, default=str)
    
    # ä¿å­˜è¯¦ç»†ç»Ÿè®¡CSV
    files_df = pd.DataFrame(all_processed_files)
    files_df.to_csv(reports_dir / "raw_data_summary.csv", index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… å¤„ç†å®Œæˆ!")
    print(f"ğŸ“Š æ€»ç»“:")
    print(f"  è¾“å…¥æ–‡ä»¶: {total_input_files} ä¸ª")
    print(f"  è¾“å‡ºæ–‡ä»¶: {len(all_processed_files)} ä¸ª")
    print(f"  ç›®æ ‡æ–‡ä»¶: 322 ä¸ª (161Ã—2)")
    print(f"  å®Œæˆç‡: {len(all_processed_files)/322*100:.1f}%")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_base}")
    print(f"ğŸ“„ å¤„ç†æŠ¥å‘Š: raw_data_processing_report.json")


if __name__ == "__main__":
    main()
