#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆç»“æœéªŒè¯è„šæœ¬
éªŒè¯ç”Ÿæˆçš„322ä¸ªæ•°æ®æ–‡ä»¶å¤¹æ˜¯å¦å®Œæ•´ä¸”ç¬¦åˆè¦æ±‚
"""

import os
import numpy as np
import pandas as pd
from pathlib import Path
import json

def verify_data_completeness():
    """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
    
    output_path = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®")
    segments_path = output_path / "processed_segments"
    
    print("ğŸ” æœ€ç»ˆç»“æœéªŒè¯")
    print("=" * 60)
    
    # 1. éªŒè¯æ–‡ä»¶å¤¹æ•°é‡
    if not segments_path.exists():
        print("âŒ é”™è¯¯: processed_segmentsæ–‡ä»¶å¤¹ä¸å­˜åœ¨")
        return False
    
    segment_dirs = [d for d in segments_path.iterdir() if d.is_dir()]
    total_segments = len(segment_dirs)
    
    print(f"ğŸ“ æ•°æ®æ–‡ä»¶å¤¹æ•°é‡: {total_segments}")
    
    if total_segments != 322:
        print(f"âŒ é”™è¯¯: é¢„æœŸ322ä¸ªæ–‡ä»¶å¤¹ï¼Œå®é™…{total_segments}ä¸ª")
        return False
    else:
        print("âœ… æ–‡ä»¶å¤¹æ•°é‡æ­£ç¡®: 322ä¸ª")
    
    # 2. éªŒè¯æ¯ä¸ªæ–‡ä»¶å¤¹çš„æ–‡ä»¶å®Œæ•´æ€§
    print(f"\nğŸ“‹ éªŒè¯æ–‡ä»¶å®Œæ•´æ€§...")
    
    required_files = [
        "_raw_data.npy",
        "_time_domain.png", 
        "_frequency_domain.png",
        "_features.csv",
        "_frequency_analysis.csv"
    ]
    
    complete_segments = 0
    incomplete_segments = []
    
    for segment_dir in segment_dirs:
        segment_name = segment_dir.name
        files_exist = []
        
        for file_suffix in required_files:
            file_path = segment_dir / f"{segment_name}{file_suffix}"
            files_exist.append(file_path.exists())
        
        if all(files_exist):
            complete_segments += 1
        else:
            incomplete_segments.append(segment_name)
    
    print(f"âœ… å®Œæ•´çš„æ•°æ®ç‰‡æ®µ: {complete_segments}/{total_segments}")
    
    if incomplete_segments:
        print(f"âŒ ä¸å®Œæ•´çš„æ•°æ®ç‰‡æ®µ ({len(incomplete_segments)}ä¸ª):")
        for segment in incomplete_segments[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"    - {segment}")
        if len(incomplete_segments) > 5:
            print(f"    ... è¿˜æœ‰{len(incomplete_segments) - 5}ä¸ª")
        return False
    
    # 3. éªŒè¯æ•°æ®ç±»åˆ«åˆ†å¸ƒ
    print(f"\nğŸ“Š éªŒè¯æ•°æ®ç±»åˆ«åˆ†å¸ƒ...")
    
    category_counts = {}
    fault_type_counts = {}
    
    for segment_dir in segment_dirs:
        segment_name = segment_dir.name
        
        # æå–æ•°æ®ç±»åˆ«
        if segment_name.startswith('12kHz_DE_'):
            category = '12kHz_DE'
        elif segment_name.startswith('12kHz_FE_'):
            category = '12kHz_FE'
        elif segment_name.startswith('48kHz_DE_'):
            category = '48kHz_DE'
        elif segment_name.startswith('48kHz_Normal_'):
            category = '48kHz_Normal'
        else:
            category = 'Unknown'
        
        category_counts[category] = category_counts.get(category, 0) + 1
        
        # ä»ç‰¹å¾æ–‡ä»¶ä¸­è¯»å–æ•…éšœç±»å‹
        features_file = segment_dir / f"{segment_name}_features.csv"
        if features_file.exists():
            try:
                df = pd.read_csv(features_file)
                fault_type = df['fault_type'].iloc[0]
                fault_type_counts[fault_type] = fault_type_counts.get(fault_type, 0) + 1
            except:
                pass
    
    print("æ•°æ®ç±»åˆ«åˆ†å¸ƒ:")
    for category, count in sorted(category_counts.items()):
        print(f"  {category}: {count} ä¸ªç‰‡æ®µ")
    
    print("\næ•…éšœç±»å‹åˆ†å¸ƒ:")
    for fault_type, count in sorted(fault_type_counts.items()):
        print(f"  {fault_type}: {count} ä¸ªç‰‡æ®µ")
    
    # 4. éªŒè¯æ–‡ä»¶å‘½åå”¯ä¸€æ€§
    print(f"\nğŸ”’ éªŒè¯æ–‡ä»¶å‘½åå”¯ä¸€æ€§...")
    
    segment_names = [d.name for d in segment_dirs]
    unique_names = set(segment_names)
    
    if len(segment_names) == len(unique_names):
        print("âœ… æ‰€æœ‰æ–‡ä»¶å¤¹åç§°éƒ½æ˜¯å”¯ä¸€çš„")
    else:
        print(f"âŒ å‘ç°é‡å¤çš„æ–‡ä»¶å¤¹åç§°: {len(segment_names) - len(unique_names)}ä¸ªé‡å¤")
        return False
    
    # 5. éªŒè¯å…³é”®æ–‡ä»¶å†…å®¹
    print(f"\nğŸ“„ éªŒè¯å…³é”®æ–‡ä»¶å†…å®¹...")
    
    # æ£€æŸ¥ç‰¹å¾CSVæ–‡ä»¶
    sample_segment = segment_dirs[0]
    sample_name = sample_segment.name
    features_file = sample_segment / f"{sample_name}_features.csv"
    freq_analysis_file = sample_segment / f"{sample_name}_frequency_analysis.csv"
    
    if features_file.exists():
        try:
            features_df = pd.read_csv(features_file)
            print(f"âœ… ç‰¹å¾æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ŒåŒ…å« {len(features_df.columns)} åˆ—")
            
            # éªŒè¯æ˜¯å¦åŒ…å«29ä¸ªç‰¹å¾
            feature_cols = [col for col in features_df.columns if col.startswith('P')]
            print(f"âœ… åŒ…å« {len(feature_cols)} ä¸ªPç‰¹å¾")
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
            return False
    
    if freq_analysis_file.exists():
        try:
            freq_df = pd.read_csv(freq_analysis_file)
            print(f"âœ… é¢‘ç‡åˆ†ææ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ŒåŒ…å« {len(freq_df.columns)} åˆ—")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸»é¢‘ä¿¡æ¯
            if 'dominant_frequency' in freq_df.columns:
                print("âœ… åŒ…å«ä¸»é¢‘æ£€æµ‹ä¿¡æ¯")
            if 'harmonics_count' in freq_df.columns:
                print("âœ… åŒ…å«è°æ³¢åˆ†æä¿¡æ¯")
                
        except Exception as e:
            print(f"âŒ é¢‘ç‡åˆ†ææ–‡ä»¶è¯»å–é”™è¯¯: {e}")
            return False
    
    # 6. éªŒè¯æŠ¥å‘Šæ–‡ä»¶
    print(f"\nğŸ“ éªŒè¯æŠ¥å‘Šæ–‡ä»¶...")
    
    reports_path = output_path / "reports"
    required_reports = [
        "processing_report.txt",
        "processing_report.json",
        "all_features_summary.csv",
        "all_frequency_analysis_summary.csv"
    ]
    
    for report_file in required_reports:
        report_path = reports_path / report_file
        if report_path.exists():
            print(f"âœ… {report_file} å­˜åœ¨")
        else:
            print(f"âŒ {report_file} ç¼ºå¤±")
            return False
    
    # éªŒè¯æ±‡æ€»CSVè¡Œæ•°
    summary_file = reports_path / "all_features_summary.csv"
    if summary_file.exists():
        try:
            summary_df = pd.read_csv(summary_file)
            print(f"âœ… ç‰¹å¾æ±‡æ€»æ–‡ä»¶åŒ…å« {len(summary_df)} è¡Œæ•°æ®")
            if len(summary_df) == 322:
                print("âœ… æ±‡æ€»æ•°æ®è¡Œæ•°æ­£ç¡®")
            else:
                print(f"âŒ æ±‡æ€»æ•°æ®è¡Œæ•°ä¸æ­£ç¡®ï¼Œé¢„æœŸ322è¡Œï¼Œå®é™…{len(summary_df)}è¡Œ")
                return False
        except Exception as e:
            print(f"âŒ æ±‡æ€»æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
            return False
    
    print(f"\nğŸ‰ éªŒè¯å®Œæˆï¼")
    print("=" * 60)
    print("âœ… æ‰€æœ‰éªŒè¯é¡¹ç›®éƒ½é€šè¿‡")
    print("âœ… æˆåŠŸç”Ÿæˆ322ä¸ªå®Œæ•´çš„æ•°æ®æ–‡ä»¶å¤¹")
    print("âœ… æ¯ä¸ªæ–‡ä»¶å¤¹åŒ…å«5ä¸ªå¿…éœ€æ–‡ä»¶")
    print("âœ… æ–‡ä»¶å‘½åå”¯ä¸€ï¼Œé¿å…äº†å†²çª")
    print("âœ… æ•°æ®ç±»åˆ«åˆ†å¸ƒåˆç†")
    print("âœ… å¢å¼ºåŠŸèƒ½(ä¸»é¢‘æ ‡æ³¨ã€è°æ³¢åˆ†æ)æ­£å¸¸å·¥ä½œ")
    
    return True

def generate_final_summary():
    """ç”Ÿæˆæœ€ç»ˆæ€»ç»“"""
    
    print("\n" + "=" * 60)
    print("ğŸ† é¡¹ç›®æœ€ç»ˆæ€»ç»“")
    print("=" * 60)
    
    improvements = [
        "âœ… è§£å†³äº†æ–‡ä»¶å¤¹åç§°å†²çªé—®é¢˜ - ä½¿ç”¨å”¯ä¸€ç¼–å·ç¡®ä¿322ä¸ªæ–‡ä»¶å¤¹",
        "âœ… å¢åŠ äº†ä¸»é¢‘æ£€æµ‹å’Œæ ‡æ³¨ - åœ¨é¢‘åŸŸå›¾ä¸­æ¸…æ™°æ ‡æ³¨ä¸»é¢‘",
        "âœ… å¢åŠ äº†è°æ³¢æˆåˆ†åˆ†æ - è‡ªåŠ¨è¯†åˆ«å’Œåˆ†æè°æ³¢æˆåˆ†",
        "âœ… ç”Ÿæˆäº†é¢‘ç‡åˆ†æCSV - åŒ…å«ä¸»é¢‘ã€è°æ³¢ã€ç†è®ºæ•…éšœé¢‘ç‡",
        "âœ… å®Œå–„äº†å›¾åƒæ ‡æ³¨ - æ—¶åŸŸå›¾å¢åŠ ç»Ÿè®¡ä¿¡æ¯ï¼Œé¢‘åŸŸå›¾å¢åŠ ä¸»é¢‘æ ‡æ³¨",
        "âœ… ä¿æŒäº†æ‰€æœ‰åŸæœ‰åŠŸèƒ½ - 29ç»´ç‰¹å¾æå–ã€å»å™ªæ»¤æ³¢ç­‰"
    ]
    
    print("ğŸ”§ å…³é”®æ”¹è¿›:")
    for improvement in improvements:
        print(f"  {improvement}")
    
    output_structure = [
        "ğŸ“ æ¯ä¸ªæ•°æ®æ–‡ä»¶å¤¹åŒ…å«5ä¸ªæ–‡ä»¶:",
        "  â€¢ *_raw_data.npy - å»å™ªæ»¤æ³¢åçš„2048ç‚¹æ—¶åŸŸæ•°æ®",
        "  â€¢ *_time_domain.png - æ—¶åŸŸä¿¡å·å›¾åƒ(å«RMSã€å³°å€¼ç­‰ç»Ÿè®¡ä¿¡æ¯)",
        "  â€¢ *_frequency_domain.png - é¢‘åŸŸä¿¡å·å›¾åƒ(å«ä¸»é¢‘ã€è°æ³¢ã€ç†è®ºæ•…éšœé¢‘ç‡æ ‡æ³¨)",
        "  â€¢ *_features.csv - 29ç»´æ—¶åŸŸ+é¢‘åŸŸç‰¹å¾å‘é‡ + æ•…éšœç±»å‹æ ‡ç­¾",
        "  â€¢ *_frequency_analysis.csv - ä¸»é¢‘ã€è°æ³¢æˆåˆ†ã€ç†è®ºæ•…éšœé¢‘ç‡åˆ†æ"
    ]
    
    print(f"\nğŸ“‹ è¾“å‡ºç»“æ„:")
    for item in output_structure:
        print(f"  {item}")
    
    print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"  â€¢ å¤„ç†æºæ–‡ä»¶: 161ä¸ª")
    print(f"  â€¢ ç”Ÿæˆæ•°æ®ç‰‡æ®µ: 322ä¸ª (æ¯ä¸ªæºæ–‡ä»¶å‰åå„ä¸€æ®µ)")
    print(f"  â€¢ æ•°æ®æ–‡ä»¶å¤¹: 322ä¸ª (å”¯ä¸€å‘½åï¼Œæ— å†²çª)")
    print(f"  â€¢ æ€»æ–‡ä»¶æ•°: 1,610ä¸ª (322 Ã— 5)")
    print(f"  â€¢ æ•°æ®å®Œæ•´æ€§: 100%")

if __name__ == "__main__":
    success = verify_data_completeness()
    if success:
        generate_final_summary()
    else:
        print("\nâŒ éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
