#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æåŸå§‹æ•°æ®é•¿åº¦åˆ†å¸ƒï¼Œè®¾è®¡æœ€ä½³åˆ†æ®µç­–ç•¥
é‡æ–°å®¡è§†æ•°æ®å¤„ç†éœ€æ±‚ï¼šä»æ¯ä¸ªmatæ–‡ä»¶ç”Ÿæˆ3ä¸ªæœ‰æ•ˆæ•°æ®ç‰‡æ®µ
"""

import os
import numpy as np
import scipy.io as sio
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import json

def analyze_original_data_lengths():
    """åˆ†ææºåŸŸæ•°æ®é›†ä¸­æ‰€æœ‰æ–‡ä»¶çš„æ•°æ®é•¿åº¦"""
    
    source_base = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/æ•°æ®é›†/æ•°æ®é›†/æºåŸŸæ•°æ®é›†")
    
    print("ğŸ” åŸå§‹æ•°æ®é•¿åº¦åˆ†æ")
    print("=" * 60)
    
    length_stats = {
        'files': [],
        'lengths': [],
        'categories': [],
        'sampling_rates': []
    }
    
    # éå†æ‰€æœ‰æ•°æ®é›†ç±»åˆ«
    categories = {
        '12kHz_DE_data': 12000,
        '12kHz_FE_data': 12000,
        '48kHz_DE_data': 48000,
        '48kHz_Normal_data': 48000
    }
    
    for category, fs in categories.items():
        category_path = source_base / category
        if not category_path.exists():
            print(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: {category_path}")
            continue
            
        print(f"\nğŸ“ åˆ†æç±»åˆ«: {category}")
        
        # æŸ¥æ‰¾æ‰€æœ‰.matæ–‡ä»¶
        mat_files = list(category_path.rglob("*.mat"))
        print(f"æ‰¾åˆ° {len(mat_files)} ä¸ª.matæ–‡ä»¶")
        
        for i, mat_file in enumerate(mat_files[:5]):  # å…ˆåˆ†æå‰5ä¸ªæ–‡ä»¶
            print(f"\n  ğŸ“„ æ–‡ä»¶ {i+1}: {mat_file.name}")
            
            try:
                mat_data = sio.loadmat(str(mat_file))
                
                # æŸ¥æ‰¾æ—¶åŸŸæ•°æ®å˜é‡
                time_vars = [k for k in mat_data.keys() 
                           if not k.startswith('__') and 'time' in k.lower()]
                
                for var_name in time_vars:
                    data = mat_data[var_name]
                    if isinstance(data, np.ndarray) and len(data.shape) >= 1:
                        length = data.shape[0]
                        duration = length / fs
                        
                        print(f"    {var_name}: {length} ç‚¹ ({duration:.2f}ç§’)")
                        
                        length_stats['files'].append(str(mat_file))
                        length_stats['lengths'].append(length)
                        length_stats['categories'].append(category)
                        length_stats['sampling_rates'].append(fs)
                        
            except Exception as e:
                print(f"    âŒ è¯»å–é”™è¯¯: {e}")
    
    return length_stats

def design_segmentation_strategy(length_stats):
    """è®¾è®¡æ•°æ®åˆ†æ®µç­–ç•¥"""
    
    print(f"\nğŸ“Š æ•°æ®åˆ†æ®µç­–ç•¥è®¾è®¡")
    print("-" * 40)
    
    # ç»Ÿè®¡æ•°æ®é•¿åº¦åˆ†å¸ƒ
    lengths = np.array(length_stats['lengths'])
    categories = length_stats['categories']
    sampling_rates = length_stats['sampling_rates']
    
    print(f"æ•°æ®é•¿åº¦ç»Ÿè®¡:")
    print(f"  æœ€å°é•¿åº¦: {np.min(lengths):,} ç‚¹")
    print(f"  æœ€å¤§é•¿åº¦: {np.max(lengths):,} ç‚¹")
    print(f"  å¹³å‡é•¿åº¦: {np.mean(lengths):,.0f} ç‚¹")
    print(f"  ä¸­ä½é•¿åº¦: {np.median(lengths):,.0f} ç‚¹")
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    print(f"\næŒ‰ç±»åˆ«ç»Ÿè®¡:")
    df = pd.DataFrame({
        'length': lengths,
        'category': categories,
        'sampling_rate': sampling_rates
    })
    
    category_stats = df.groupby(['category', 'sampling_rate']).agg({
        'length': ['count', 'min', 'max', 'mean', 'median']
    }).round(0)
    
    print(category_stats)
    
    # è®¾è®¡åˆ†æ®µç­–ç•¥
    print(f"\nğŸ¯ åˆ†æ®µç­–ç•¥è®¾è®¡:")
    
    strategies = {}
    
    for (category, fs), group in df.groupby(['category', 'sampling_rate']):
        min_length = group['length'].min()
        avg_length = group['length'].mean()
        
        # éœ€æ±‚ï¼šæ¯æ®µ>=6ä¸‡ç‚¹ï¼Œé™é‡‡æ ·å>=2ä¸‡ç‚¹
        min_segment_points = 60000  # åŸå§‹æ•°æ®æœ€å°ç‚¹æ•°
        min_downsampled_points = 20000  # é™é‡‡æ ·åæœ€å°ç‚¹æ•°
        
        # å¦‚æœæ˜¯48kHzæ•°æ®ï¼Œéœ€è¦é™é‡‡æ ·åˆ°12kHz
        if fs == 48000:
            target_fs = 12000
            downsample_ratio = fs / target_fs  # 4:1
            min_original_points = min_downsampled_points * downsample_ratio  # 80000ç‚¹
        else:
            target_fs = fs
            downsample_ratio = 1
            min_original_points = min_downsampled_points  # 20000ç‚¹
        
        # ç¡®ä¿æ»¡è¶³æœ€å°è¦æ±‚
        actual_min_points = max(min_segment_points, min_original_points)
        
        # è®¡ç®—å¯ä»¥åˆ†æˆå‡ æ®µ
        num_segments = int(min_length // actual_min_points)
        segment_length = int(min_length // num_segments) if num_segments > 0 else min_length
        
        # ä½†æˆ‘ä»¬è¦æ±‚æ˜¯3æ®µï¼Œæ‰€ä»¥é‡æ–°è®¡ç®—
        target_segments = 3
        required_total_length = target_segments * actual_min_points
        
        if min_length >= required_total_length:
            # å¯ä»¥åˆ†æˆ3æ®µ
            segment_length = int(min_length // target_segments)
            feasible = True
        else:
            # æ•°æ®ä¸å¤Ÿåˆ†æˆ3æ®µï¼Œè°ƒæ•´ç­–ç•¥
            segment_length = int(min_length // 2)  # åˆ†æˆ2æ®µ
            target_segments = 2
            feasible = False
        
        strategies[f"{category}_{fs}Hz"] = {
            'category': category,
            'original_fs': int(fs),
            'target_fs': int(target_fs),
            'downsample_ratio': float(downsample_ratio),
            'min_length': int(min_length),
            'avg_length': int(avg_length),
            'target_segments': int(target_segments),
            'segment_length': int(segment_length),
            'min_required_points': int(actual_min_points),
            'feasible_3_segments': bool(feasible),
            'downsampled_segment_length': int(segment_length / downsample_ratio)
        }
        
        print(f"\n  ğŸ“Š {category} ({fs}Hz):")
        print(f"    åŸå§‹é•¿åº¦èŒƒå›´: {int(min_length):,} - {int(group['length'].max()):,} ç‚¹")
        print(f"    é™é‡‡æ ·æ¯”ä¾‹: {downsample_ratio:.1f}:1 ({fs}Hz â†’ {target_fs}Hz)")
        print(f"    å»ºè®®åˆ†æ®µæ•°: {target_segments} æ®µ")
        print(f"    æ¯æ®µé•¿åº¦: {segment_length:,} ç‚¹")
        print(f"    é™é‡‡æ ·åæ¯æ®µ: {int(segment_length / downsample_ratio):,} ç‚¹")
        print(f"    3æ®µæ–¹æ¡ˆå¯è¡Œ: {'âœ…' if feasible else 'âŒ'}")
    
    return strategies

def visualize_length_distribution(length_stats):
    """å¯è§†åŒ–æ•°æ®é•¿åº¦åˆ†å¸ƒ"""
    
    plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['axes.unicode_minus'] = False
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('åŸå§‹æ•°æ®é•¿åº¦åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')
    
    df = pd.DataFrame({
        'length': length_stats['lengths'],
        'category': length_stats['categories'],
        'sampling_rate': length_stats['sampling_rates']
    })
    
    # 1. æ€»ä½“é•¿åº¦åˆ†å¸ƒ
    axes[0, 0].hist(df['length'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, 0].set_title('æ€»ä½“æ•°æ®é•¿åº¦åˆ†å¸ƒ')
    axes[0, 0].set_xlabel('æ•°æ®é•¿åº¦ (ç‚¹)')
    axes[0, 0].set_ylabel('æ–‡ä»¶æ•°é‡')
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. æŒ‰ç±»åˆ«åˆ†å¸ƒ
    categories = df['category'].unique()
    colors = ['red', 'blue', 'green', 'orange']
    for i, cat in enumerate(categories):
        cat_data = df[df['category'] == cat]['length']
        axes[0, 1].hist(cat_data, bins=10, alpha=0.6, 
                       color=colors[i % len(colors)], label=cat)
    axes[0, 1].set_title('æŒ‰ç±»åˆ«çš„é•¿åº¦åˆ†å¸ƒ')
    axes[0, 1].set_xlabel('æ•°æ®é•¿åº¦ (ç‚¹)')
    axes[0, 1].set_ylabel('æ–‡ä»¶æ•°é‡')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. ç®±çº¿å›¾
    box_data = [df[df['category'] == cat]['length'] for cat in categories]
    axes[1, 0].boxplot(box_data, tick_labels=[cat.replace('_data', '') for cat in categories])
    axes[1, 0].set_title('å„ç±»åˆ«é•¿åº¦åˆ†å¸ƒç®±çº¿å›¾')
    axes[1, 0].set_ylabel('æ•°æ®é•¿åº¦ (ç‚¹)')
    axes[1, 0].tick_params(axis='x', rotation=45)
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. ç»Ÿè®¡æ‘˜è¦è¡¨
    axes[1, 1].axis('off')
    summary_stats = df.groupby('category')['length'].describe()
    table_data = []
    for cat in summary_stats.index:
        stats = summary_stats.loc[cat]
        table_data.append([
            cat.replace('_data', ''),
            f"{stats['count']:.0f}",
            f"{stats['min']:,.0f}",
            f"{stats['max']:,.0f}",
            f"{stats['mean']:,.0f}",
            f"{stats['std']:,.0f}"
        ])
    
    table = axes[1, 1].table(cellText=table_data,
                            colLabels=['ç±»åˆ«', 'æ–‡ä»¶æ•°', 'æœ€å°å€¼', 'æœ€å¤§å€¼', 'å¹³å‡å€¼', 'æ ‡å‡†å·®'],
                            cellLoc='center',
                            loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1.2, 1.5)
    axes[1, 1].set_title('ç»Ÿè®¡æ‘˜è¦è¡¨')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    output_dir = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/reports")
    plt.savefig(output_dir / "original_data_length_analysis.png", dpi=300, bbox_inches='tight')
    plt.show()

def save_analysis_results(length_stats, strategies):
    """ä¿å­˜åˆ†æç»“æœ"""
    
    output_dir = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/reports")
    
    # ä¿å­˜è¯¦ç»†æ•°æ®
    df = pd.DataFrame(length_stats)
    df.to_csv(output_dir / "original_data_length_stats.csv", index=False, encoding='utf-8-sig')
    
    # ä¿å­˜ç­–ç•¥
    with open(output_dir / "segmentation_strategies.json", 'w', encoding='utf-8') as f:
        json.dump(strategies, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜ç­–ç•¥æ‘˜è¦
    strategy_df = pd.DataFrame(strategies).T
    strategy_df.to_csv(output_dir / "segmentation_strategies.csv", encoding='utf-8-sig')
    
    print(f"\nğŸ“„ åˆ†æç»“æœå·²ä¿å­˜:")
    print(f"  - original_data_length_stats.csv: è¯¦ç»†é•¿åº¦æ•°æ®")
    print(f"  - segmentation_strategies.json: åˆ†æ®µç­–ç•¥")
    print(f"  - segmentation_strategies.csv: ç­–ç•¥æ‘˜è¦")
    print(f"  - original_data_length_analysis.png: å¯è§†åŒ–å›¾è¡¨")

def main():
    """ä¸»å‡½æ•°"""
    print("é‡æ–°è®¾è®¡æ•°æ®å¤„ç†æ–¹æ¡ˆ")
    print("=" * 60)
    print("ç›®æ ‡: ä»æ¯ä¸ªmatæ–‡ä»¶ç”Ÿæˆ3ä¸ªæ•°æ®ç‰‡æ®µ")
    print("è¦æ±‚: æ¯æ®µ>=6ä¸‡ç‚¹ï¼Œé™é‡‡æ ·å>=2ä¸‡ç‚¹")
    print("=" * 60)
    
    # åˆ†æåŸå§‹æ•°æ®é•¿åº¦
    length_stats = analyze_original_data_lengths()
    
    if not length_stats['lengths']:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
        return
    
    # è®¾è®¡åˆ†æ®µç­–ç•¥
    strategies = design_segmentation_strategy(length_stats)
    
    # å¯è§†åŒ–åˆ†æ
    visualize_length_distribution(length_stats)
    
    # ä¿å­˜ç»“æœ
    save_analysis_results(length_stats, strategies)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼")
    print(f"ä¸‹ä¸€æ­¥: åŸºäºåˆ†æç»“æœå®ç°æ–°çš„æ•°æ®å¤„ç†æµç¨‹")

if __name__ == "__main__":
    main()
