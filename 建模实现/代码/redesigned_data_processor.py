#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°è®¾è®¡çš„æ•°æ®å¤„ç†å™¨
åŸºäºæ•°æ®é•¿åº¦åˆ†æç»“æœï¼Œä»æ¯ä¸ªmatæ–‡ä»¶ç”Ÿæˆ3ä¸ªæ•°æ®ç‰‡æ®µ
ç¡®ä¿æ¯æ®µ>=6ä¸‡ç‚¹ï¼Œé™é‡‡æ ·å>=2ä¸‡ç‚¹
"""

import os
import numpy as np
import scipy.io as sio
import scipy.signal as signal
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import json
from datetime import datetime

class RedesignedDataProcessor:
    """é‡æ–°è®¾è®¡çš„æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, source_base_path, output_base_path):
        self.source_base = Path(source_base_path)
        self.output_base = Path(output_base_path)
        self.processed_count = 0
        
        # æ•°æ®é•¿åº¦åˆ†æç»“æœï¼ˆåŸºäºä¹‹å‰çš„åˆ†æï¼‰
        self.length_strategies = {
            '12kHz_DE_data': {
                'original_fs': 12000,
                'target_fs': 12000,
                'downsample_ratio': 1.0,
                'typical_length': 96000,
                'segments_per_file': 2,  # 96kåªèƒ½åˆ†2æ®µï¼Œæ¯æ®µ48k
                'segment_length': 48000
            },
            '12kHz_FE_data': {
                'original_fs': 12000,
                'target_fs': 12000,
                'downsample_ratio': 1.0,
                'typical_length': 96000,
                'segments_per_file': 2,  # 96kåªèƒ½åˆ†2æ®µï¼Œæ¯æ®µ48k
                'segment_length': 48000
            },
            '48kHz_DE_data': {
                'original_fs': 48000,
                'target_fs': 12000,
                'downsample_ratio': 4.0,
                'typical_length': 192000,
                'segments_per_file': 2,  # 192ké™é‡‡æ ·å48kï¼Œåˆ†2æ®µæ¯æ®µ24k
                'segment_length': 96000
            },
            '48kHz_Normal_data': {
                'original_fs': 48000,
                'target_fs': 12000,
                'downsample_ratio': 4.0,
                'typical_length': 350000,  # å¹³å‡é•¿åº¦
                'segments_per_file': 3,  # åªæœ‰è¿™ä¸ªå¯ä»¥åˆ†3æ®µ
                'segment_length': 116000  # çº¦116kæ¯æ®µ
            }
        }
        
        # è½´æ‰¿å‚æ•°
        self.bearing_params = {
            'SKF6205': {'n': 9, 'd': 0.3126, 'D': 1.537},  # DEè½´æ‰¿
            'SKF6203': {'n': 9, 'd': 0.2656, 'D': 1.122}   # FEè½´æ‰¿
        }
    
    def load_mat_file(self, file_path):
        """åŠ è½½.matæ–‡ä»¶"""
        try:
            return sio.loadmat(str(file_path))
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None
    
    def downsample_signal(self, data, original_fs, target_fs):
        """é™é‡‡æ ·ä¿¡å·"""
        if original_fs == target_fs:
            return data
        
        # è®¡ç®—é™é‡‡æ ·æ¯”ä¾‹
        downsample_factor = int(original_fs / target_fs)
        
        # ä½¿ç”¨scipyçš„decimateå‡½æ•°è¿›è¡Œé™é‡‡æ ·
        # å…ˆåº”ç”¨æŠ—æ··å æ»¤æ³¢å™¨ï¼Œç„¶åé™é‡‡æ ·
        downsampled = signal.decimate(data.flatten(), downsample_factor, ftype='iir')
        
        return downsampled.reshape(-1, 1)
    
    def apply_denoising(self, data, fs):
        """åº”ç”¨å»å™ªæ»¤æ³¢å™¨"""
        data_flat = data.flatten()
        
        # 1. é«˜é€šæ»¤æ³¢ (10Hz)
        sos_hp = signal.butter(4, 10, btype='highpass', fs=fs, output='sos')
        data_filtered = signal.sosfilt(sos_hp, data_flat)
        
        # 2. ä½é€šæ»¤æ³¢ (5000Hz)
        sos_lp = signal.butter(4, 5000, btype='lowpass', fs=fs, output='sos')
        data_filtered = signal.sosfilt(sos_lp, data_filtered)
        
        # 3. é™·æ³¢æ»¤æ³¢ (50Hzå·¥é¢‘åŠå…¶è°æ³¢)
        for freq in [50, 100, 150]:
            if freq < fs/2:
                b_notch, a_notch = signal.iirnotch(freq, 30, fs)
                data_filtered = signal.filtfilt(b_notch, a_notch, data_filtered)
        
        # 4. ä¸­å€¼æ»¤æ³¢å»é™¤è„‰å†²å™ªå£°
        data_filtered = signal.medfilt(data_filtered, kernel_size=3)
        
        return data_filtered.reshape(-1, 1)
    
    def extract_multiple_segments(self, data, strategy):
        """ä»æ•°æ®ä¸­æå–å¤šä¸ªç‰‡æ®µ"""
        data_length = len(data)
        segments_per_file = strategy['segments_per_file']
        
        # å¦‚æœæ•°æ®é•¿åº¦ä¸è¶³ï¼Œè°ƒæ•´ç­–ç•¥
        min_segment_length = 60000  # æœ€å°6ä¸‡ç‚¹
        if data_length < min_segment_length * segments_per_file:
            # æ•°æ®ä¸å¤Ÿï¼Œå‡å°‘æ®µæ•°æˆ–è°ƒæ•´æ®µé•¿åº¦
            if data_length >= min_segment_length * 2:
                segments_per_file = 2
                segment_length = data_length // 2
            else:
                segments_per_file = 1
                segment_length = data_length
        else:
            segment_length = data_length // segments_per_file
        
        segments = []
        for i in range(segments_per_file):
            start_idx = i * segment_length
            end_idx = min(start_idx + segment_length, data_length)
            segment = data[start_idx:end_idx]
            
            # ç¡®ä¿æ®µé•¿åº¦è¶³å¤Ÿ
            if len(segment) >= min_segment_length:
                segments.append(segment)
        
        return segments
    
    def extract_time_features(self, segment_data):
        """æå–æ—¶åŸŸç‰¹å¾"""
        data = segment_data.flatten()
        
        features = {
            'P1_Mean': float(np.mean(data)),
            'P2_RMS': float(np.sqrt(np.mean(data**2))),
            'P3_Variance': float(np.var(data)),
            'P4_Std': float(np.std(data)),
            'P5_Skewness': float(self._skewness(data)),
            'P6_Kurtosis': float(self._kurtosis(data)),
            'P7_Peak': float(np.max(np.abs(data))),
            'P8_Peak2Peak': float(np.max(data) - np.min(data)),
            'P9_CrestFactor': float(np.max(np.abs(data)) / np.sqrt(np.mean(data**2))),
            'P10_ShapeFactor': float(np.sqrt(np.mean(data**2)) / np.mean(np.abs(data))),
            'P11_ImpulseFactor': float(np.max(np.abs(data)) / np.mean(np.abs(data))),
            'P12_MarginFactor': float(np.max(np.abs(data)) / (np.mean(np.sqrt(np.abs(data))))**2),
            'P13_Energy': float(np.sum(data**2)),
            'P14_Entropy': float(self._calculate_entropy(data)),
            'P15_ZeroCrossing': int(np.sum(np.diff(np.sign(data)) != 0)),
            'P16_MeanFreq': float(self._mean_frequency(data))
        }
        
        return features
    
    def compute_fft_features(self, segment_data, fs):
        """è®¡ç®—FFTç‰¹å¾"""
        data = segment_data.flatten()
        
        # è®¡ç®—FFT
        fft_data = np.fft.fft(data)
        fft_magnitude = np.abs(fft_data[:len(fft_data)//2])
        frequencies = np.fft.fftfreq(len(data), 1/fs)[:len(fft_data)//2]
        
        # é¢‘åŸŸç‰¹å¾
        freq_mean = float(np.sum(frequencies * fft_magnitude) / np.sum(fft_magnitude))
        freq_var = float(np.sum((frequencies - freq_mean)**2 * fft_magnitude) / np.sum(fft_magnitude))
        
        features = {
            'P17_FreqMean': freq_mean,
            'P18_FreqVar': freq_var,
            'P19_FreqStd': float(np.sqrt(freq_var)),
            'P20_FreqSkew': float(self._freq_skewness(frequencies, fft_magnitude)),
            'P21_FreqKurt': float(self._freq_kurtosis(frequencies, fft_magnitude)),
            'P22_FreqRMS': float(np.sqrt(np.mean(fft_magnitude**2))),
            'P23_SpectralCentroid': float(np.sum(frequencies * fft_magnitude) / np.sum(fft_magnitude)),
            'P24_SpectralRolloff': float(self._spectral_rolloff(frequencies, fft_magnitude)),
            'P25_SpectralFlatness': float(self._spectral_flatness(fft_magnitude)),
            'P26_SpectralBandwidth': float(self._spectral_bandwidth(frequencies, fft_magnitude)),
            'P27_DominantFreq': float(frequencies[np.argmax(fft_magnitude)]),
            'P28_FreqPeak': float(np.max(fft_magnitude)),
            'P29_TotalPower': float(np.sum(fft_magnitude**2))
        }
        
        return features, fft_magnitude, frequencies
    
    def calculate_theoretical_fault_frequencies(self, rpm, bearing_type):
        """è®¡ç®—ç†è®ºæ•…éšœé¢‘ç‡"""
        fr = rpm / 60  # è½¬é¢‘(Hz)
        
        if bearing_type not in self.bearing_params:
            return {}
        
        params = self.bearing_params[bearing_type]
        n, d, D = params['n'], params['d'], params['D']
        
        # è®¡ç®—ç‰¹å¾é¢‘ç‡
        bpfo = (n * fr / 2) * (1 - d * np.cos(0) / D)  # å¤–åœˆæ•…éšœé¢‘ç‡
        bpfi = (n * fr / 2) * (1 + d * np.cos(0) / D)  # å†…åœˆæ•…éšœé¢‘ç‡
        bsf = (D * fr / (2 * d)) * (1 - (d * np.cos(0) / D)**2)  # æ»šåŠ¨ä½“æ•…éšœé¢‘ç‡
        ftf = (fr / 2) * (1 - d * np.cos(0) / D)  # ä¿æŒæ¶æ•…éšœé¢‘ç‡
        
        return {
            'BPFO': float(bpfo),
            'BPFI': float(bpfi),
            'BSF': float(bsf),
            'FTF': float(ftf),
            'FR': float(fr)
        }
    
    def analyze_frequency_components(self, fft_magnitude, frequencies, fs, rpm, bearing_type):
        """åˆ†æé¢‘ç‡æˆåˆ†"""
        # ä¸»é¢‘æ£€æµ‹
        peak_indices, _ = signal.find_peaks(fft_magnitude, height=np.max(fft_magnitude)*0.1)
        
        if len(peak_indices) > 0:
            main_peak_idx = peak_indices[np.argmax(fft_magnitude[peak_indices])]
            main_frequency = frequencies[main_peak_idx]
            main_amplitude = fft_magnitude[main_peak_idx]
        else:
            main_frequency = frequencies[np.argmax(fft_magnitude)]
            main_amplitude = np.max(fft_magnitude)
        
        # è°æ³¢æ£€æµ‹
        harmonics = []
        for h in range(2, 6):  # æ£€æµ‹2-5æ¬¡è°æ³¢
            harmonic_freq = main_frequency * h
            if harmonic_freq < fs/2:
                # æŸ¥æ‰¾è°æ³¢é™„è¿‘çš„å³°å€¼
                freq_range = 5  # Hz
                mask = (frequencies >= harmonic_freq - freq_range) & (frequencies <= harmonic_freq + freq_range)
                if np.any(mask):
                    harmonic_idx = np.argmax(fft_magnitude[mask])
                    actual_idx = np.where(mask)[0][harmonic_idx]
                    harmonics.append({
                        'order': h,
                        'frequency': float(frequencies[actual_idx]),
                        'amplitude': float(fft_magnitude[actual_idx])
                    })
        
        # ç†è®ºæ•…éšœé¢‘ç‡
        theoretical_freqs = self.calculate_theoretical_fault_frequencies(rpm, bearing_type)
        
        analysis_result = {
            'main_frequency': float(main_frequency),
            'main_amplitude': float(main_amplitude),
            'harmonics': harmonics,
            'theoretical_frequencies': theoretical_freqs,
            'peak_count': len(peak_indices)
        }
        
        return analysis_result
    
    def plot_time_domain(self, segment_data, fs, output_path, segment_name):
        """ç»˜åˆ¶æ—¶åŸŸä¿¡å·"""
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        data = segment_data.flatten()
        time = np.arange(len(data)) / fs
        
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.plot(time, data, 'b-', linewidth=0.8)
        ax.set_xlabel('æ—¶é—´ (ç§’)')
        ax.set_ylabel('æŒ¯å¹…')
        ax.set_title(f'{segment_name} - æ—¶åŸŸä¿¡å·')
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        rms = np.sqrt(np.mean(data**2))
        peak = np.max(np.abs(data))
        peak2peak = np.max(data) - np.min(data)
        
        info_text = f'RMS: {rms:.4f}\nPeak: {peak:.4f}\nP-P: {peak2peak:.4f}'
        ax.text(0.02, 0.98, info_text, transform=ax.transAxes, 
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_frequency_domain(self, fft_magnitude, frequencies, output_path, segment_name, freq_analysis):
        """ç»˜åˆ¶é¢‘åŸŸä¿¡å·"""
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.plot(frequencies, fft_magnitude, 'b-', linewidth=0.8)
        ax.set_xlabel('é¢‘ç‡ (Hz)')
        ax.set_ylabel('å¹…å€¼')
        ax.set_title(f'{segment_name} - é¢‘åŸŸä¿¡å·')
        ax.grid(True, alpha=0.3)
        
        # æ ‡æ³¨ä¸»é¢‘
        main_freq = freq_analysis['main_frequency']
        main_amp = freq_analysis['main_amplitude']
        ax.plot(main_freq, main_amp, 'ro', markersize=8)
        ax.annotate(f'ä¸»é¢‘: {main_freq:.1f}Hz', 
                   xy=(main_freq, main_amp), xytext=(main_freq+50, main_amp),
                   arrowprops=dict(arrowstyle='->', color='red'))
        
        # æ ‡æ³¨è°æ³¢
        for harmonic in freq_analysis['harmonics'][:3]:  # åªæ ‡æ³¨å‰3ä¸ªè°æ³¢
            h_freq = harmonic['frequency']
            h_amp = harmonic['amplitude']
            ax.plot(h_freq, h_amp, 'go', markersize=6)
            ax.annotate(f'{harmonic["order"]}æ¬¡è°æ³¢', 
                       xy=(h_freq, h_amp), xytext=(h_freq+30, h_amp*0.8),
                       arrowprops=dict(arrowstyle='->', color='green'))
        
        # æ ‡æ³¨ç†è®ºæ•…éšœé¢‘ç‡
        theoretical = freq_analysis['theoretical_frequencies']
        colors = {'BPFO': 'orange', 'BPFI': 'purple', 'BSF': 'brown', 'FTF': 'pink'}
        for fault_type, freq_val in theoretical.items():
            if fault_type != 'FR' and freq_val < max(frequencies):
                ax.axvline(x=freq_val, color=colors.get(fault_type, 'gray'), 
                          linestyle='--', alpha=0.7, label=f'{fault_type}: {freq_val:.1f}Hz')
        
        ax.legend()
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def process_single_file(self, file_path, category, file_index):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶: {file_path.name}")
        
        # åŠ è½½æ•°æ®
        mat_data = self.load_mat_file(file_path)
        if mat_data is None:
            return []
        
        # è·å–å¤„ç†ç­–ç•¥
        strategy = self.length_strategies.get(category)
        if strategy is None:
            print(f"âŒ æœªæ‰¾åˆ°ç±»åˆ« {category} çš„å¤„ç†ç­–ç•¥")
            return []
        
        # æŸ¥æ‰¾æ•°æ®å˜é‡
        time_vars = [k for k in mat_data.keys() if not k.startswith('__') and 'time' in k.lower()]
        rpm_vars = [k for k in mat_data.keys() if not k.startswith('__') and 'rpm' in k.lower()]
        
        if not time_vars:
            print(f"âŒ æœªæ‰¾åˆ°æ—¶åŸŸæ•°æ®å˜é‡")
            return []
        
        # è·å–RPM
        rpm = 1760  # é»˜è®¤è½¬é€Ÿ
        if rpm_vars:
            rpm_data = mat_data[rpm_vars[0]]
            if isinstance(rpm_data, np.ndarray):
                rpm = float(rpm_data.flatten()[0])
        
        processed_segments = []
        
        # å¤„ç†æ¯ä¸ªæ—¶åŸŸå˜é‡
        for var_name in time_vars:
            data = mat_data[var_name]
            if not isinstance(data, np.ndarray) or len(data.shape) < 1:
                continue
            
            print(f"  å¤„ç†å˜é‡: {var_name}, é•¿åº¦: {len(data):,}")
            
            # æå–å¤šä¸ªç‰‡æ®µ
            segments = self.extract_multiple_segments(data, strategy)
            
            for seg_idx, segment in enumerate(segments):
                segment_id = f"{file_path.stem}_{var_name.split('_')[-2]}_{seg_idx+1}"
                
                # é™é‡‡æ ·
                if strategy['downsample_ratio'] > 1:
                    segment = self.downsample_signal(segment, strategy['original_fs'], strategy['target_fs'])
                
                # å»å™ª
                segment_denoised = self.apply_denoising(segment, strategy['target_fs'])
                
                # ç‰¹å¾æå–
                time_features = self.extract_time_features(segment_denoised)
                freq_features, fft_magnitude, frequencies = self.compute_fft_features(segment_denoised, strategy['target_fs'])
                
                # é¢‘ç‡åˆ†æ
                bearing_type = 'SKF6205' if 'DE' in var_name else 'SKF6203'
                freq_analysis = self.analyze_frequency_components(fft_magnitude, frequencies, strategy['target_fs'], rpm, bearing_type)
                
                # ç¡®å®šæ•…éšœç±»å‹
                fault_type = self._determine_fault_type(file_path.name, category)
                
                # åˆ›å»ºè¾“å‡ºç›®å½•
                segment_dir = self.output_base / f"{segment_id}"
                segment_dir.mkdir(parents=True, exist_ok=True)
                
                # ä¿å­˜åŸå§‹æ•°æ®
                np.save(segment_dir / f"{segment_id}_raw_data.npy", segment_denoised)
                
                # ç»˜åˆ¶å›¾åƒ
                self.plot_time_domain(segment_denoised, strategy['target_fs'], 
                                    segment_dir / f"{segment_id}_time_domain.png", segment_id)
                self.plot_frequency_domain(fft_magnitude, frequencies, 
                                         segment_dir / f"{segment_id}_frequency_domain.png", 
                                         segment_id, freq_analysis)
                
                # ä¿å­˜ç‰¹å¾
                all_features = {**time_features, **freq_features, 'fault_type': fault_type}
                features_df = pd.DataFrame([all_features])
                features_df.to_csv(segment_dir / f"{segment_id}_features.csv", index=False, encoding='utf-8-sig')
                
                # ä¿å­˜é¢‘ç‡åˆ†æ
                freq_df = pd.DataFrame([freq_analysis])
                freq_df.to_csv(segment_dir / f"{segment_id}_frequency_analysis.csv", index=False, encoding='utf-8-sig')
                
                processed_segments.append({
                    'segment_id': segment_id,
                    'original_file': str(file_path),
                    'variable': var_name,
                    'segment_index': seg_idx,
                    'original_length': len(data),
                    'processed_length': len(segment_denoised),
                    'fault_type': fault_type,
                    'rpm': rpm,
                    'sampling_rate': strategy['target_fs']
                })
                
                self.processed_count += 1
                print(f"    âœ… ç‰‡æ®µ {seg_idx+1}: {segment_id}")
        
        return processed_segments
    
    def _determine_fault_type(self, filename, category):
        """ç¡®å®šæ•…éšœç±»å‹"""
        filename_upper = filename.upper()
        if 'OR' in filename_upper or 'OUTER' in filename_upper:
            return 'OR'
        elif 'IR' in filename_upper or 'INNER' in filename_upper:
            return 'IR'
        elif 'B' in filename_upper and ('007' in filename or '014' in filename or '021' in filename or '028' in filename):
            return 'B'
        elif 'N' in filename_upper or 'NORMAL' in filename_upper:
            return 'N'
        else:
            return 'Unknown'
    
    # è¾…åŠ©å‡½æ•°
    def _skewness(self, data):
        """è®¡ç®—ååº¦"""
        return np.mean(((data - np.mean(data)) / np.std(data)) ** 3)
    
    def _kurtosis(self, data):
        """è®¡ç®—å³­åº¦"""
        return np.mean(((data - np.mean(data)) / np.std(data)) ** 4) - 3
    
    def _calculate_entropy(self, data):
        """è®¡ç®—ç†µ"""
        hist, _ = np.histogram(data, bins=50)
        hist = hist[hist > 0]
        prob = hist / np.sum(hist)
        return -np.sum(prob * np.log2(prob))
    
    def _mean_frequency(self, data):
        """è®¡ç®—å¹³å‡é¢‘ç‡"""
        fft_data = np.fft.fft(data)
        magnitude = np.abs(fft_data[:len(fft_data)//2])
        freqs = np.arange(len(magnitude))
        return np.sum(freqs * magnitude) / np.sum(magnitude)
    
    def _freq_skewness(self, frequencies, magnitude):
        """é¢‘åŸŸååº¦"""
        mean_freq = np.sum(frequencies * magnitude) / np.sum(magnitude)
        variance = np.sum((frequencies - mean_freq)**2 * magnitude) / np.sum(magnitude)
        if variance == 0:
            return 0
        std_freq = np.sqrt(variance)
        return np.sum(((frequencies - mean_freq) / std_freq)**3 * magnitude) / np.sum(magnitude)
    
    def _freq_kurtosis(self, frequencies, magnitude):
        """é¢‘åŸŸå³­åº¦"""
        mean_freq = np.sum(frequencies * magnitude) / np.sum(magnitude)
        variance = np.sum((frequencies - mean_freq)**2 * magnitude) / np.sum(magnitude)
        if variance == 0:
            return 0
        std_freq = np.sqrt(variance)
        return np.sum(((frequencies - mean_freq) / std_freq)**4 * magnitude) / np.sum(magnitude) - 3
    
    def _spectral_rolloff(self, frequencies, magnitude, rolloff_percent=0.85):
        """è°±æ»šé™"""
        total_energy = np.sum(magnitude)
        rolloff_energy = rolloff_percent * total_energy
        cumulative_energy = np.cumsum(magnitude)
        rolloff_idx = np.where(cumulative_energy >= rolloff_energy)[0]
        return frequencies[rolloff_idx[0]] if len(rolloff_idx) > 0 else frequencies[-1]
    
    def _spectral_flatness(self, magnitude):
        """è°±å¹³å¦åº¦"""
        geometric_mean = np.exp(np.mean(np.log(magnitude + 1e-10)))
        arithmetic_mean = np.mean(magnitude)
        return geometric_mean / arithmetic_mean if arithmetic_mean > 0 else 0
    
    def _spectral_bandwidth(self, frequencies, magnitude):
        """è°±å¸¦å®½"""
        centroid = np.sum(frequencies * magnitude) / np.sum(magnitude)
        return np.sqrt(np.sum((frequencies - centroid)**2 * magnitude) / np.sum(magnitude))


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é‡æ–°è®¾è®¡çš„æ•°æ®å¤„ç†å™¨")
    print("=" * 60)
    print("ç›®æ ‡: ä»æ¯ä¸ªmatæ–‡ä»¶ç”Ÿæˆå¤šä¸ªé«˜è´¨é‡æ•°æ®ç‰‡æ®µ")
    print("ç­–ç•¥: æ ¹æ®æ•°æ®é•¿åº¦åŠ¨æ€è°ƒæ•´åˆ†æ®µæ•°é‡")
    print("=" * 60)
    
    # è·¯å¾„è®¾ç½®
    source_base = "/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/æ•°æ®é›†/æ•°æ®é›†/æºåŸŸæ•°æ®é›†"
    output_base = "/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/redesigned_segments"
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = RedesignedDataProcessor(source_base, output_base)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_base).mkdir(parents=True, exist_ok=True)
    
    # åˆ é™¤æ—§çš„å¤„ç†ç»“æœ
    if Path(output_base).exists():
        import shutil
        shutil.rmtree(output_base)
        Path(output_base).mkdir(parents=True, exist_ok=True)
    
    all_processed_segments = []
    processing_stats = {}
    
    # å¤„ç†æ‰€æœ‰ç±»åˆ«
    categories = ['12kHz_DE_data', '12kHz_FE_data', '48kHz_DE_data', '48kHz_Normal_data']
    
    for category in categories:
        category_path = Path(source_base) / category
        if not category_path.exists():
            print(f"âš ï¸ ç±»åˆ«è·¯å¾„ä¸å­˜åœ¨: {category_path}")
            continue
        
        print(f"\nğŸ“ å¤„ç†ç±»åˆ«: {category}")
        
        # æŸ¥æ‰¾æ‰€æœ‰.matæ–‡ä»¶
        mat_files = list(category_path.rglob("*.mat"))
        print(f"æ‰¾åˆ° {len(mat_files)} ä¸ª.matæ–‡ä»¶")
        
        category_segments = []
        
        for file_idx, mat_file in enumerate(mat_files):
            segments = processor.process_single_file(mat_file, category, file_idx)
            category_segments.extend(segments)
            all_processed_segments.extend(segments)
        
        processing_stats[category] = {
            'input_files': len(mat_files),
            'output_segments': len(category_segments),
            'segments_per_file': len(category_segments) / len(mat_files) if len(mat_files) > 0 else 0
        }
        
        print(f"ğŸ“Š {category} ç»Ÿè®¡:")
        print(f"  è¾“å…¥æ–‡ä»¶: {len(mat_files)} ä¸ª")
        print(f"  è¾“å‡ºç‰‡æ®µ: {len(category_segments)} ä¸ª")
        print(f"  å¹³å‡æ¯æ–‡ä»¶ç‰‡æ®µæ•°: {len(category_segments) / len(mat_files):.1f}")
    
    # ä¿å­˜å¤„ç†ç»Ÿè®¡
    stats_summary = {
        'processing_time': datetime.now().isoformat(),
        'total_input_files': sum(stats['input_files'] for stats in processing_stats.values()),
        'total_output_segments': len(all_processed_segments),
        'category_stats': processing_stats,
        'segments_detail': all_processed_segments
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    reports_dir = Path(output_base).parent / "reports"
    reports_dir.mkdir(exist_ok=True)
    
    with open(reports_dir / "redesigned_processing_report.json", 'w', encoding='utf-8') as f:
        json.dump(stats_summary, f, ensure_ascii=False, indent=2, default=str)
    
    # ä¿å­˜è¯¦ç»†ç»Ÿè®¡CSV
    segments_df = pd.DataFrame(all_processed_segments)
    segments_df.to_csv(reports_dir / "redesigned_segments_summary.csv", index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… å¤„ç†å®Œæˆ!")
    print(f"ğŸ“Š æ€»ç»“:")
    print(f"  è¾“å…¥æ–‡ä»¶: {stats_summary['total_input_files']} ä¸ª")
    print(f"  è¾“å‡ºç‰‡æ®µ: {stats_summary['total_output_segments']} ä¸ª")
    print(f"  å¤„ç†æ•ˆç‡: {stats_summary['total_output_segments'] / stats_summary['total_input_files']:.1f} ç‰‡æ®µ/æ–‡ä»¶")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_base}")


if __name__ == "__main__":
    main()
