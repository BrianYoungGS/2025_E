#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CRWUæ•°æ®é›†åˆ†æè„šæœ¬
åˆ†æCRWUæ•°æ®é›†ä¸æºåŸŸæ•°æ®é›†çš„å¼‚åŒï¼Œè¯„ä¼°æ˜¯å¦å¯ä½œä¸ºæ‰©å±•æ•°æ®é›†
"""

import os
import numpy as np
import scipy.io as sio
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import json

def analyze_crwu_dataset():
    """åˆ†æCRWUæ•°æ®é›†"""
    
    crwu_path = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/CRWU")
    
    print("ğŸ” CRWUæ•°æ®é›†åˆ†æ")
    print("=" * 60)
    
    # æ•°æ®é›†ç»Ÿè®¡
    categories = {
        '12k Drive End Bearing Fault Data': '12kHz_DE',
        '12k Fan End Bearing Fault Data': '12kHz_FE',
        '48k Drive End Bearing Fault Data': '48kHz_DE',
        'Normal Baseline': 'Normal'
    }
    
    dataset_stats = {}
    total_files = 0
    
    for category, code in categories.items():
        category_path = crwu_path / category
        if category_path.exists():
            mat_files = list(category_path.rglob("*.mat"))
            file_count = len(mat_files)
            dataset_stats[code] = {
                'count': file_count,
                'files': mat_files
            }
            total_files += file_count
            print(f"ğŸ“ {category}: {file_count} ä¸ªæ–‡ä»¶")
    
    print(f"\nğŸ“Š æ€»è®¡: {total_files} ä¸ª.matæ–‡ä»¶")
    
    return dataset_stats, total_files

def analyze_sample_files(dataset_stats):
    """åˆ†ææ ·æœ¬æ–‡ä»¶æ ¼å¼"""
    
    print(f"\nğŸ”¬ æ ·æœ¬æ–‡ä»¶åˆ†æ")
    print("-" * 40)
    
    sample_info = {}
    
    for category, data in dataset_stats.items():
        if data['files']:
            # å–ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºæ ·æœ¬
            sample_file = data['files'][0]
            print(f"\nğŸ“‹ {category} æ ·æœ¬: {sample_file.name}")
            
            try:
                mat_data = sio.loadmat(str(sample_file))
                keys = [k for k in mat_data.keys() if not k.startswith('__')]
                
                file_info = {
                    'path': str(sample_file),
                    'variables': {}
                }
                
                for key in keys:
                    var = mat_data[key]
                    if isinstance(var, np.ndarray):
                        file_info['variables'][key] = {
                            'shape': var.shape,
                            'dtype': str(var.dtype),
                            'size': var.size
                        }
                        print(f"  {key}: {var.shape} ({var.dtype})")
                
                sample_info[category] = file_info
                
            except Exception as e:
                print(f"  âŒ è¯»å–é”™è¯¯: {e}")
                sample_info[category] = {'error': str(e)}
    
    return sample_info

def compare_with_source_dataset():
    """ä¸æºåŸŸæ•°æ®é›†å¯¹æ¯”"""
    
    print(f"\nğŸ“ˆ ä¸æºåŸŸæ•°æ®é›†å¯¹æ¯”")
    print("-" * 40)
    
    # æºåŸŸæ•°æ®é›†ç»Ÿè®¡ï¼ˆåŸºäºä¹‹å‰çš„å¤„ç†ç»“æœï¼‰
    source_stats = {
        '12kHz_DE': 60,   # ä»å¤„ç†æŠ¥å‘Šä¸­å¾—åˆ°
        '12kHz_FE': 45,
        '48kHz_DE': 52,
        '48kHz_Normal': 4,
        'Total': 161
    }
    
    print("æºåŸŸæ•°æ®é›†:")
    for category, count in source_stats.items():
        print(f"  {category}: {count} ä¸ªæ–‡ä»¶")
    
    return source_stats

def evaluate_compatibility(crwu_stats, source_stats, sample_info):
    """è¯„ä¼°å…¼å®¹æ€§"""
    
    print(f"\nâš–ï¸ å…¼å®¹æ€§è¯„ä¼°")
    print("-" * 40)
    
    compatibility = {
        'file_format': True,
        'data_structure': True,
        'categories_match': True,
        'can_extend': True,
        'issues': []
    }
    
    # 1. æ£€æŸ¥æ•°æ®ç±»åˆ«
    crwu_categories = set(crwu_stats.keys())
    source_categories = set([k for k in source_stats.keys() if k != 'Total'])
    
    print("ğŸ“‹ æ•°æ®ç±»åˆ«å¯¹æ¯”:")
    for cat in source_categories:
        if cat in crwu_categories:
            print(f"  âœ… {cat}: ä¸¤ä¸ªæ•°æ®é›†éƒ½æœ‰")
        else:
            print(f"  âŒ {cat}: CRWUä¸­ç¼ºå¤±")
            compatibility['issues'].append(f"CRWUç¼ºå°‘{cat}ç±»åˆ«")
    
    # 2. æ£€æŸ¥æ–‡ä»¶æ ¼å¼
    print(f"\nğŸ“„ æ–‡ä»¶æ ¼å¼æ£€æŸ¥:")
    all_mat = True
    for category, info in sample_info.items():
        if 'error' in info:
            print(f"  âŒ {category}: æ–‡ä»¶è¯»å–é”™è¯¯")
            all_mat = False
            compatibility['file_format'] = False
            compatibility['issues'].append(f"{category}æ–‡ä»¶æ ¼å¼é—®é¢˜")
        else:
            print(f"  âœ… {category}: .matæ ¼å¼æ­£å¸¸")
    
    # 3. æ£€æŸ¥æ•°æ®ç»“æ„
    print(f"\nğŸ”§ æ•°æ®ç»“æ„æ£€æŸ¥:")
    expected_vars = ['DE_time', 'FE_time', 'BA_time', 'RPM']
    
    for category, info in sample_info.items():
        if 'variables' in info:
            vars_found = list(info['variables'].keys())
            has_de = any('DE' in var for var in vars_found)
            has_time = any('time' in var for var in vars_found)
            
            if has_de and has_time:
                print(f"  âœ… {category}: åŒ…å«æ—¶åŸŸæ•°æ®")
            else:
                print(f"  âš ï¸ {category}: æ•°æ®ç»“æ„å¯èƒ½ä¸åŒ")
                print(f"      å˜é‡: {vars_found}")
                compatibility['issues'].append(f"{category}æ•°æ®ç»“æ„å¼‚å¸¸")
    
    # 4. æ•°é‡å¯¹æ¯”
    print(f"\nğŸ“Š æ•°é‡å¯¹æ¯”:")
    total_crwu = sum(stats['count'] for stats in crwu_stats.values())
    total_source = source_stats['Total']
    
    print(f"  CRWUæ•°æ®é›†: {total_crwu} ä¸ªæ–‡ä»¶")
    print(f"  æºåŸŸæ•°æ®é›†: {total_source} ä¸ªæ–‡ä»¶")
    print(f"  æ‰©å±•åæ€»æ•°: {total_crwu + total_source} ä¸ªæ–‡ä»¶")
    
    # 5. æœ€ç»ˆè¯„ä¼°
    if len(compatibility['issues']) == 0:
        compatibility['can_extend'] = True
        print(f"\nâœ… å…¼å®¹æ€§è¯„ä¼°: å¯ä»¥ä½œä¸ºæ‰©å±•æ•°æ®é›†ä½¿ç”¨")
    else:
        compatibility['can_extend'] = False
        print(f"\nâš ï¸ å…¼å®¹æ€§è¯„ä¼°: éœ€è¦å¤„ç†ä»¥ä¸‹é—®é¢˜æ‰èƒ½ä½¿ç”¨:")
        for issue in compatibility['issues']:
            print(f"    - {issue}")
    
    return compatibility

def generate_crwu_report(crwu_stats, source_stats, sample_info, compatibility):
    """ç”ŸæˆCRWUåˆ†ææŠ¥å‘Š"""
    
    report = {
        'analysis_time': pd.Timestamp.now().isoformat(),
        'crwu_dataset': crwu_stats,
        'source_dataset': source_stats,
        'sample_analysis': sample_info,
        'compatibility': compatibility,
        'recommendations': []
    }
    
    # ç”Ÿæˆå»ºè®®
    if compatibility['can_extend']:
        report['recommendations'] = [
            "âœ… å¯ä»¥ç›´æ¥ä½¿ç”¨CRWUæ•°æ®é›†ä½œä¸ºæ‰©å±•",
            "âœ… ä½¿ç”¨ç°æœ‰çš„æ•°æ®å¤„ç†ç®¡é“å¤„ç†CRWUæ•°æ®",
            "âœ… åˆå¹¶åå¯è·å¾—æ›´å¤§çš„è®­ç»ƒæ•°æ®é›†",
            "âœ… ä¿æŒç›¸åŒçš„ç‰¹å¾æå–å’Œå¤„ç†æµç¨‹"
        ]
    else:
        report['recommendations'] = [
            "âš ï¸ éœ€è¦å…ˆè§£å†³å…¼å®¹æ€§é—®é¢˜",
            "âš ï¸ å¯èƒ½éœ€è¦è°ƒæ•´æ•°æ®å¤„ç†æµç¨‹",
            "âš ï¸ å»ºè®®å…ˆå¤„ç†å°‘é‡æ ·æœ¬éªŒè¯",
            "âš ï¸ ç¡®ä¿æ•°æ®è´¨é‡å’Œä¸€è‡´æ€§"
        ]
    
    # ä¿å­˜æŠ¥å‘Š
    base_path = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/reports")
    
    # JSONæŠ¥å‘Š
    with open(base_path / "crwu_analysis_report.json", 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=str)
    
    # æ–‡æœ¬æŠ¥å‘Š
    with open(base_path / "crwu_analysis_report.txt", 'w', encoding='utf-8') as f:
        f.write("CRWUæ•°æ®é›†åˆ†ææŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        
        f.write("ğŸ“Š æ•°æ®é›†å¯¹æ¯”:\n")
        f.write(f"CRWUæ•°æ®é›†æ€»æ–‡ä»¶æ•°: {sum(stats['count'] for stats in crwu_stats.values())}\n")
        f.write(f"æºåŸŸæ•°æ®é›†æ€»æ–‡ä»¶æ•°: {source_stats['Total']}\n")
        f.write(f"åˆå¹¶åæ€»æ–‡ä»¶æ•°: {sum(stats['count'] for stats in crwu_stats.values()) + source_stats['Total']}\n\n")
        
        f.write("ğŸ“‹ ç±»åˆ«åˆ†å¸ƒå¯¹æ¯”:\n")
        for category in ['12kHz_DE', '12kHz_FE', '48kHz_DE', 'Normal']:
            crwu_count = crwu_stats.get(category, {}).get('count', 0)
            source_count = source_stats.get(category, 0)
            f.write(f"  {category}: CRWU={crwu_count}, æºåŸŸ={source_count}\n")
        
        f.write("\nğŸ”§ å…¼å®¹æ€§è¯„ä¼°:\n")
        if compatibility['can_extend']:
            f.write("âœ… å¯ä»¥ä½œä¸ºæ‰©å±•æ•°æ®é›†ä½¿ç”¨\n")
        else:
            f.write("âš ï¸ éœ€è¦å¤„ç†å…¼å®¹æ€§é—®é¢˜\n")
            for issue in compatibility['issues']:
                f.write(f"  - {issue}\n")
        
        f.write("\nğŸ“ å»ºè®®:\n")
        for rec in report['recommendations']:
            f.write(f"  {rec}\n")
    
    print(f"\nğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°:")
    print(f"  - crwu_analysis_report.json")
    print(f"  - crwu_analysis_report.txt")

def main():
    """ä¸»å‡½æ•°"""
    print("CRWUæ•°æ®é›†åˆ†æå·¥å…·")
    print("=" * 60)
    
    # åˆ†æCRWUæ•°æ®é›†
    crwu_stats, total_files = analyze_crwu_dataset()
    
    # åˆ†ææ ·æœ¬æ–‡ä»¶
    sample_info = analyze_sample_files(crwu_stats)
    
    # ä¸æºåŸŸæ•°æ®é›†å¯¹æ¯”
    source_stats = compare_with_source_dataset()
    
    # å…¼å®¹æ€§è¯„ä¼°
    compatibility = evaluate_compatibility(crwu_stats, source_stats, sample_info)
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_crwu_report(crwu_stats, source_stats, sample_info, compatibility)

if __name__ == "__main__":
    main()
