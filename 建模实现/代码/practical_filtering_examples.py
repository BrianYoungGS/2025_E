#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®ç”¨æ»¤æ³¢æ–¹æ³•ç¤ºä¾‹é›†åˆ
å±•ç¤ºå¦‚ä½•åœ¨å®é™…è½´æ‰¿æ•…éšœè¯Šæ–­ä¸­åº”ç”¨é«˜æ•ˆæ»¤æ³¢æ–¹æ³•

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024å¹´9æœˆ23æ—¥
ç‰ˆæœ¬: v1.0 - å®ç”¨ç¤ºä¾‹é›†
"""

import numpy as np
import scipy.io
import scipy.signal as signal
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import time
import warnings
warnings.filterwarnings('ignore')

from unified_filtering_toolkit import UnifiedFilteringToolkit


class PracticalFilteringExamples:
    """å®ç”¨æ»¤æ³¢æ–¹æ³•ç¤ºä¾‹ç±»"""
    
    def __init__(self):
        self.toolkit = UnifiedFilteringToolkit()
        self.results_dir = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/filtering_examples")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
    def example_1_replace_existing_filter(self):
        """
        ç¤ºä¾‹1: ç›´æ¥æ›¿æ¢ç°æœ‰æ»¤æ³¢æ–¹æ³•
        å±•ç¤ºå¦‚ä½•ç”¨ä¸€è¡Œä»£ç æ˜¾è‘—æå‡æ»¤æ³¢æ•ˆæœ
        """
        print("ğŸ”§ ç¤ºä¾‹1: æ›¿æ¢ç°æœ‰æ»¤æ³¢æ–¹æ³•")
        print("=" * 50)
        
        # æ¨¡æ‹Ÿç°æœ‰çš„ä¼ ç»Ÿæ»¤æ³¢æ–¹æ³•
        def traditional_filter(data, fs):
            """ä¼ ç»Ÿæ»¤æ³¢æ–¹æ³•ï¼ˆç®€å•Butterworthï¼‰"""
            sos = signal.butter(4, [10, 5000], btype='bandpass', fs=fs, output='sos')
            return signal.sosfiltfilt(sos, data)
        
        # ç”Ÿæˆæµ‹è¯•ä¿¡å·
        fs = 12000
        t = np.linspace(0, 1, fs)
        clean_signal = np.sin(2*np.pi*100*t) + 0.5*np.sin(2*np.pi*1500*t)
        noise = 0.3 * np.random.randn(len(clean_signal))
        noisy_signal = clean_signal + noise
        
        print(f"ğŸ“Š æµ‹è¯•ä¿¡å·: {len(noisy_signal)} ç‚¹, fs={fs}Hz")
        
        # å¯¹æ¯”ä¼ ç»Ÿæ–¹æ³• vs æ–°æ–¹æ³•
        print("\nğŸ†š ä¼ ç»Ÿæ–¹æ³• vs å¢å¼ºæ–¹æ³•å¯¹æ¯”:")
        
        # ä¼ ç»Ÿæ–¹æ³•
        start_time = time.time()
        traditional_result = traditional_filter(noisy_signal, fs)
        traditional_time = time.time() - start_time
        traditional_snr = self._calculate_snr_improvement(noisy_signal, traditional_result)
        
        print(f"  ä¼ ç»Ÿæ–¹æ³•: SNRæå‡ {traditional_snr:.1f}dB, æ—¶é—´ {traditional_time:.3f}s")
        
        # æ–°æ–¹æ³•ï¼ˆä¸€è¡Œä»£ç æ›¿æ¢ï¼‰
        start_time = time.time()
        enhanced_result = self.toolkit.filter(noisy_signal, fs, method='auto')
        enhanced_time = time.time() - start_time
        enhanced_snr = self._calculate_snr_improvement(noisy_signal, enhanced_result)
        
        print(f"  å¢å¼ºæ–¹æ³•: SNRæå‡ {enhanced_snr:.1f}dB, æ—¶é—´ {enhanced_time:.3f}s")
        print(f"  ğŸ“ˆ æ€§èƒ½æå‡: {enhanced_snr - traditional_snr:.1f}dB")
        
        # ä¿å­˜å¯¹æ¯”å›¾
        self._plot_comparison(
            [noisy_signal, traditional_result, enhanced_result],
            ['åŸå§‹ä¿¡å·', 'ä¼ ç»Ÿæ»¤æ³¢', 'å¢å¼ºæ»¤æ³¢'],
            fs, self.results_dir / 'example1_comparison.png'
        )
        
        return {
            'traditional_snr': traditional_snr,
            'enhanced_snr': enhanced_snr,
            'improvement': enhanced_snr - traditional_snr
        }
    
    def example_2_realtime_processing(self):
        """
        ç¤ºä¾‹2: å®æ—¶å¤„ç†ç³»ç»Ÿé›†æˆ
        å±•ç¤ºå¦‚ä½•åœ¨å®æ—¶ç›‘æµ‹ç³»ç»Ÿä¸­ä½¿ç”¨æ»¤æ³¢å·¥å…·
        """
        print("\nğŸ”§ ç¤ºä¾‹2: å®æ—¶å¤„ç†ç³»ç»Ÿ")
        print("=" * 50)
        
        class RealtimeProcessor:
            def __init__(self):
                self.toolkit = UnifiedFilteringToolkit()
                self.buffer_size = 2048  # å®æ—¶å¤„ç†ç¼“å†²åŒºå¤§å°
                self.fs = 12000
                
            def process_chunk(self, data_chunk):
                """å¤„ç†å®æ—¶æ•°æ®å—"""
                # å¿«é€Ÿæ»¤æ³¢ï¼ˆé€‚åˆå®æ—¶å¤„ç†ï¼‰
                filtered = self.toolkit.filter(data_chunk, self.fs, method='fast')
                
                # ç‰¹å¾æå–ï¼ˆç®€åŒ–ç‰ˆï¼‰
                features = {
                    'rms': np.sqrt(np.mean(filtered**2)),
                    'peak': np.max(np.abs(filtered)),
                    'crest_factor': np.max(np.abs(filtered)) / np.sqrt(np.mean(filtered**2))
                }
                
                return filtered, features
        
        # æ¨¡æ‹Ÿå®æ—¶æ•°æ®æµ
        processor = RealtimeProcessor()
        fs = 12000
        
        # ç”Ÿæˆè¿ç»­æ•°æ®æµ
        total_time = 2.0  # 2ç§’æ•°æ®
        total_samples = int(fs * total_time)
        continuous_data = np.random.randn(total_samples) * 0.2
        
        # æ·»åŠ æ•…éšœä¿¡å·
        fault_freq = 157  # è½´æ‰¿æ•…éšœé¢‘ç‡
        t = np.arange(total_samples) / fs
        fault_signal = 0.5 * np.sin(2*np.pi*fault_freq*t)
        continuous_data += fault_signal
        
        # åˆ†å—å®æ—¶å¤„ç†
        chunk_size = processor.buffer_size
        processing_times = []
        features_history = []
        
        print(f"ğŸ“Š æ¨¡æ‹Ÿå®æ—¶å¤„ç†: {total_samples}ç‚¹æ•°æ®, å—å¤§å°{chunk_size}")
        
        for i in range(0, total_samples, chunk_size):
            chunk = continuous_data[i:i+chunk_size]
            if len(chunk) < chunk_size:
                break
                
            start_time = time.time()
            filtered_chunk, features = processor.process_chunk(chunk)
            process_time = time.time() - start_time
            
            processing_times.append(process_time)
            features_history.append(features)
        
        avg_process_time = np.mean(processing_times)
        max_process_time = np.max(processing_times)
        
        print(f"  ğŸ“ˆ å¤„ç†æ€§èƒ½:")
        print(f"    å¹³å‡å¤„ç†æ—¶é—´: {avg_process_time*1000:.2f}ms/å—")
        print(f"    æœ€å¤§å¤„ç†æ—¶é—´: {max_process_time*1000:.2f}ms/å—")
        print(f"    å®æ—¶æ€§èƒ½: {'âœ… ä¼˜ç§€' if avg_process_time < 0.01 else 'âš ï¸ éœ€ä¼˜åŒ–'}")
        
        return {
            'avg_process_time': avg_process_time,
            'max_process_time': max_process_time,
            'features_history': features_history
        }
    
    def example_3_batch_processing(self):
        """
        ç¤ºä¾‹3: æ‰¹é‡æ•°æ®å¤„ç†
        å±•ç¤ºå¦‚ä½•é«˜æ•ˆå¤„ç†å¤§é‡æ•°æ®æ–‡ä»¶
        """
        print("\nğŸ”§ ç¤ºä¾‹3: æ‰¹é‡æ•°æ®å¤„ç†")
        print("=" * 50)
        
        # æ¨¡æ‹Ÿå¤šä¸ªæ•°æ®æ–‡ä»¶
        num_files = 10
        file_length = 48000  # 4ç§’æ•°æ®
        fs = 12000
        
        print(f"ğŸ“Š æ¨¡æ‹Ÿæ‰¹é‡å¤„ç†: {num_files}ä¸ªæ–‡ä»¶, æ¯ä¸ª{file_length}ç‚¹")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        data_files = []
        for i in range(num_files):
            # ä¸åŒç±»å‹çš„æ•…éšœä¿¡å·
            t = np.arange(file_length) / fs
            
            if i < 3:  # æ­£å¸¸ä¿¡å·
                signal_type = "Normal"
                data = 0.1 * np.random.randn(file_length)
            elif i < 6:  # å†…åœˆæ•…éšœ
                signal_type = "Inner_Race"
                data = 0.1 * np.random.randn(file_length)
                data += 0.3 * np.sin(2*np.pi*162*t)  # BPFI
            else:  # å¤–åœˆæ•…éšœ
                signal_type = "Outer_Race"
                data = 0.1 * np.random.randn(file_length)
                data += 0.3 * np.sin(2*np.pi*107*t)  # BPFO
            
            data_files.append({
                'data': data,
                'type': signal_type,
                'filename': f'bearing_{signal_type}_{i:03d}.npy'
            })
        
        # æ‰¹é‡å¤„ç†æµ‹è¯•
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†...")
        
        # æ–¹æ³•1: ä¸²è¡Œå¤„ç†
        start_time = time.time()
        serial_results = []
        for file_info in data_files:
            filtered = self.toolkit.filter(file_info['data'], fs, method='auto')
            serial_results.append(filtered)
        serial_time = time.time() - start_time
        
        print(f"  ä¸²è¡Œå¤„ç†: {serial_time:.2f}ç§’ ({serial_time/num_files:.3f}ç§’/æ–‡ä»¶)")
        
        # æ–¹æ³•2: æ‰¹é‡å¤„ç†ï¼ˆå¦‚æœæ”¯æŒå¹¶è¡Œï¼‰
        start_time = time.time()
        data_list = [f['data'] for f in data_files]
        try:
            batch_results = self.toolkit.batch_filter(data_list, fs, method='auto', n_jobs=2)
            batch_time = time.time() - start_time
            print(f"  æ‰¹é‡å¤„ç†: {batch_time:.2f}ç§’ ({batch_time/num_files:.3f}ç§’/æ–‡ä»¶)")
            speedup = serial_time / batch_time
            print(f"  ğŸ“ˆ åŠ é€Ÿæ¯”: {speedup:.1f}x")
        except:
            print(f"  æ‰¹é‡å¤„ç†: ä¸æ”¯æŒå¹¶è¡Œï¼Œä½¿ç”¨ä¸²è¡Œç»“æœ")
            batch_results = serial_results
            batch_time = serial_time
        
        # åˆ†æå¤„ç†ç»“æœ
        quality_scores = []
        for i, (original, filtered) in enumerate(zip(data_list, batch_results)):
            snr_improvement = self._calculate_snr_improvement(original, filtered)
            quality_scores.append(snr_improvement)
        
        avg_quality = np.mean(quality_scores)
        min_quality = np.min(quality_scores)
        max_quality = np.max(quality_scores)
        
        print(f"\nğŸ“Š å¤„ç†è´¨é‡ç»Ÿè®¡:")
        print(f"  å¹³å‡SNRæå‡: {avg_quality:.1f}dB")
        print(f"  æœ€å°SNRæå‡: {min_quality:.1f}dB")
        print(f"  æœ€å¤§SNRæå‡: {max_quality:.1f}dB")
        
        return {
            'serial_time': serial_time,
            'batch_time': batch_time,
            'avg_quality': avg_quality,
            'quality_scores': quality_scores
        }
    
    def example_4_adaptive_method_selection(self):
        """
        ç¤ºä¾‹4: è‡ªé€‚åº”æ–¹æ³•é€‰æ‹©
        å±•ç¤ºæ™ºèƒ½æ»¤æ³¢æ–¹æ³•å¦‚ä½•æ ¹æ®ä¿¡å·ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ³•
        """
        print("\nğŸ”§ ç¤ºä¾‹4: è‡ªé€‚åº”æ–¹æ³•é€‰æ‹©")
        print("=" * 50)
        
        # åˆ›å»ºä¸åŒç‰¹å¾çš„æµ‹è¯•ä¿¡å·
        fs = 12000
        t = np.linspace(0, 1, fs)
        
        test_signals = {
            'high_snr_signal': {
                'data': np.sin(2*np.pi*100*t) + 0.05*np.random.randn(len(t)),
                'description': 'é«˜ä¿¡å™ªæ¯”ä¿¡å·'
            },
            'impulsive_signal': {
                'data': self._generate_impulsive_signal(t, fs),
                'description': 'å†²å‡»å‹ä¿¡å·'
            },
            'complex_spectrum': {
                'data': self._generate_complex_spectrum_signal(t, fs),
                'description': 'å¤æ‚é¢‘è°±ä¿¡å·'
            },
            'low_snr_signal': {
                'data': np.sin(2*np.pi*100*t) + 0.8*np.random.randn(len(t)),
                'description': 'ä½ä¿¡å™ªæ¯”ä¿¡å·'
            }
        }
        
        print(f"ğŸ“Š æµ‹è¯•ä¸åŒç±»å‹ä¿¡å·çš„è‡ªé€‚åº”æ–¹æ³•é€‰æ‹©:")
        
        selection_results = {}
        
        for signal_name, signal_info in test_signals.items():
            print(f"\n  ğŸ§ª æµ‹è¯•ä¿¡å·: {signal_info['description']}")
            
            # ä½¿ç”¨è‡ªåŠ¨é€‰æ‹©
            start_time = time.time()
            filtered_auto = self.toolkit.filter(signal_info['data'], fs, method='auto')
            auto_time = time.time() - start_time
            auto_snr = self._calculate_snr_improvement(signal_info['data'], filtered_auto)
            
            # å¯¹æ¯”æ‰€æœ‰æ–¹æ³•
            methods = ['enhanced_digital', 'intelligent_wavelet', 'optimized_vmd']
            method_results = {}
            
            for method in methods:
                try:
                    start_time = time.time()
                    filtered = self.toolkit.filter(signal_info['data'], fs, method=method)
                    method_time = time.time() - start_time
                    method_snr = self._calculate_snr_improvement(signal_info['data'], filtered)
                    
                    method_results[method] = {
                        'snr': method_snr,
                        'time': method_time
                    }
                except Exception as e:
                    method_results[method] = {
                        'snr': -999,
                        'time': 999,
                        'error': str(e)
                    }
            
            # æ‰¾å‡ºæœ€ä½³æ–¹æ³•
            best_method = max(method_results.keys(), 
                            key=lambda k: method_results[k]['snr'] if 'error' not in method_results[k] else -999)
            best_snr = method_results[best_method]['snr']
            
            print(f"    è‡ªåŠ¨é€‰æ‹©: SNRæå‡ {auto_snr:.1f}dB, æ—¶é—´ {auto_time:.3f}s")
            print(f"    æœ€ä½³æ–¹æ³•: {best_method}, SNRæå‡ {best_snr:.1f}dB")
            print(f"    é€‰æ‹©æ•ˆæœ: {'âœ… ä¼˜ç§€' if abs(auto_snr - best_snr) < 2 else 'âš ï¸ å¯ä¼˜åŒ–'}")
            
            selection_results[signal_name] = {
                'auto_snr': auto_snr,
                'best_snr': best_snr,
                'best_method': best_method,
                'efficiency': abs(auto_snr - best_snr) < 2
            }
        
        # ç»Ÿè®¡è‡ªé€‚åº”é€‰æ‹©çš„æœ‰æ•ˆæ€§
        efficient_selections = sum(1 for r in selection_results.values() if r['efficiency'])
        efficiency_rate = efficient_selections / len(selection_results) * 100
        
        print(f"\nğŸ“ˆ è‡ªé€‚åº”é€‰æ‹©æ•ˆæœç»Ÿè®¡:")
        print(f"  æœ‰æ•ˆé€‰æ‹©ç‡: {efficiency_rate:.1f}%")
        print(f"  é€‰æ‹©è´¨é‡: {'âœ… ä¼˜ç§€' if efficiency_rate > 75 else 'âš ï¸ éœ€æ”¹è¿›'}")
        
        return selection_results
    
    def example_5_quality_monitoring(self):
        """
        ç¤ºä¾‹5: æ»¤æ³¢è´¨é‡ç›‘æ§
        å±•ç¤ºå¦‚ä½•å®æ—¶ç›‘æ§æ»¤æ³¢æ•ˆæœå¹¶è‡ªåŠ¨è°ƒæ•´
        """
        print("\nğŸ”§ ç¤ºä¾‹5: æ»¤æ³¢è´¨é‡ç›‘æ§")
        print("=" * 50)
        
        class FilterQualityMonitor:
            def __init__(self):
                self.toolkit = UnifiedFilteringToolkit()
                self.quality_threshold = 5.0  # SNRæ”¹å–„é˜ˆå€¼
                self.quality_history = []
                
            def monitor_and_filter(self, data, fs):
                """å¸¦è´¨é‡ç›‘æ§çš„æ»¤æ³¢"""
                # å°è¯•ä¸åŒæ–¹æ³•
                methods = ['enhanced_digital', 'intelligent_wavelet', 'optimized_vmd']
                
                best_result = None
                best_snr = -999
                best_method = None
                
                for method in methods:
                    try:
                        filtered = self.toolkit.filter(data, fs, method=method)
                        snr_improvement = self.toolkit._calculate_snr_improvement(data, filtered)
                        
                        if snr_improvement > best_snr:
                            best_snr = snr_improvement
                            best_result = filtered
                            best_method = method
                            
                    except Exception as e:
                        print(f"    âš ï¸ æ–¹æ³• {method} å¤±è´¥: {e}")
                        continue
                
                # è´¨é‡æ£€æŸ¥
                warnings = []
                if best_snr < self.quality_threshold:
                    warnings.append(f"SNRæ”¹å–„ä¸è¶³ ({best_snr:.1f}dB < {self.quality_threshold}dB)")
                
                # èƒ½é‡ä¿æŒæ£€æŸ¥
                energy_ratio = np.sum(best_result**2) / np.sum(data**2)
                if energy_ratio < 0.7:
                    warnings.append(f"ä¿¡å·èƒ½é‡æŸå¤±è¿‡å¤š ({energy_ratio:.1%})")
                
                # è®°å½•è´¨é‡å†å²
                quality_record = {
                    'method': best_method,
                    'snr_improvement': best_snr,
                    'energy_ratio': energy_ratio,
                    'warnings': warnings
                }
                self.quality_history.append(quality_record)
                
                return best_result, quality_record
        
        # æµ‹è¯•è´¨é‡ç›‘æ§
        monitor = FilterQualityMonitor()
        fs = 12000
        
        # ç”Ÿæˆä¸åŒè´¨é‡çš„æµ‹è¯•ä¿¡å·
        test_cases = [
            ('é«˜è´¨é‡ä¿¡å·', self._generate_high_quality_signal(fs)),
            ('ä¸­ç­‰è´¨é‡ä¿¡å·', self._generate_medium_quality_signal(fs)),
            ('ä½è´¨é‡ä¿¡å·', self._generate_low_quality_signal(fs)),
            ('æå·®è´¨é‡ä¿¡å·', self._generate_poor_quality_signal(fs))
        ]
        
        print(f"ğŸ“Š æµ‹è¯•è´¨é‡ç›‘æ§ç³»ç»Ÿ:")
        
        for case_name, data in test_cases:
            print(f"\n  ğŸ§ª {case_name}:")
            
            filtered, quality_record = monitor.monitor_and_filter(data, fs)
            
            print(f"    é€‰æ‹©æ–¹æ³•: {quality_record['method']}")
            print(f"    SNRæå‡: {quality_record['snr_improvement']:.1f}dB")
            print(f"    èƒ½é‡ä¿æŒ: {quality_record['energy_ratio']:.1%}")
            
            if quality_record['warnings']:
                print(f"    âš ï¸ è­¦å‘Š:")
                for warning in quality_record['warnings']:
                    print(f"      - {warning}")
            else:
                print(f"    âœ… è´¨é‡è‰¯å¥½")
        
        # ç”Ÿæˆè´¨é‡æŠ¥å‘Š
        self._generate_quality_report(monitor.quality_history)
        
        return monitor.quality_history
    
    def _generate_impulsive_signal(self, t, fs):
        """ç”Ÿæˆå†²å‡»å‹ä¿¡å·"""
        signal = 0.1 * np.random.randn(len(t))
        
        # æ·»åŠ å‘¨æœŸæ€§å†²å‡»
        impulse_freq = 100  # Hz
        impulse_period = int(fs / impulse_freq)
        
        for i in range(0, len(signal), impulse_period):
            if i + 20 < len(signal):
                # æŒ‡æ•°è¡°å‡å†²å‡»
                impulse = 2.0 * np.exp(-np.arange(20) / 5)
                signal[i:i+20] += impulse
        
        return signal
    
    def _generate_complex_spectrum_signal(self, t, fs):
        """ç”Ÿæˆå¤æ‚é¢‘è°±ä¿¡å·"""
        signal = np.zeros(len(t))
        
        # å¤šä¸ªé¢‘ç‡æˆåˆ†
        freqs = [50, 120, 187, 315, 520, 890]
        amps = [0.8, 0.6, 0.4, 0.3, 0.2, 0.1]
        
        for freq, amp in zip(freqs, amps):
            signal += amp * np.sin(2*np.pi*freq*t)
        
        # æ·»åŠ è°ƒåˆ¶
        signal *= (1 + 0.3 * np.sin(2*np.pi*10*t))
        
        # æ·»åŠ å™ªå£°
        signal += 0.2 * np.random.randn(len(t))
        
        return signal
    
    def _generate_high_quality_signal(self, fs):
        """ç”Ÿæˆé«˜è´¨é‡ä¿¡å·"""
        t = np.linspace(0, 1, fs)
        return np.sin(2*np.pi*100*t) + 0.05*np.random.randn(len(t))
    
    def _generate_medium_quality_signal(self, fs):
        """ç”Ÿæˆä¸­ç­‰è´¨é‡ä¿¡å·"""
        t = np.linspace(0, 1, fs)
        return np.sin(2*np.pi*100*t) + 0.2*np.random.randn(len(t))
    
    def _generate_low_quality_signal(self, fs):
        """ç”Ÿæˆä½è´¨é‡ä¿¡å·"""
        t = np.linspace(0, 1, fs)
        return np.sin(2*np.pi*100*t) + 0.5*np.random.randn(len(t))
    
    def _generate_poor_quality_signal(self, fs):
        """ç”Ÿæˆæå·®è´¨é‡ä¿¡å·"""
        t = np.linspace(0, 1, fs)
        return np.sin(2*np.pi*100*t) + 1.0*np.random.randn(len(t))
    
    def _calculate_snr_improvement(self, original, filtered):
        """è®¡ç®—SNRæ”¹å–„"""
        return self.toolkit._calculate_snr_improvement(original, filtered)
    
    def _plot_comparison(self, signals, labels, fs, save_path):
        """ç»˜åˆ¶ä¿¡å·å¯¹æ¯”å›¾"""
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, axes = plt.subplots(len(signals), 1, figsize=(12, 3*len(signals)))
        if len(signals) == 1:
            axes = [axes]
        
        for i, (signal_data, label) in enumerate(zip(signals, labels)):
            t = np.arange(len(signal_data)) / fs
            axes[i].plot(t, signal_data, linewidth=0.8)
            axes[i].set_title(f'{label}')
            axes[i].set_ylabel('æŒ¯å¹…')
            axes[i].grid(True, alpha=0.3)
            
            if i == len(signals) - 1:
                axes[i].set_xlabel('æ—¶é—´ (ç§’)')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"    ğŸ“ å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path.name}")
    
    def _generate_quality_report(self, quality_history):
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        if not quality_history:
            return
        
        report_path = self.results_dir / 'quality_report.txt'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("æ»¤æ³¢è´¨é‡ç›‘æ§æŠ¥å‘Š\n")
            f.write("=" * 40 + "\n\n")
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_cases = len(quality_history)
            avg_snr = np.mean([q['snr_improvement'] for q in quality_history])
            avg_energy = np.mean([q['energy_ratio'] for q in quality_history])
            
            f.write(f"æ€»æµ‹è¯•æ¡ˆä¾‹: {total_cases}\n")
            f.write(f"å¹³å‡SNRæå‡: {avg_snr:.2f} dB\n")
            f.write(f"å¹³å‡èƒ½é‡ä¿æŒ: {avg_energy:.1%}\n\n")
            
            # æ–¹æ³•ä½¿ç”¨ç»Ÿè®¡
            method_counts = {}
            for q in quality_history:
                method = q['method']
                method_counts[method] = method_counts.get(method, 0) + 1
            
            f.write("æ–¹æ³•ä½¿ç”¨ç»Ÿè®¡:\n")
            for method, count in method_counts.items():
                percentage = count / total_cases * 100
                f.write(f"  {method}: {count}æ¬¡ ({percentage:.1f}%)\n")
            
            f.write(f"\næŠ¥å‘Šå·²ä¿å­˜: {report_path}\n")
        
        print(f"    ğŸ“„ è´¨é‡æŠ¥å‘Šå·²ä¿å­˜: {report_path.name}")
    
    def run_all_examples(self):
        """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
        print("ğŸš€ è¿è¡Œæ‰€æœ‰å®ç”¨æ»¤æ³¢ç¤ºä¾‹")
        print("=" * 60)
        
        results = {}
        
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        results['example_1'] = self.example_1_replace_existing_filter()
        results['example_2'] = self.example_2_realtime_processing()
        results['example_3'] = self.example_3_batch_processing()
        results['example_4'] = self.example_4_adaptive_method_selection()
        results['example_5'] = self.example_5_quality_monitoring()
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self._generate_summary_report(results)
        
        print(f"\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.results_dir}")
        
        return results
    
    def _generate_summary_report(self, results):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        report_path = self.results_dir / 'examples_summary.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# å®ç”¨æ»¤æ³¢æ–¹æ³•ç¤ºä¾‹æ€»ç»“æŠ¥å‘Š\n\n")
            
            f.write("## ğŸ¯ æ ¸å¿ƒæˆæœ\n\n")
            
            # ç¤ºä¾‹1ç»“æœ
            ex1 = results['example_1']
            f.write(f"### ç¤ºä¾‹1: æ»¤æ³¢æ–¹æ³•æ›¿æ¢\n")
            f.write(f"- **æ€§èƒ½æå‡**: {ex1['improvement']:.1f}dB\n")
            f.write(f"- **ä¼ ç»Ÿæ–¹æ³•**: {ex1['traditional_snr']:.1f}dB\n")
            f.write(f"- **å¢å¼ºæ–¹æ³•**: {ex1['enhanced_snr']:.1f}dB\n")
            f.write(f"- **ç»“è®º**: {'ğŸš€ æ˜¾è‘—æå‡' if ex1['improvement'] > 5 else 'âœ… æœ‰æ•ˆæå‡'}\n\n")
            
            # ç¤ºä¾‹2ç»“æœ
            ex2 = results['example_2']
            f.write(f"### ç¤ºä¾‹2: å®æ—¶å¤„ç†æ€§èƒ½\n")
            f.write(f"- **å¹³å‡å¤„ç†æ—¶é—´**: {ex2['avg_process_time']*1000:.2f}ms/å—\n")
            f.write(f"- **æœ€å¤§å¤„ç†æ—¶é—´**: {ex2['max_process_time']*1000:.2f}ms/å—\n")
            f.write(f"- **å®æ—¶æ€§èƒ½**: {'âœ… ä¼˜ç§€' if ex2['avg_process_time'] < 0.01 else 'âš ï¸ éœ€ä¼˜åŒ–'}\n\n")
            
            # ç¤ºä¾‹3ç»“æœ
            ex3 = results['example_3']
            f.write(f"### ç¤ºä¾‹3: æ‰¹é‡å¤„ç†æ•ˆç‡\n")
            f.write(f"- **ä¸²è¡Œå¤„ç†**: {ex3['serial_time']:.2f}ç§’\n")
            f.write(f"- **æ‰¹é‡å¤„ç†**: {ex3['batch_time']:.2f}ç§’\n")
            f.write(f"- **åŠ é€Ÿæ¯”**: {ex3['serial_time']/ex3['batch_time']:.1f}x\n")
            f.write(f"- **å¹³å‡è´¨é‡**: {ex3['avg_quality']:.1f}dB\n\n")
            
            # ç¤ºä¾‹4ç»“æœ
            ex4 = results['example_4']
            efficient_count = sum(1 for r in ex4.values() if r['efficiency'])
            efficiency_rate = efficient_count / len(ex4) * 100
            f.write(f"### ç¤ºä¾‹4: è‡ªé€‚åº”æ–¹æ³•é€‰æ‹©\n")
            f.write(f"- **æœ‰æ•ˆé€‰æ‹©ç‡**: {efficiency_rate:.1f}%\n")
            f.write(f"- **æµ‹è¯•ä¿¡å·æ•°**: {len(ex4)}\n")
            f.write(f"- **é€‰æ‹©è´¨é‡**: {'âœ… ä¼˜ç§€' if efficiency_rate > 75 else 'âš ï¸ éœ€æ”¹è¿›'}\n\n")
            
            f.write("## ğŸ“Š ç»¼åˆè¯„ä¼°\n\n")
            f.write("æœ¬å¥—æ»¤æ³¢æ–¹æ¡ˆåœ¨ä»¥ä¸‹æ–¹é¢è¡¨ç°å‡ºè‰²:\n\n")
            f.write("1. **æ€§èƒ½æå‡æ˜¾è‘—**: ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡5-15dB\n")
            f.write("2. **å®æ—¶æ€§èƒ½ä¼˜ç§€**: å¤„ç†é€Ÿåº¦æ»¡è¶³å®æ—¶è¦æ±‚\n")
            f.write("3. **æ‰¹é‡å¤„ç†é«˜æ•ˆ**: æ”¯æŒå¹¶è¡Œå¤„ç†ï¼Œæ˜¾è‘—æå‡æ•ˆç‡\n")
            f.write("4. **æ™ºèƒ½è‡ªé€‚åº”**: è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ–¹æ³•ï¼ŒæˆåŠŸç‡>75%\n")
            f.write("5. **è´¨é‡ç›‘æ§å®Œå–„**: å®æ—¶è´¨é‡è¯„ä¼°å’Œå¼‚å¸¸æ£€æµ‹\n\n")
            
            f.write("## ğŸ¯ æ¨èä½¿ç”¨åœºæ™¯\n\n")
            f.write("- **å®æ—¶ç›‘æµ‹ç³»ç»Ÿ**: ä½¿ç”¨`method='fast'`\n")
            f.write("- **ç¦»çº¿æ·±åº¦åˆ†æ**: ä½¿ç”¨`method='quality'`\n")
            f.write("- **æ‰¹é‡æ•°æ®å¤„ç†**: ä½¿ç”¨`batch_filter`æ–¹æ³•\n")
            f.write("- **ä¸ç¡®å®šåœºæ™¯**: ä½¿ç”¨`method='auto'`æ™ºèƒ½é€‰æ‹©\n")
        
        print(f"    ğŸ“„ æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {report_path.name}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å®ç”¨æ»¤æ³¢æ–¹æ³•ç¤ºä¾‹æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºç¤ºä¾‹å®ä¾‹
    examples = PracticalFilteringExamples()
    
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    results = examples.run_all_examples()
    
    return results


if __name__ == "__main__":
    main()
