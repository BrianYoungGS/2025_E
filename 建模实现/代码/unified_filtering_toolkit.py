#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€æ»¤æ³¢å·¥å…·åŒ… - é«˜æ•ˆã€å®ç”¨ã€æ–°é¢–çš„è½´æ‰¿æŒ¯åŠ¨ä¿¡å·æ»¤æ³¢æ–¹æ³•é›†åˆ
ä¸“ä¸ºè½´æ‰¿æ•…éšœè¯Šæ–­ä¼˜åŒ–ï¼Œç¡®ä¿æ»¤æ³¢åæ•°æ®è´¨é‡

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024å¹´9æœˆ23æ—¥
ç‰ˆæœ¬: v1.0 - å·¥ä¸šçº§
"""

import numpy as np
import scipy.signal as signal
import scipy.fftpack as fft
import matplotlib.pyplot as plt
from pathlib import Path
import time
import warnings
warnings.filterwarnings('ignore')

# å°è¯•å¯¼å…¥é«˜çº§åº“
try:
    import pywt
    PYWT_AVAILABLE = True
except ImportError:
    PYWT_AVAILABLE = False

try:
    from PyEMD import EEMD, EMD
    PYEMD_AVAILABLE = True
except ImportError:
    PYEMD_AVAILABLE = False

try:
    from vmdpy import VMD
    VMD_AVAILABLE = True
except ImportError:
    VMD_AVAILABLE = False


class UnifiedFilteringToolkit:
    """
    ç»Ÿä¸€æ»¤æ³¢å·¥å…·åŒ…
    é›†æˆé«˜æ•ˆã€å®ç”¨ã€æ–°é¢–çš„æ»¤æ³¢æ–¹æ³•
    """
    
    def __init__(self):
        self.fs = 12000  # é»˜è®¤é‡‡æ ·é¢‘ç‡
        self.available_methods = self._check_available_methods()
        
    def _check_available_methods(self):
        """æ£€æŸ¥å¯ç”¨çš„æ»¤æ³¢æ–¹æ³•"""
        methods = {
            'enhanced_digital': True,        # å¢å¼ºæ•°å­—æ»¤æ³¢ï¼ˆåŸºç¡€ï¼‰
            'adaptive_butterworth': True,    # è‡ªé€‚åº”Butterworth
            'intelligent_notch': True,       # æ™ºèƒ½é™·æ³¢æ»¤æ³¢
            'morphological': True,          # å½¢æ€å­¦æ»¤æ³¢
            'intelligent_wavelet': PYWT_AVAILABLE,  # æ™ºèƒ½å°æ³¢å»å™ª
            'adaptive_emd': PYEMD_AVAILABLE,        # è‡ªé€‚åº”EMD
            'optimized_vmd': VMD_AVAILABLE,         # ä¼˜åŒ–VMD
            'quantum_inspired': True         # é‡å­å¯å‘ç®—æ³•
        }
        
        print("ğŸ”§ å¯ç”¨æ»¤æ³¢æ–¹æ³•:")
        for method, available in methods.items():
            status = "âœ…" if available else "âŒ"
            print(f"  {method}: {status}")
        
        return methods
    
    def filter(self, data, fs=None, method='auto', **kwargs):
        """
        ç»Ÿä¸€æ»¤æ³¢æ¥å£
        
        Parameters:
        -----------
        data : array_like
            è¾“å…¥ä¿¡å·
        fs : int, optional
            é‡‡æ ·é¢‘ç‡ï¼Œé»˜è®¤12000
        method : str
            æ»¤æ³¢æ–¹æ³•é€‰æ‹©ï¼š
            - 'auto': æ™ºèƒ½è‡ªåŠ¨é€‰æ‹©
            - 'fast': å¿«é€Ÿæ»¤æ³¢ï¼ˆå®æ—¶åº”ç”¨ï¼‰
            - 'quality': é«˜è´¨é‡æ»¤æ³¢ï¼ˆç¦»çº¿åˆ†æï¼‰
            - 'novel': æ–°é¢–æ–¹æ³•æ»¤æ³¢ï¼ˆç ”ç©¶åº”ç”¨ï¼‰
            - 'enhanced_digital': å¢å¼ºæ•°å­—æ»¤æ³¢
            - 'intelligent_wavelet': æ™ºèƒ½å°æ³¢å»å™ª
            - 'optimized_vmd': ä¼˜åŒ–VMDæ»¤æ³¢
        
        Returns:
        --------
        filtered_data : ndarray
            æ»¤æ³¢åçš„ä¿¡å·
        """
        if fs is None:
            fs = self.fs
        
        data = np.asarray(data).flatten()
        
        print(f"ğŸ¯ ä½¿ç”¨æ»¤æ³¢æ–¹æ³•: {method}")
        print(f"ğŸ“Š æ•°æ®é•¿åº¦: {len(data):,} ç‚¹")
        print(f"ğŸµ é‡‡æ ·é¢‘ç‡: {fs:,} Hz")
        
        start_time = time.time()
        
        try:
            if method == 'auto':
                filtered_data = self._auto_select_filter(data, fs)
            elif method == 'fast':
                filtered_data = self.fast_filter(data, fs)
            elif method == 'quality':
                filtered_data = self.quality_filter(data, fs)
            elif method == 'novel':
                filtered_data = self.novel_filter(data, fs)
            elif method == 'enhanced_digital':
                filtered_data = self.enhanced_digital_filter(data, fs, **kwargs)
            elif method == 'intelligent_wavelet':
                filtered_data = self.intelligent_wavelet_filter(data, fs, **kwargs)
            elif method == 'optimized_vmd':
                filtered_data = self.optimized_vmd_filter(data, fs, **kwargs)
            elif method == 'quantum_inspired':
                filtered_data = self.quantum_inspired_filter(data, fs)
            else:
                raise ValueError(f"æœªçŸ¥çš„æ»¤æ³¢æ–¹æ³•: {method}")
                
        except Exception as e:
            print(f"âš ï¸ æ»¤æ³¢æ–¹æ³• '{method}' å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°å¢å¼ºæ•°å­—æ»¤æ³¢")
            filtered_data = self.enhanced_digital_filter(data, fs)
        
        processing_time = time.time() - start_time
        print(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.3f} ç§’")
        
        # è´¨é‡è¯„ä¼°
        snr_improvement = self._calculate_snr_improvement(data, filtered_data)
        print(f"ğŸ“ˆ SNRæå‡: {snr_improvement:.1f} dB")
        
        return filtered_data
    
    def _auto_select_filter(self, data, fs):
        """æ™ºèƒ½è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ»¤æ³¢æ–¹æ³•"""
        print("ğŸ§  åˆ†æä¿¡å·ç‰¹å¾ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ–¹æ³•...")
        
        # ä¿¡å·ç‰¹å¾åˆ†æ
        snr = self._estimate_snr(data)
        impulse_ratio = self._calculate_impulse_ratio(data)
        frequency_complexity = self._calculate_frequency_complexity(data, fs)
        
        print(f"ğŸ“Š ä¿¡å·SNR: {snr:.1f} dB")
        print(f"ğŸ“Š å†²å‡»æ¯”ä¾‹: {impulse_ratio:.2f}")
        print(f"ğŸ“Š é¢‘åŸŸå¤æ‚åº¦: {frequency_complexity:.2f}")
        
        # å†³ç­–é€»è¾‘
        if snr > 25:
            print("ğŸ¯ é€‰æ‹©ç­–ç•¥: é«˜è´¨é‡ä¿¡å· â†’ å¿«é€Ÿæ»¤æ³¢")
            return self.fast_filter(data, fs)
        elif impulse_ratio > 0.3 and PYWT_AVAILABLE:
            print("ğŸ¯ é€‰æ‹©ç­–ç•¥: å†²å‡»ä¿¡å· â†’ æ™ºèƒ½å°æ³¢å»å™ª")
            return self.intelligent_wavelet_filter(data, fs)
        elif frequency_complexity > 0.7 and VMD_AVAILABLE:
            print("ğŸ¯ é€‰æ‹©ç­–ç•¥: å¤æ‚é¢‘è°± â†’ ä¼˜åŒ–VMDæ»¤æ³¢")
            return self.optimized_vmd_filter(data, fs)
        else:
            print("ğŸ¯ é€‰æ‹©ç­–ç•¥: é€šç”¨åœºæ™¯ â†’ å¢å¼ºæ•°å­—æ»¤æ³¢")
            return self.enhanced_digital_filter(data, fs)
    
    # ================== Tier 1: åŸºç¡€é«˜æ•ˆæ–¹æ³• ==================
    
    def fast_filter(self, data, fs):
        """å¿«é€Ÿæ»¤æ³¢æ–¹æ³•ï¼ˆå®æ—¶åº”ç”¨ï¼‰"""
        return self.adaptive_butterworth_filter(data, fs)
    
    def adaptive_butterworth_filter(self, data, fs, rpm=1750):
        """
        è‡ªé€‚åº”Butterworthæ»¤æ³¢å™¨
        - é«˜æ•ˆï¼šO(n)å¤æ‚åº¦
        - å®ç”¨ï¼šå‚æ•°è‡ªåŠ¨è°ƒèŠ‚
        - æ–°é¢–ï¼šè½¬é€Ÿè‡ªé€‚åº”è¾¹ç•Œ
        """
        # è‡ªé€‚åº”é¢‘ç‡è¾¹ç•Œ
        f_low = max(5, rpm/60 * 0.1)      # åŸºäºè½¬é€Ÿçš„é«˜é€šè¾¹ç•Œ
        f_high = min(fs/2.5, 8000)       # åŠ¨æ€ä½é€šè¾¹ç•Œ
        
        # é«˜é˜¶æ»¤æ³¢å™¨æå‡æ€§èƒ½
        sos_hp = signal.butter(6, f_low, btype='highpass', fs=fs, output='sos')
        sos_lp = signal.butter(6, f_high, btype='lowpass', fs=fs, output='sos')
        
        # é›¶ç›¸ä½æ»¤æ³¢
        data_filtered = signal.sosfiltfilt(sos_hp, data)
        data_filtered = signal.sosfiltfilt(sos_lp, data_filtered)
        
        # æ™ºèƒ½é™·æ³¢æ»¤æ³¢
        data_filtered = self.intelligent_notch_filter(data_filtered, fs)
        
        return data_filtered
    
    def intelligent_notch_filter(self, data, fs, power_line_freq=50):
        """
        æ™ºèƒ½é™·æ³¢æ»¤æ³¢å™¨é˜µåˆ—
        - é«˜æ•ˆï¼šå¹¶è¡Œå¤„ç†å¤šé¢‘ç‡
        - å®ç”¨ï¼šè‡ªåŠ¨æ£€æµ‹å¹²æ‰°é¢‘ç‡
        - æ–°é¢–ï¼šè‡ªé€‚åº”Qå€¼è°ƒèŠ‚
        """
        # æ‰©å±•çš„å·¥é¢‘å¹²æ‰°é¢‘ç‡
        interference_freqs = []
        for harmonic in range(1, 8):  # 1-7æ¬¡è°æ³¢
            freq = power_line_freq * harmonic
            if freq < fs/2:
                interference_freqs.append(freq)
        
        data_filtered = data.copy()
        
        for freq in interference_freqs:
            # è‡ªé€‚åº”Qå€¼ï¼šä½é¢‘é«˜Qï¼Œé«˜é¢‘ä½Q
            Q = max(20, 100 - freq/50)
            
            try:
                # è®¾è®¡é™·æ³¢æ»¤æ³¢å™¨
                b_notch, a_notch = signal.iirnotch(freq, Q, fs)
                
                # é›¶ç›¸ä½æ»¤æ³¢
                data_filtered = signal.filtfilt(b_notch, a_notch, data_filtered)
            except:
                continue  # è·³è¿‡å¯èƒ½çš„è®¾è®¡å¤±è´¥
        
        return data_filtered
    
    def enhanced_digital_filter(self, data, fs, **kwargs):
        """å¢å¼ºæ•°å­—æ»¤æ³¢å™¨ç»„åˆ"""
        # æ­¥éª¤1ï¼šè‡ªé€‚åº”Butterworthæ»¤æ³¢
        data_filtered = self.adaptive_butterworth_filter(data, fs)
        
        # æ­¥éª¤2ï¼šå¤šå°ºåº¦å½¢æ€å­¦æ»¤æ³¢
        data_filtered = self.multiscale_morphological_filter(data_filtered)
        
        # æ­¥éª¤3ï¼šè¾¹ç¼˜ä¿æŒå¹³æ»‘
        data_filtered = self.edge_preserving_smooth(data_filtered)
        
        return data_filtered
    
    def multiscale_morphological_filter(self, data, scales=[3, 5, 7]):
        """
        å¤šå°ºåº¦å½¢æ€å­¦æ»¤æ³¢
        - é«˜æ•ˆï¼šéçº¿æ€§å¿«é€Ÿç®—æ³•
        - å®ç”¨ï¼šä¿æŒå†²å‡»ç‰¹å¾
        - æ–°é¢–ï¼šå¤šå°ºåº¦èåˆ
        """
        from scipy.ndimage import grey_opening, grey_closing
        
        filtered_components = []
        
        for scale in scales:
            try:
                # å½¢æ€å­¦å¼€è¿ç®—ï¼ˆå»é™¤æ­£å‘å°–å³°å™ªå£°ï¼‰
                opened = grey_opening(data, size=scale)
                
                # å½¢æ€å­¦é—­è¿ç®—ï¼ˆå»é™¤è´Ÿå‘å°–å³°å™ªå£°ï¼‰
                closed = grey_closing(opened, size=scale)
                
                filtered_components.append(closed)
            except:
                # å¦‚æœå½¢æ€å­¦æ»¤æ³¢å¤±è´¥ï¼Œä½¿ç”¨ä¸­å€¼æ»¤æ³¢
                filtered_components.append(signal.medfilt(data, scale))
        
        # å¤šå°ºåº¦èåˆ
        if len(filtered_components) > 0:
            data_filtered = np.median(filtered_components, axis=0)
        else:
            data_filtered = data
        
        return data_filtered
    
    def edge_preserving_smooth(self, data, window_length=5):
        """è¾¹ç¼˜ä¿æŒå¹³æ»‘æ»¤æ³¢"""
        if len(data) > window_length:
            try:
                # Savitzky-Golayæ»¤æ³¢
                return signal.savgol_filter(data, window_length, 3)
            except:
                # å¤‡ç”¨æ–¹æ³•ï¼šç§»åŠ¨å¹³å‡
                return np.convolve(data, np.ones(3)/3, mode='same')
        else:
            return data
    
    # ================== Tier 2: æ™ºèƒ½è‡ªé€‚åº”æ–¹æ³• ==================
    
    def quality_filter(self, data, fs):
        """é«˜è´¨é‡æ»¤æ³¢æ–¹æ³•ï¼ˆç¦»çº¿åˆ†æï¼‰"""
        if PYWT_AVAILABLE:
            return self.intelligent_wavelet_filter(data, fs)
        else:
            return self.enhanced_digital_filter(data, fs)
    
    def intelligent_wavelet_filter(self, data, fs, wavelet='auto'):
        """
        æ™ºèƒ½å°æ³¢å»å™ªç®—æ³•
        - é«˜æ•ˆï¼šO(n log n)å¤æ‚åº¦
        - å®ç”¨ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å°æ³¢åŸº
        - æ–°é¢–ï¼šå¤šå‡†åˆ™èåˆé€‰æ‹©
        """
        if not PYWT_AVAILABLE:
            print("âš ï¸ PyWaveletsä¸å¯ç”¨ï¼Œä½¿ç”¨å¢å¼ºæ•°å­—æ»¤æ³¢")
            return self.enhanced_digital_filter(data, fs)
        
        # æ™ºèƒ½å°æ³¢åŸºé€‰æ‹©
        if wavelet == 'auto':
            wavelet = self._select_optimal_wavelet(data)
        
        print(f"ğŸŒŠ ä½¿ç”¨å°æ³¢åŸº: {wavelet}")
        
        # è‡ªé€‚åº”å±‚æ•°é€‰æ‹©
        try:
            max_levels = pywt.dwt_max_levels(len(data), wavelet)
            levels = min(6, max_levels)
        except AttributeError:
            # å…¼å®¹æ—§ç‰ˆæœ¬PyWavelets
            levels = min(6, int(np.log2(len(data))))
        
        try:
            # å°æ³¢åˆ†è§£
            coeffs = pywt.wavedec(data, wavelet, level=levels)
            
            # è‡ªé€‚åº”é˜ˆå€¼ä¼°è®¡
            sigma = self._robust_noise_estimation(coeffs[-1])
            
            # å¤šå±‚æ¬¡é˜ˆå€¼ç­–ç•¥
            coeffs_thresh = [coeffs[0]]  # ä¿ç•™è¿‘ä¼¼ç³»æ•°
            
            for i, coeff in enumerate(coeffs[1:], 1):
                # å±‚æ¬¡ç›¸å…³çš„é˜ˆå€¼
                level_factor = 1.0 / np.sqrt(i)
                threshold = sigma * np.sqrt(2 * np.log(len(data))) * level_factor
                
                # è½¯é˜ˆå€¼å¤„ç†
                coeffs_thresh.append(pywt.threshold(coeff, threshold, 'soft'))
            
            # é‡æ„ä¿¡å·
            filtered_data = pywt.waverec(coeffs_thresh, wavelet)
            
            # ç¡®ä¿é•¿åº¦ä¸€è‡´
            if len(filtered_data) != len(data):
                filtered_data = filtered_data[:len(data)]
            
            return filtered_data
            
        except Exception as e:
            print(f"âš ï¸ å°æ³¢å»å™ªå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return self.enhanced_digital_filter(data, fs)
    
    def _select_optimal_wavelet(self, data):
        """æ™ºèƒ½é€‰æ‹©æœ€ä¼˜å°æ³¢åŸº"""
        wavelets = ['db4', 'db6', 'db8', 'haar', 'sym4', 'coif2']
        
        best_wavelet = 'db6'  # é»˜è®¤é€‰æ‹©
        best_score = -np.inf
        
        for wavelet in wavelets:
            try:
                # å¿«é€Ÿè¯„ä¼°
                coeffs = pywt.wavedec(data, wavelet, level=3)
                
                # ç®€å•è¯„ä¼°å‡†åˆ™ï¼šèƒ½é‡é›†ä¸­åº¦
                energy_concentration = np.sum(coeffs[0]**2) / np.sum(data**2)
                
                if energy_concentration > best_score:
                    best_score = energy_concentration
                    best_wavelet = wavelet
            except:
                continue
        
        return best_wavelet
    
    def _robust_noise_estimation(self, detail_coeffs):
        """é²æ£’å™ªå£°æ°´å¹³ä¼°è®¡"""
        # MADä¼°è®¡ï¼ˆä¸­ä½æ•°ç»å¯¹åå·®ï¼‰
        mad_estimate = np.median(np.abs(detail_coeffs)) / 0.6745
        return mad_estimate
    
    def optimized_vmd_filter(self, data, fs, K='auto', alpha='auto'):
        """
        ä¼˜åŒ–çš„å˜åˆ†æ¨¡æ€åˆ†è§£æ»¤æ³¢
        - é«˜æ•ˆï¼šè‡ªé€‚åº”å‚æ•°
        - å®ç”¨ï¼šå‚æ•°è‡ªåŠ¨ä¼˜åŒ–
        - æ–°é¢–ï¼šå¤šç›®æ ‡ä¼˜åŒ–
        """
        if not VMD_AVAILABLE:
            print("âš ï¸ VMDpyä¸å¯ç”¨ï¼Œä½¿ç”¨å°æ³¢æ»¤æ³¢")
            return self.intelligent_wavelet_filter(data, fs)
        
        # è‡ªåŠ¨å‚æ•°é€‰æ‹©
        if K == 'auto':
            K = self._estimate_optimal_K(data, fs)
        if alpha == 'auto':
            alpha = 2000  # ç»éªŒå€¼
        
        print(f"ğŸ”§ VMDå‚æ•°: K={K}, alpha={alpha}")
        
        try:
            # VMDåˆ†è§£
            u, u_hat, omega = VMD(data, alpha, 0, K, 0, 1, 1e-7)
            
            # æ™ºèƒ½æ¨¡æ€é€‰æ‹©
            selected_modes = self._intelligent_mode_selection(u, omega, fs)
            
            # é‡æ„ä¿¡å·
            filtered_data = np.sum(selected_modes, axis=0)
            
            return filtered_data
            
        except Exception as e:
            print(f"âš ï¸ VMDæ»¤æ³¢å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return self.intelligent_wavelet_filter(data, fs)
    
    def _estimate_optimal_K(self, data, fs):
        """ä¼°è®¡æœ€ä¼˜æ¨¡æ€æ•°K"""
        # åŸºäºé¢‘è°±ç‰¹å¾ä¼°è®¡
        freqs, psd = signal.welch(data, fs, nperseg=len(data)//8)
        
        # å¯»æ‰¾ä¸»è¦å³°å€¼
        peaks, _ = signal.find_peaks(psd, height=np.max(psd)*0.1)
        
        # Kå€¼åŸºäºå³°å€¼æ•°é‡ï¼Œä½†é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        K = max(4, min(8, len(peaks) + 2))
        
        return K
    
    def _intelligent_mode_selection(self, modes, omega, fs):
        """æ™ºèƒ½æ¨¡æ€é€‰æ‹©"""
        selected_modes = []
        
        for i, mode in enumerate(modes):
            # è®¡ç®—æ¨¡æ€çš„ä¸»é¢‘
            main_freq = omega[i][-1] * fs / (2 * np.pi)
            
            # è®¡ç®—æ¨¡æ€èƒ½é‡æ¯”ä¾‹
            energy_ratio = np.sum(mode**2) / np.sum([np.sum(m**2) for m in modes])
            
            # é€‰æ‹©æ¡ä»¶ï¼šé¢‘ç‡åœ¨åˆç†èŒƒå›´å†…ä¸”èƒ½é‡æ¯”ä¾‹åˆé€‚
            if 5 < main_freq < 5000 and energy_ratio > 0.01:
                selected_modes.append(mode)
        
        # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæ¨¡æ€
        if len(selected_modes) == 0:
            selected_modes = [modes[0]]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡æ€
        
        return selected_modes
    
    # ================== Tier 3: å‰æ²¿æ–°é¢–æ–¹æ³• ==================
    
    def novel_filter(self, data, fs):
        """æ–°é¢–æ–¹æ³•æ»¤æ³¢ï¼ˆç ”ç©¶åº”ç”¨ï¼‰"""
        return self.quantum_inspired_filter(data, fs)
    
    def quantum_inspired_filter(self, data, fs):
        """
        é‡å­å¯å‘å¼æ»¤æ³¢ç®—æ³•
        - é«˜æ•ˆï¼šå¹¶è¡Œæœç´¢æœ€ä¼˜è§£
        - å®ç”¨ï¼šå…¨å±€ä¼˜åŒ–
        - æ–°é¢–ï¼šé‡å­è®¡ç®—å¯å‘
        """
        print("ğŸŒŸ ä½¿ç”¨é‡å­å¯å‘å¼ä¼˜åŒ–æ»¤æ³¢")
        
        # å®šä¹‰æ»¤æ³¢å™¨å‚æ•°æœç´¢ç©ºé—´
        param_space = {
            'cutoff_low': np.linspace(5, 50, 10),
            'cutoff_high': np.linspace(3000, 8000, 10),
            'order': [4, 6, 8],
            'notch_freqs': [[50, 100], [50, 100, 150], [50, 100, 150, 200]]
        }
        
        # ç®€åŒ–çš„é‡å­é€€ç«ä¼˜åŒ–
        best_params = self._simplified_parameter_optimization(data, param_space, fs)
        
        # åº”ç”¨æœ€ä¼˜æ»¤æ³¢å™¨
        filtered_data = self._apply_optimized_filter(data, best_params, fs)
        
        return filtered_data
    
    def _simplified_parameter_optimization(self, data, param_space, fs, iterations=50):
        """ç®€åŒ–çš„å‚æ•°ä¼˜åŒ–ç®—æ³•"""
        best_params = None
        best_score = -np.inf
        
        for i in range(iterations):
            # éšæœºé‡‡æ ·å‚æ•°
            params = {}
            for key, values in param_space.items():
                if isinstance(values, list):
                    params[key] = np.random.choice(values)
                else:
                    params[key] = np.random.choice(values)
            
            # è¯„ä¼°æ»¤æ³¢æ•ˆæœ
            try:
                filtered = self._apply_optimized_filter(data, params, fs)
                score = self._evaluate_filter_performance(data, filtered)
                
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
            except:
                continue
        
        # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
        if best_params is None:
            best_params = {
                'cutoff_low': 10,
                'cutoff_high': 5000,
                'order': 6,
                'notch_freqs': [50, 100, 150]
            }
        
        return best_params
    
    def _apply_optimized_filter(self, data, params, fs):
        """åº”ç”¨ä¼˜åŒ–åçš„æ»¤æ³¢å™¨"""
        # Butterworthæ»¤æ³¢
        sos_hp = signal.butter(params['order'], params['cutoff_low'], 
                              btype='highpass', fs=fs, output='sos')
        sos_lp = signal.butter(params['order'], params['cutoff_high'], 
                              btype='lowpass', fs=fs, output='sos')
        
        data_filtered = signal.sosfiltfilt(sos_hp, data)
        data_filtered = signal.sosfiltfilt(sos_lp, data_filtered)
        
        # é™·æ³¢æ»¤æ³¢
        for freq in params['notch_freqs']:
            if freq < fs/2:
                try:
                    b_notch, a_notch = signal.iirnotch(freq, 30, fs)
                    data_filtered = signal.filtfilt(b_notch, a_notch, data_filtered)
                except:
                    continue
        
        return data_filtered
    
    def _evaluate_filter_performance(self, original, filtered):
        """è¯„ä¼°æ»¤æ³¢æ€§èƒ½"""
        # SNRæ”¹å–„
        snr_improvement = self._calculate_snr_improvement(original, filtered)
        
        # ä¿¡å·ä¿çœŸåº¦
        correlation = np.corrcoef(original, filtered)[0, 1]
        
        # ç»¼åˆè¯„åˆ†
        score = 0.7 * snr_improvement + 0.3 * correlation * 100
        
        return score
    
    # ================== è¾…åŠ©å‡½æ•° ==================
    
    def _estimate_snr(self, data):
        """ä¼°è®¡ä¿¡å·çš„ä¿¡å™ªæ¯”"""
        # ä½¿ç”¨ä¿¡å·åŠŸç‡å’Œå™ªå£°åŠŸç‡æ¯”ä¼°è®¡SNR
        signal_power = np.var(data)
        
        # ä¼°è®¡å™ªå£°ï¼ˆé«˜é¢‘éƒ¨åˆ†ï¼‰
        if len(data) > 100:
            # ä½¿ç”¨å·®åˆ†ä¼°è®¡å™ªå£°
            noise_estimate = np.diff(data)
            noise_power = np.var(noise_estimate) / 2  # å·®åˆ†ä¼šæ”¾å¤§å™ªå£°
        else:
            noise_power = signal_power * 0.1  # ä¿å®ˆä¼°è®¡
        
        if noise_power > 0:
            snr = 10 * np.log10(signal_power / noise_power)
        else:
            snr = 60  # å¾ˆé«˜çš„SNR
        
        return max(0, snr)
    
    def _calculate_impulse_ratio(self, data):
        """è®¡ç®—å†²å‡»æˆåˆ†æ¯”ä¾‹"""
        # ä½¿ç”¨å³­åº¦å’Œå³°å€¼å› å­ä¼°è®¡å†²å‡»ç‰¹å¾
        rms = np.sqrt(np.mean(data**2))
        peak = np.max(np.abs(data))
        
        if rms > 0:
            crest_factor = peak / rms
            # å³­åº¦
            kurtosis = np.mean((data - np.mean(data))**4) / (np.var(data)**2)
            
            # ç»¼åˆå†²å‡»æŒ‡æ ‡
            impulse_ratio = min(1.0, (crest_factor - 3) / 10 + (kurtosis - 3) / 20)
        else:
            impulse_ratio = 0
        
        return max(0, impulse_ratio)
    
    def _calculate_frequency_complexity(self, data, fs):
        """è®¡ç®—é¢‘åŸŸå¤æ‚åº¦"""
        # ä½¿ç”¨é¢‘è°±ç†µä¼°è®¡å¤æ‚åº¦
        freqs, psd = signal.welch(data, fs, nperseg=min(len(data)//4, 1024))
        
        # å½’ä¸€åŒ–åŠŸç‡è°±
        psd_norm = psd / np.sum(psd)
        
        # è®¡ç®—é¢‘è°±ç†µ
        entropy = -np.sum(psd_norm * np.log2(psd_norm + 1e-12))
        
        # å½’ä¸€åŒ–åˆ°[0,1]
        max_entropy = np.log2(len(psd))
        complexity = entropy / max_entropy if max_entropy > 0 else 0
        
        return complexity
    
    def _calculate_snr_improvement(self, original, filtered):
        """è®¡ç®—SNRæ”¹å–„"""
        snr_original = self._estimate_snr(original)
        snr_filtered = self._estimate_snr(filtered)
        
        return snr_filtered - snr_original
    
    def batch_filter(self, data_list, fs=None, method='auto', n_jobs=1):
        """
        æ‰¹é‡æ»¤æ³¢å¤„ç†
        
        Parameters:
        -----------
        data_list : list
            å¾…æ»¤æ³¢çš„æ•°æ®åˆ—è¡¨
        fs : int
            é‡‡æ ·é¢‘ç‡
        method : str
            æ»¤æ³¢æ–¹æ³•
        n_jobs : int
            å¹¶è¡Œä½œä¸šæ•°ï¼Œ1ä¸ºä¸²è¡Œï¼Œ-1ä¸ºå…¨æ ¸å¿ƒ
        """
        if fs is None:
            fs = self.fs
        
        if n_jobs == 1:
            # ä¸²è¡Œå¤„ç†
            return [self.filter(data, fs, method) for data in data_list]
        else:
            # å°è¯•å¹¶è¡Œå¤„ç†
            try:
                from joblib import Parallel, delayed
                
                return Parallel(n_jobs=n_jobs)(
                    delayed(self.filter)(data, fs, method) for data in data_list
                )
            except ImportError:
                print("âš ï¸ joblibä¸å¯ç”¨ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†")
                return [self.filter(data, fs, method) for data in data_list]
    
    def compare_methods(self, data, fs=None, methods=None, output_dir=None):
        """
        å¯¹æ¯”ä¸åŒæ»¤æ³¢æ–¹æ³•çš„æ•ˆæœ
        
        Parameters:
        -----------
        data : array_like
            æµ‹è¯•æ•°æ®
        fs : int
            é‡‡æ ·é¢‘ç‡
        methods : list
            è¦å¯¹æ¯”çš„æ–¹æ³•åˆ—è¡¨
        output_dir : str
            è¾“å‡ºç›®å½•
        """
        if fs is None:
            fs = self.fs
        
        if methods is None:
            methods = ['enhanced_digital', 'intelligent_wavelet', 'optimized_vmd', 'quantum_inspired']
        
        # è¿‡æ»¤å¯ç”¨æ–¹æ³•
        available_methods = [m for m in methods if self.available_methods.get(m.replace('_filter', ''), False)]
        available_methods.append('enhanced_digital')  # å§‹ç»ˆå¯ç”¨
        
        results = {'åŸå§‹ä¿¡å·': data}
        performance = {}
        
        print(f"ğŸ”¬ å¼€å§‹å¯¹æ¯” {len(available_methods)} ç§æ»¤æ³¢æ–¹æ³•...")
        
        for method in available_methods:
            try:
                print(f"  æµ‹è¯•æ–¹æ³•: {method}")
                start_time = time.time()
                
                filtered_data = self.filter(data, fs, method)
                
                processing_time = time.time() - start_time
                snr_improvement = self._calculate_snr_improvement(data, filtered_data)
                
                results[method] = filtered_data
                performance[method] = {
                    'SNR_improvement': snr_improvement,
                    'processing_time': processing_time
                }
                
                print(f"    SNRæå‡: {snr_improvement:.1f}dB, æ—¶é—´: {processing_time:.3f}s")
                
            except Exception as e:
                print(f"    âŒ å¤±è´¥: {e}")
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        self._generate_comparison_report(results, performance, output_dir)
        
        return results, performance
    
    def _generate_comparison_report(self, results, performance, output_dir=None):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        print("\nğŸ“Š æ»¤æ³¢æ–¹æ³•å¯¹æ¯”ç»“æœ:")
        print("-" * 80)
        print(f"{'æ–¹æ³•åç§°':<20} {'SNRæå‡(dB)':<12} {'å¤„ç†æ—¶é—´(s)':<12} {'æ¨èåº¦'}")
        print("-" * 80)
        
        # æ’åºæ˜¾ç¤º
        sorted_methods = sorted(performance.items(), 
                               key=lambda x: x[1]['SNR_improvement'], reverse=True)
        
        for method, metrics in sorted_methods:
            snr = metrics['SNR_improvement']
            time_cost = metrics['processing_time']
            
            # æ¨èåº¦è¯„ä¼°
            if snr > 20:
                recommendation = "â­â­â­â­â­"
            elif snr > 10:
                recommendation = "â­â­â­â­"
            elif snr > 5:
                recommendation = "â­â­â­"
            else:
                recommendation = "â­â­"
            
            print(f"{method:<20} {snr:<12.1f} {time_cost:<12.3f} {recommendation}")
        
        # æ¨èæœ€ä½³æ–¹æ³•
        if sorted_methods:
            best_method = sorted_methods[0][0]
            best_snr = sorted_methods[0][1]['SNR_improvement']
            print(f"\nğŸ† æ¨èæ–¹æ³•: {best_method} (SNRæå‡: {best_snr:.1f}dB)")


def main():
    """æ¼”ç¤ºç»Ÿä¸€æ»¤æ³¢å·¥å…·åŒ…çš„ä½¿ç”¨"""
    print("ğŸš€ ç»Ÿä¸€æ»¤æ³¢å·¥å…·åŒ…æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºå·¥å…·åŒ…å®ä¾‹
    toolkit = UnifiedFilteringToolkit()
    
    # ç”Ÿæˆæµ‹è¯•ä¿¡å·
    fs = 12000
    t = np.linspace(0, 2, fs*2)
    
    # æ¨¡æ‹Ÿè½´æ‰¿æ•…éšœä¿¡å·
    signal_clean = (np.sin(2*np.pi*100*t) + 
                   0.5*np.sin(2*np.pi*200*t) + 
                   0.3*np.sin(2*np.pi*1500*t))
    
    # æ·»åŠ æ•…éšœå†²å‡»
    impulse_times = np.arange(0.1, 2, 0.1)
    for imp_time in impulse_times:
        idx = int(imp_time * fs)
        if idx < len(signal_clean):
            signal_clean[idx:idx+50] += 2 * np.exp(-np.arange(50)/10)
    
    # æ·»åŠ å™ªå£°
    noise = 0.3 * np.random.randn(len(signal_clean))
    signal_noisy = signal_clean + noise
    
    print(f"\nğŸµ æµ‹è¯•ä¿¡å·:")
    print(f"é‡‡æ ·é¢‘ç‡: {fs} Hz")
    print(f"ä¿¡å·é•¿åº¦: {len(signal_noisy)} ç‚¹")
    
    # æµ‹è¯•ä¸åŒæ»¤æ³¢æ–¹æ³•
    print(f"\nğŸ§ª æµ‹è¯•å„ç§æ»¤æ³¢æ–¹æ³•:")
    
    # 1. è‡ªåŠ¨é€‰æ‹©
    print(f"\n1ï¸âƒ£ è‡ªåŠ¨é€‰æ‹©æ–¹æ³•:")
    filtered_auto = toolkit.filter(signal_noisy, fs, method='auto')
    
    # 2. å¿«é€Ÿæ»¤æ³¢
    print(f"\n2ï¸âƒ£ å¿«é€Ÿæ»¤æ³¢:")
    filtered_fast = toolkit.filter(signal_noisy, fs, method='fast')
    
    # 3. é«˜è´¨é‡æ»¤æ³¢
    print(f"\n3ï¸âƒ£ é«˜è´¨é‡æ»¤æ³¢:")
    filtered_quality = toolkit.filter(signal_noisy, fs, method='quality')
    
    # 4. æ–¹æ³•å¯¹æ¯”
    print(f"\n4ï¸âƒ£ æ–¹æ³•å¯¹æ¯”:")
    results, performance = toolkit.compare_methods(
        signal_noisy, fs, 
        output_dir="/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/filtering_comparison"
    )
    
    print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    main()
