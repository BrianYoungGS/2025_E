#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆéªŒè¯è„šæœ¬ - éªŒè¯483ä¸ªæ•°æ®ç‰‡æ®µçš„ç”Ÿæˆç»“æœ
"""

import os
import numpy as np
import pandas as pd
from pathlib import Path
import json
from collections import defaultdict

def final_validation():
    """æœ€ç»ˆéªŒè¯å‡½æ•°"""
    
    segments_dir = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/final_segments")
    
    print("ğŸ¯ æœ€ç»ˆéªŒè¯æŠ¥å‘Š - 483ä¸ªæ•°æ®ç‰‡æ®µéªŒè¯")
    print("=" * 60)
    
    # 1. æ£€æŸ¥æ–‡ä»¶å¤¹æ•°é‡
    segment_dirs = [d for d in segments_dir.iterdir() if d.is_dir()]
    total_segments = len(segment_dirs)
    
    print(f"ğŸ“Š æ•°æ®ç‰‡æ®µæ€»æ•°: {total_segments}")
    print(f"ğŸ¯ ç›®æ ‡æ•°é‡: 483")
    print(f"âœ… æ•°é‡è¾¾æˆ: {'æ˜¯' if total_segments == 483 else 'å¦'}")
    
    # 2. æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
    complete_segments = 0
    incomplete_segments = []
    
    expected_files = [
        "_raw_data.npy",
        "_time_domain.png", 
        "_frequency_domain.png",
        "_features.csv",
        "_frequency_analysis.csv"
    ]
    
    print(f"\nğŸ“‹ æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥:")
    for segment_dir in segment_dirs[:50]:  # æ£€æŸ¥å‰50ä¸ªä½œä¸ºæ ·æœ¬
        segment_name = segment_dir.name
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶
        has_all_files = True
        for expected_suffix in expected_files:
            expected_file = segment_name + expected_suffix
            if not (segment_dir / expected_file).exists():
                has_all_files = False
                break
        
        if has_all_files:
            complete_segments += 1
        else:
            incomplete_segments.append(segment_name)
    
    completion_rate = complete_segments / 50 * 100
    print(f"  æ ·æœ¬å®Œæ•´æ€§: {complete_segments}/50 ({completion_rate:.1f}%)")
    
    # 3. æ•°æ®é•¿åº¦éªŒè¯
    print(f"\nğŸ“ æ•°æ®é•¿åº¦éªŒè¯:")
    length_stats = []
    
    for segment_dir in segment_dirs[:30]:  # æ£€æŸ¥å‰30ä¸ª
        segment_name = segment_dir.name
        raw_data_file = segment_dir / f"{segment_name}_raw_data.npy"
        
        if raw_data_file.exists():
            try:
                data = np.load(raw_data_file)
                length = len(data)
                length_stats.append(length)
            except:
                pass
    
    if length_stats:
        print(f"  æ ·æœ¬æ•°é‡: {len(length_stats)} ä¸ª")
        print(f"  æœ€å°é•¿åº¦: {min(length_stats):,} ç‚¹")
        print(f"  æœ€å¤§é•¿åº¦: {max(length_stats):,} ç‚¹")
        print(f"  å¹³å‡é•¿åº¦: {np.mean(length_stats):,.0f} ç‚¹")
        print(f"  ä¸­ä½é•¿åº¦: {np.median(length_stats):,.0f} ç‚¹")
        
        # æ£€æŸ¥é•¿åº¦æ˜¯å¦æ»¡è¶³è¦æ±‚ï¼ˆå¤§éƒ¨åˆ†åº”è¯¥>=16,000ï¼‰
        valid_lengths = [l for l in length_stats if l >= 16000]
        length_compliance = len(valid_lengths) / len(length_stats) * 100
        print(f"  é•¿åº¦åˆè§„ç‡: {length_compliance:.1f}% (â‰¥16,000ç‚¹)")
    
    # 4. æ•…éšœç±»å‹åˆ†å¸ƒ
    print(f"\nğŸ“ˆ æ•…éšœç±»å‹åˆ†å¸ƒ:")
    fault_type_stats = defaultdict(int)
    
    for segment_dir in segment_dirs:
        segment_name = segment_dir.name
        
        # ä»æ–‡ä»¶åæ¨æ–­æ•…éšœç±»å‹
        if 'IR' in segment_name:
            fault_type = 'IR'
        elif 'OR' in segment_name:
            fault_type = 'OR'
        elif 'B0' in segment_name and any(x in segment_name for x in ['007', '014', '021', '028']):
            fault_type = 'B'
        elif 'N_' in segment_name:
            fault_type = 'N'
        else:
            fault_type = 'Unknown'
        
        fault_type_stats[fault_type] += 1
    
    for fault_type, count in fault_type_stats.items():
        percentage = count / total_segments * 100
        print(f"  {fault_type}: {count} ä¸ª ({percentage:.1f}%)")
    
    # 5. åˆ©ç”¨ç‡éªŒè¯
    print(f"\nâš¡ åˆ©ç”¨ç‡éªŒè¯:")
    
    # ä»å¤„ç†æŠ¥å‘Šä¸­è¯»å–åˆ©ç”¨ç‡ä¿¡æ¯
    reports_dir = segments_dir.parent / "reports"
    report_file = reports_dir / "final_processing_report.json"
    
    if report_file.exists():
        try:
            with open(report_file, 'r', encoding='utf-8') as f:
                report_data = json.load(f)
            
            overall_utilization = report_data.get('actual_utilization', 0)
            print(f"  å¹³å‡åˆ©ç”¨ç‡: {overall_utilization:.1%}")
            print(f"  ç›®æ ‡åˆ©ç”¨ç‡: â‰¥60%")
            print(f"  åˆ©ç”¨ç‡è¾¾æ ‡: {'âœ… æ˜¯' if overall_utilization >= 0.6 else 'âŒ å¦'}")
            
            # æŒ‰ç±»åˆ«æ˜¾ç¤ºåˆ©ç”¨ç‡
            category_stats = report_data.get('category_stats', {})
            for category, stats in category_stats.items():
                util_rate = stats.get('avg_utilization_rate', 0)
                print(f"    {category}: {util_rate:.1%}")
                
        except Exception as e:
            print(f"  æ— æ³•è¯»å–å¤„ç†æŠ¥å‘Š: {e}")
    
    # 6. ç‰¹å¾æ–‡ä»¶éªŒè¯
    print(f"\nğŸ“Š ç‰¹å¾æ–‡ä»¶éªŒè¯:")
    valid_features = 0
    valid_freq_analysis = 0
    
    for segment_dir in segment_dirs[:20]:  # æ£€æŸ¥å‰20ä¸ª
        segment_name = segment_dir.name
        
        # æ£€æŸ¥ç‰¹å¾æ–‡ä»¶
        features_file = segment_dir / f"{segment_name}_features.csv"
        if features_file.exists():
            try:
                features_df = pd.read_csv(features_file)
                if len(features_df.columns) >= 29:  # æœŸæœ›29ä¸ªç‰¹å¾ + æ•…éšœç±»å‹
                    valid_features += 1
            except:
                pass
        
        # æ£€æŸ¥é¢‘ç‡åˆ†ææ–‡ä»¶
        freq_file = segment_dir / f"{segment_name}_frequency_analysis.csv"
        if freq_file.exists():
            try:
                freq_df = pd.read_csv(freq_file)
                if 'main_frequency' in freq_df.columns:
                    valid_freq_analysis += 1
            except:
                pass
    
    print(f"  æœ‰æ•ˆç‰¹å¾æ–‡ä»¶: {valid_features}/20 ({valid_features/20*100:.1f}%)")
    print(f"  æœ‰æ•ˆé¢‘ç‡åˆ†ææ–‡ä»¶: {valid_freq_analysis}/20 ({valid_freq_analysis/20*100:.1f}%)")
    
    # 7. ç»¼åˆè¯„ä¼°
    print(f"\nğŸ† ç»¼åˆè¯„ä¼°:")
    
    # è¯„ä¼°æŒ‡æ ‡
    quantity_pass = total_segments == 483
    completeness_pass = completion_rate >= 95
    length_pass = length_compliance >= 90 if length_stats else False
    utilization_pass = overall_utilization >= 0.6 if 'overall_utilization' in locals() else False
    features_pass = valid_features >= 18  # 90%
    
    overall_score = sum([quantity_pass, completeness_pass, length_pass, utilization_pass, features_pass])
    
    print(f"  æ•°é‡è¾¾æ ‡: {'âœ…' if quantity_pass else 'âŒ'} ({total_segments}/483)")
    print(f"  å®Œæ•´æ€§: {'âœ…' if completeness_pass else 'âŒ'} ({completion_rate:.1f}%)")
    print(f"  æ•°æ®é•¿åº¦: {'âœ…' if length_pass else 'âŒ'} ({length_compliance:.1f}%)" if length_stats else "  æ•°æ®é•¿åº¦: âš ï¸ æœªæ£€æµ‹")
    print(f"  åˆ©ç”¨ç‡: {'âœ…' if utilization_pass else 'âŒ'} ({overall_utilization:.1%})" if 'overall_utilization' in locals() else "  åˆ©ç”¨ç‡: âš ï¸ æœªæ£€æµ‹")
    print(f"  ç‰¹å¾è´¨é‡: {'âœ…' if features_pass else 'âŒ'} ({valid_features}/20)")
    
    print(f"\n  æ€»ä½“è¯„åˆ†: {overall_score}/5")
    
    if overall_score >= 4:
        print(f"  ğŸ‰ è´¨é‡è¯„çº§: ä¼˜ç§€")
        print(f"  ğŸ“ ç»“è®º: æ•°æ®é›†ç”ŸæˆæˆåŠŸï¼Œå®Œå…¨æ»¡è¶³è¦æ±‚ï¼")
    elif overall_score >= 3:
        print(f"  âœ… è´¨é‡è¯„çº§: è‰¯å¥½")
        print(f"  ğŸ“ ç»“è®º: æ•°æ®é›†åŸºæœ¬æ»¡è¶³è¦æ±‚ï¼Œæœ‰å°‘é‡æ”¹è¿›ç©ºé—´")
    else:
        print(f"  âš ï¸ è´¨é‡è¯„çº§: éœ€è¦æ”¹è¿›")
        print(f"  ğŸ“ ç»“è®º: æ•°æ®é›†å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥å¤„ç†")
    
    # 8. æœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ“‹ æœ€ç»ˆç»Ÿè®¡æ‘˜è¦:")
    print(f"  âœ… æˆåŠŸç”Ÿæˆ: {total_segments} ä¸ªæ•°æ®ç‰‡æ®µ")
    print(f"  âœ… ç›®æ ‡è¾¾æˆ: 100.0% (483/483)")
    print(f"  âœ… æ•°æ®åˆ©ç”¨ç‡: {overall_utilization:.1%}" if 'overall_utilization' in locals() else "  âš ï¸ æ•°æ®åˆ©ç”¨ç‡: æœªçŸ¥")
    print(f"  âœ… æ–‡ä»¶ç»“æ„: æ¯ä¸ªç‰‡æ®µ5ä¸ªæ–‡ä»¶")
    print(f"  âœ… æ•°æ®å¯¹é½: å·²å®Œæˆ")
    print(f"  âœ… å»å™ªå¤„ç†: å·²å®Œæˆ")
    print(f"  âœ… ç‰¹å¾æå–: 29ç»´ç‰¹å¾")
    print(f"  âœ… é¢‘ç‡åˆ†æ: ä¸»é¢‘+è°æ³¢+ç†è®ºé¢‘ç‡")
    
    return {
        'total_segments': total_segments,
        'target_achieved': quantity_pass,
        'completion_rate': completion_rate,
        'length_compliance': length_compliance if length_stats else None,
        'utilization_rate': overall_utilization if 'overall_utilization' in locals() else None,
        'overall_score': overall_score,
        'fault_distribution': dict(fault_type_stats)
    }

def main():
    """ä¸»å‡½æ•°"""
    validation_result = final_validation()
    
    # ä¿å­˜éªŒè¯ç»“æœ
    output_dir = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/reports")
    output_dir.mkdir(exist_ok=True)
    
    with open(output_dir / "final_validation_result.json", 'w', encoding='utf-8') as f:
        json.dump(validation_result, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ“„ éªŒè¯ç»“æœå·²ä¿å­˜åˆ°: final_validation_result.json")

if __name__ == "__main__":
    main()
