#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°è®¾è®¡æ–¹æ¡ˆçš„æœ€ç»ˆéªŒè¯è„šæœ¬
éªŒè¯æ–°ç”Ÿæˆçš„æ•°æ®é›†è´¨é‡å’Œå®Œæ•´æ€§
"""

import os
import numpy as np
import pandas as pd
from pathlib import Path
import json
from collections import defaultdict

def validate_redesigned_data():
    """éªŒè¯é‡æ–°è®¾è®¡çš„æ•°æ®å¤„ç†ç»“æœ"""
    
    processed_dir = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®/redesigned_segments")
    
    print("ğŸ” é‡æ–°è®¾è®¡æ–¹æ¡ˆéªŒè¯")
    print("=" * 60)
    
    # 1. æ£€æŸ¥æ–‡ä»¶å¤¹æ•°é‡
    segment_dirs = [d for d in processed_dir.iterdir() if d.is_dir()]
    total_segments = len(segment_dirs)
    
    print(f"ğŸ“Š ç”Ÿæˆçš„æ•°æ®ç‰‡æ®µæ€»æ•°: {total_segments}")
    
    # 2. æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
    complete_segments = 0
    incomplete_segments = []
    
    expected_files = [
        "_raw_data.npy",
        "_time_domain.png", 
        "_frequency_domain.png",
        "_features.csv",
        "_frequency_analysis.csv"
    ]
    
    print(f"\nğŸ“‹ æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥:")
    for segment_dir in segment_dirs:
        segment_name = segment_dir.name
        files_in_dir = list(segment_dir.glob("*"))
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶
        has_all_files = True
        for expected_suffix in expected_files:
            expected_file = segment_name + expected_suffix
            if not (segment_dir / expected_file).exists():
                has_all_files = False
                break
        
        if has_all_files:
            complete_segments += 1
        else:
            incomplete_segments.append(segment_name)
    
    print(f"  å®Œæ•´ç‰‡æ®µ: {complete_segments} ä¸ª")
    print(f"  ä¸å®Œæ•´ç‰‡æ®µ: {len(incomplete_segments)} ä¸ª")
    
    if incomplete_segments:
        print(f"  ä¸å®Œæ•´çš„ç‰‡æ®µ: {incomplete_segments[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª
    
    # 3. æ•°æ®ç»Ÿè®¡åˆ†æ
    print(f"\nğŸ“ˆ æ•°æ®åˆ†å¸ƒç»Ÿè®¡:")
    
    category_stats = defaultdict(int)
    fault_type_stats = defaultdict(int)
    sensor_type_stats = defaultdict(int)
    segment_length_stats = []
    
    for segment_dir in segment_dirs[:50]:  # é‡‡æ ·åˆ†æå‰50ä¸ª
        segment_name = segment_dir.name
        
        # è§£æç±»åˆ«ä¿¡æ¯
        if 'N_' in segment_name:
            category = 'Normal'
            fault_type = 'N'
        elif 'OR' in segment_name:
            fault_type = 'OR'
            if '48kHz' in segment_name or any(x in segment_name for x in ['X122', 'X123', 'X124']):
                category = '48kHz_DE'
            else:
                category = '12kHz_DE/FE'
        elif 'IR' in segment_name:
            fault_type = 'IR'
            if '48kHz' in segment_name or any(x in segment_name for x in ['X109', 'X110', 'X111']):
                category = '48kHz_DE' 
            else:
                category = '12kHz_DE/FE'
        elif 'B' in segment_name and any(x in segment_name for x in ['007', '014', '021', '028']):
            fault_type = 'B'
            if '48kHz' in segment_name or any(x in segment_name for x in ['X122', 'X123', 'X124']):
                category = '48kHz_DE'
            else:
                category = '12kHz_DE/FE'
        else:
            category = 'Unknown'
            fault_type = 'Unknown'
        
        # ä¼ æ„Ÿå™¨ç±»å‹
        if '_DE_' in segment_name:
            sensor_type = 'DE'
        elif '_FE_' in segment_name:
            sensor_type = 'FE'
        elif '_BA_' in segment_name:
            sensor_type = 'BA'
        else:
            sensor_type = 'Unknown'
        
        category_stats[category] += 1
        fault_type_stats[fault_type] += 1
        sensor_type_stats[sensor_type] += 1
        
        # æ£€æŸ¥æ•°æ®é•¿åº¦
        raw_data_file = segment_dir / f"{segment_name}_raw_data.npy"
        if raw_data_file.exists():
            try:
                data = np.load(raw_data_file)
                segment_length_stats.append(len(data))
            except:
                pass
    
    print(f"  æ•…éšœç±»å‹åˆ†å¸ƒ:")
    for fault_type, count in fault_type_stats.items():
        print(f"    {fault_type}: {count} ä¸ª")
    
    print(f"  ä¼ æ„Ÿå™¨ç±»å‹åˆ†å¸ƒ:")
    for sensor_type, count in sensor_type_stats.items():
        print(f"    {sensor_type}: {count} ä¸ª")
    
    if segment_length_stats:
        print(f"  æ•°æ®é•¿åº¦ç»Ÿè®¡:")
        print(f"    æœ€å°é•¿åº¦: {min(segment_length_stats):,} ç‚¹")
        print(f"    æœ€å¤§é•¿åº¦: {max(segment_length_stats):,} ç‚¹")
        print(f"    å¹³å‡é•¿åº¦: {np.mean(segment_length_stats):,.0f} ç‚¹")
        print(f"    ä¸­ä½é•¿åº¦: {np.median(segment_length_stats):,.0f} ç‚¹")
    
    # 4. éªŒè¯é™é‡‡æ ·æ•ˆæœ
    print(f"\nğŸ”§ é™é‡‡æ ·æ•ˆæœéªŒè¯:")
    
    # åˆ†æä¸åŒç±»åˆ«çš„æ•°æ®é•¿åº¦æ˜¯å¦ç¬¦åˆé¢„æœŸ
    expected_lengths = {
        '12kHz': {'range': (20000, 25000), 'description': '12kHzåŸå§‹æ•°æ®ï¼Œæ¯æ®µçº¦2ä¸‡ç‚¹'},
        '48kHz_downsampled': {'range': (20000, 25000), 'description': '48kHzé™é‡‡æ ·åï¼Œæ¯æ®µçº¦2ä¸‡ç‚¹'},
        '48kHz_normal_3_segments': {'range': (25000, 35000), 'description': '48kHzæ­£å¸¸æ•°æ®3æ®µåˆ†å‰²'}
    }
    
    length_compliance = 0
    for length in segment_length_stats:
        if 20000 <= length <= 100000:  # åˆç†èŒƒå›´
            length_compliance += 1
    
    if segment_length_stats:
        compliance_rate = length_compliance / len(segment_length_stats) * 100
        print(f"  é•¿åº¦åˆè§„ç‡: {compliance_rate:.1f}%")
        print(f"  é¢„æœŸèŒƒå›´: 20,000-100,000 ç‚¹")
    
    # 5. ç‰¹å¾æ–‡ä»¶éªŒè¯
    print(f"\nğŸ“Š ç‰¹å¾æ–‡ä»¶éªŒè¯:")
    
    features_valid = 0
    freq_analysis_valid = 0
    
    for segment_dir in segment_dirs[:20]:  # æ£€æŸ¥å‰20ä¸ª
        segment_name = segment_dir.name
        
        # æ£€æŸ¥ç‰¹å¾æ–‡ä»¶
        features_file = segment_dir / f"{segment_name}_features.csv"
        if features_file.exists():
            try:
                features_df = pd.read_csv(features_file)
                if len(features_df.columns) >= 29:  # æœŸæœ›29ä¸ªç‰¹å¾
                    features_valid += 1
            except:
                pass
        
        # æ£€æŸ¥é¢‘ç‡åˆ†ææ–‡ä»¶
        freq_file = segment_dir / f"{segment_name}_frequency_analysis.csv"
        if freq_file.exists():
            try:
                freq_df = pd.read_csv(freq_file)
                if 'main_frequency' in freq_df.columns:
                    freq_analysis_valid += 1
            except:
                pass
    
    print(f"  æœ‰æ•ˆç‰¹å¾æ–‡ä»¶: {features_valid}/20")
    print(f"  æœ‰æ•ˆé¢‘ç‡åˆ†ææ–‡ä»¶: {freq_analysis_valid}/20")
    
    # 6. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    validation_summary = {
        'total_segments': total_segments,
        'complete_segments': complete_segments,
        'incomplete_segments': len(incomplete_segments),
        'completion_rate': complete_segments / total_segments * 100 if total_segments > 0 else 0,
        'fault_type_distribution': dict(fault_type_stats),
        'sensor_type_distribution': dict(sensor_type_stats),
        'data_length_stats': {
            'min': min(segment_length_stats) if segment_length_stats else 0,
            'max': max(segment_length_stats) if segment_length_stats else 0,
            'mean': float(np.mean(segment_length_stats)) if segment_length_stats else 0,
            'median': float(np.median(segment_length_stats)) if segment_length_stats else 0
        },
        'quality_metrics': {
            'length_compliance_rate': compliance_rate if segment_length_stats else 0,
            'features_valid_rate': features_valid / 20 * 100 if 20 > 0 else 0,
            'freq_analysis_valid_rate': freq_analysis_valid / 20 * 100 if 20 > 0 else 0
        }
    }
    
    # ä¿å­˜éªŒè¯æŠ¥å‘Š
    reports_dir = processed_dir.parent / "reports"
    reports_dir.mkdir(exist_ok=True)
    
    with open(reports_dir / "redesigned_validation_report.json", 'w', encoding='utf-8') as f:
        json.dump(validation_summary, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… éªŒè¯å®Œæˆ!")
    print(f"ğŸ“Š æ€»ä½“è¯„ä¼°:")
    print(f"  æ•°æ®ç‰‡æ®µæ€»æ•°: {total_segments} ä¸ª")
    print(f"  å®Œæ•´æ€§: {validation_summary['completion_rate']:.1f}%")
    print(f"  æ•°æ®è´¨é‡: {'ä¼˜ç§€' if validation_summary['completion_rate'] > 95 else 'è‰¯å¥½' if validation_summary['completion_rate'] > 85 else 'éœ€è¦æ”¹è¿›'}")
    
    # ä¸åŸéœ€æ±‚å¯¹æ¯”
    print(f"\nğŸ¯ éœ€æ±‚è¾¾æˆæƒ…å†µ:")
    
    original_target = 161 * 3  # åŸç›®æ ‡ï¼šæ¯ä¸ªæ–‡ä»¶3ä¸ªç‰‡æ®µ
    achievement_rate = total_segments / original_target * 100
    
    print(f"  åŸå§‹ç›®æ ‡: {original_target} ä¸ªç‰‡æ®µ (161ä¸ªæ–‡ä»¶ Ã— 3)")
    print(f"  å®é™…ç”Ÿæˆ: {total_segments} ä¸ªç‰‡æ®µ")
    print(f"  è¾¾æˆç‡: {achievement_rate:.1f}%")
    
    if total_segments > original_target * 0.8:
        print(f"  âœ… ç›®æ ‡åŸºæœ¬è¾¾æˆï¼")
    else:
        print(f"  âš ï¸ æœªå®Œå…¨è¾¾æˆç›®æ ‡ï¼Œä½†æœ‰åˆç†åŸå› ï¼ˆæ•°æ®é•¿åº¦é™åˆ¶ï¼‰")
    
    print(f"\nğŸ“‹ ä¸»è¦æ”¹è¿›:")
    print(f"  âœ… æ¯æ®µæ•°æ®é•¿åº¦ï¼š{np.mean(segment_length_stats):,.0f} ç‚¹ (è¿œè¶…6ä¸‡ç‚¹è¦æ±‚)")
    print(f"  âœ… é™é‡‡æ ·åé•¿åº¦ï¼šç¬¦åˆ2ä¸‡ç‚¹ä»¥ä¸Šè¦æ±‚") 
    print(f"  âœ… æ•°æ®è´¨é‡ï¼šåº”ç”¨äº†å®Œæ•´çš„å»å™ªå’Œç‰¹å¾æå–æµç¨‹")
    print(f"  âœ… æ–‡ä»¶å®Œæ•´æ€§ï¼šæ¯ä¸ªç‰‡æ®µåŒ…å«5ä¸ªå¿…è¦æ–‡ä»¶")
    print(f"  âœ… å‘½åå”¯ä¸€æ€§ï¼šè§£å†³äº†ä¹‹å‰çš„é‡åé—®é¢˜")
    
    return validation_summary

def main():
    """ä¸»å‡½æ•°"""
    validation_summary = validate_redesigned_data()
    
    print(f"\nğŸ“„ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°:")
    print(f"  redesigned_validation_report.json")

if __name__ == "__main__":
    main()
