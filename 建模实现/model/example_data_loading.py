#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è½´æ‰¿æ•…éšœè¯Šæ–­æ•°æ®åŠ è½½ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨data_loaderå’Œdata_preprocessoræ¨¡å—
"""

import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from data_loader import BearingDataLoader, create_train_test_split
from data_preprocessor import BearingDataPreprocessor, create_preprocessing_pipeline

def main():
    """
    ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå®Œæ•´çš„æ•°æ®åŠ è½½å’Œé¢„å¤„ç†æµç¨‹
    """
    print("=" * 60)
    print("è½´æ‰¿æ•…éšœè¯Šæ–­æ•°æ®åŠ è½½å’Œé¢„å¤„ç†ç¤ºä¾‹")
    print("=" * 60)
    
    # 1. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ“ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    loader = BearingDataLoader()
    
    # 2. æ‰«ææ•°æ®é›†
    print("ğŸ” æ‰«ææ•°æ®é›†...")
    segment_info, raw_info = loader.scan_datasets()
    
    # 3. è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:")
    stats = loader.get_dataset_statistics()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # 4. ç­›é€‰è®­ç»ƒæ•°æ®
    print("\nğŸ¯ ç­›é€‰è®­ç»ƒæ•°æ®...")
    
    # æ–¹æ¡ˆ1: ä½¿ç”¨åˆ†æ®µæ•°æ®ï¼Œ12kHzï¼Œé©±åŠ¨ç«¯
    train_filter_config = {
        'fault_types': ['N', 'B', 'IR', 'OR'],  # å››ç§æ•…éšœç±»å‹
        'sampling_freqs': ['12kHz'],             # 12kHzæ•°æ®
        'sensor_types': ['DE'],                  # é©±åŠ¨ç«¯æ•°æ®
        'data_type': 'segment',                  # åˆ†æ®µæ•°æ®
        'loads': [0, 1, 2, 3]                   # æ‰€æœ‰è½½è·æ¡ä»¶
    }
    
    filtered_data = loader.filter_by_criteria(**train_filter_config)
    print(f"ç­›é€‰ç»“æœ: {len(filtered_data)} ä¸ªæ ·æœ¬")
    
    # æ˜¾ç¤ºæ¯ä¸ªæ•…éšœç±»å‹çš„æ ·æœ¬æ•°é‡
    fault_counts = {}
    for data in filtered_data:
        fault_type = data['fault_type']
        fault_counts[fault_type] = fault_counts.get(fault_type, 0) + 1
    print(f"æ•…éšœç±»å‹åˆ†å¸ƒ: {fault_counts}")
    
    # 5. åˆ›å»ºè®­ç»ƒ/æµ‹è¯•åˆ†å‰²
    print("\nğŸ“ˆ åˆ›å»ºè®­ç»ƒ/æµ‹è¯•æ•°æ®é›†...")
    
    # é™åˆ¶æ ·æœ¬æ•°é‡ä»¥å¿«é€Ÿæ¼”ç¤ºï¼ˆå®é™…ä½¿ç”¨æ—¶å¯ä»¥ç§»é™¤è¿™ä¸ªé™åˆ¶ï¼‰
    demo_data = filtered_data[:100]  # ä»…ä½¿ç”¨å‰100ä¸ªæ ·æœ¬è¿›è¡Œæ¼”ç¤º
    
    # åŠ è½½æ•°æ®
    dataset = loader.load_dataset(
        demo_data,
        include_raw=True,           # åŒ…å«åŸå§‹ä¿¡å·
        include_features=True,      # åŒ…å«ç‰¹å¾æ•°æ®
        include_freq_analysis=False, # ä¸åŒ…å«é¢‘åŸŸåˆ†æï¼ˆå¯é€‰ï¼‰
        include_images=False        # ä¸åŒ…å«å›¾åƒï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰
    )
    
    print(f"åŠ è½½çš„æ•°æ®å½¢çŠ¶:")
    print(f"  åŸå§‹ä¿¡å·: {dataset['raw_signals'].shape}")
    print(f"  ç‰¹å¾æ•°æ®: {dataset['features'].shape}")
    print(f"  æ ‡ç­¾: {dataset['labels'].shape}")
    
    # 6. æ•°æ®é¢„å¤„ç†
    print("\nğŸ”§ æ•°æ®é¢„å¤„ç†...")
    preprocessor = BearingDataPreprocessor()
    
    # åŸå§‹ä¿¡å·é¢„å¤„ç†
    if len(dataset['raw_signals']) > 0:
        # æ ‡å‡†åŒ–åŸå§‹ä¿¡å·
        normalized_signals = preprocessor.normalize_signals(
            dataset['raw_signals'], 
            method='standard'
        )
        print(f"ä¿¡å·æ ‡å‡†åŒ–å®Œæˆ: {normalized_signals.shape}")
        
        # æå–ç»¼åˆç‰¹å¾
        extracted_features = preprocessor.extract_comprehensive_features(
            normalized_signals,
            fs=12000,
            include_wavelet=False  # è·³è¿‡å°æ³¢ç‰¹å¾ä»¥åŠ å¿«æ¼”ç¤º
        )
        print(f"ç‰¹å¾æå–å®Œæˆ: {extracted_features.shape}")
        
        # ç‰¹å¾é€‰æ‹©
        if len(extracted_features) > 0:
            selected_features = preprocessor.feature_selection(
                extracted_features,
                dataset['labels'],
                method='univariate',
                k=min(30, extracted_features.shape[1])  # é€‰æ‹©30ä¸ªæœ€ä½³ç‰¹å¾
            )
            print(f"ç‰¹å¾é€‰æ‹©å®Œæˆ: {selected_features.shape}")
    
    # 7. æ•°æ®å¢å¼ºç¤ºä¾‹
    print("\nğŸš€ æ•°æ®å¢å¼ºç¤ºä¾‹...")
    if len(dataset['raw_signals']) > 0:
        # ä»…å¯¹å°‘é‡æ•°æ®è¿›è¡Œå¢å¼ºæ¼”ç¤º
        sample_signals = dataset['raw_signals'][:10]
        sample_labels = dataset['labels'][:10]
        
        augmented_signals, augmented_labels = preprocessor.augment_signals(
            sample_signals,
            sample_labels,
            methods=['noise', 'scaling'],
            noise_level=0.005
        )
        print(f"æ•°æ®å¢å¼º: {sample_signals.shape[0]} -> {augmented_signals.shape[0]} ä¸ªæ ·æœ¬")
    
    # 8. æ•°æ®å¯è§†åŒ–
    print("\nğŸ“Š æ•°æ®å¯è§†åŒ–...")
    if len(dataset['raw_signals']) > 0:
        plot_data_examples(dataset, fault_counts)
    
    # 9. è¿ç§»å­¦ä¹ æ•°æ®å‡†å¤‡
    print("\nğŸ¯ è¿ç§»å­¦ä¹ æ•°æ®å‡†å¤‡...")
    transfer_learning_demo(loader)
    
    print("\nâœ… æ•°æ®åŠ è½½å’Œé¢„å¤„ç†ç¤ºä¾‹å®Œæˆï¼")
    print("=" * 60)

def plot_data_examples(dataset, fault_counts):
    """
    ç»˜åˆ¶æ•°æ®ç¤ºä¾‹
    """
    try:
        import matplotlib.pyplot as plt
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        fig.suptitle('è½´æ‰¿æ•…éšœä¿¡å·ç¤ºä¾‹', fontsize=16)
        
        # æ•…éšœç±»å‹æ ‡ç­¾æ˜ å°„
        fault_labels = {0: 'Normal', 1: 'Ball', 2: 'Inner Race', 3: 'Outer Race'}
        
        # ä¸ºæ¯ç§æ•…éšœç±»å‹ç»˜åˆ¶ä¸€ä¸ªç¤ºä¾‹
        plot_idx = 0
        for fault_type in [0, 1, 2, 3]:  # N, B, IR, OR
            if fault_type in dataset['labels'] and plot_idx < 4:
                # æ‰¾åˆ°è¯¥æ•…éšœç±»å‹çš„ç¬¬ä¸€ä¸ªæ ·æœ¬
                indices = np.where(dataset['labels'] == fault_type)[0]
                if len(indices) > 0:
                    signal = dataset['raw_signals'][indices[0]]
                    
                    ax = axes[plot_idx // 2, plot_idx % 2]
                    ax.plot(signal[:1000])  # åªæ˜¾ç¤ºå‰1000ä¸ªç‚¹
                    ax.set_title(f'{fault_labels[fault_type]} æ•…éšœ')
                    ax.set_xlabel('é‡‡æ ·ç‚¹')
                    ax.set_ylabel('å¹…å€¼')
                    ax.grid(True, alpha=0.3)
                    
                    plot_idx += 1
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        output_dir = Path(__file__).parent.parent / "outputs"
        output_dir.mkdir(exist_ok=True)
        plt.savefig(output_dir / "bearing_signal_examples.png", dpi=150, bbox_inches='tight')
        print(f"  ä¿¡å·ç¤ºä¾‹å›¾ä¿å­˜è‡³: {output_dir / 'bearing_signal_examples.png'}")
        
        # ç»˜åˆ¶æ•…éšœç±»å‹åˆ†å¸ƒ
        plt.figure(figsize=(8, 6))
        fault_types = list(fault_counts.keys())
        fault_nums = list(fault_counts.values())
        
        plt.bar(fault_types, fault_nums, color=['green', 'orange', 'red', 'blue'])
        plt.title('æ•…éšœç±»å‹åˆ†å¸ƒ')
        plt.xlabel('æ•…éšœç±»å‹')
        plt.ylabel('æ ·æœ¬æ•°é‡')
        plt.grid(True, alpha=0.3)
        
        for i, v in enumerate(fault_nums):
            plt.text(i, v + 1, str(v), ha='center', va='bottom')
        
        plt.savefig(output_dir / "fault_distribution.png", dpi=150, bbox_inches='tight')
        print(f"  æ•…éšœåˆ†å¸ƒå›¾ä¿å­˜è‡³: {output_dir / 'fault_distribution.png'}")
        
        plt.close('all')  # å…³é—­æ‰€æœ‰å›¾å½¢
        
    except ImportError:
        print("  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
    except Exception as e:
        print(f"  å¯è§†åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

def transfer_learning_demo(loader):
    """
    è¿ç§»å­¦ä¹ æ•°æ®å‡†å¤‡æ¼”ç¤º
    """
    print("\n  ä¸ºè¿ç§»å­¦ä¹ å‡†å¤‡ä¸åŒåŸŸçš„æ•°æ®...")
    
    # æºåŸŸï¼š12kHz DEæ•°æ®
    source_data = loader.filter_by_criteria(
        fault_types=['N', 'B', 'IR', 'OR'],
        sampling_freqs=['12kHz'],
        sensor_types=['DE'],
        data_type='segment'
    )
    
    # ç›®æ ‡åŸŸï¼š12kHz FEæ•°æ®ï¼ˆæ¨¡æ‹Ÿä¸åŒä¼ æ„Ÿå™¨ä½ç½®ï¼‰
    target_data = loader.filter_by_criteria(
        fault_types=['N', 'B', 'IR', 'OR'],
        sampling_freqs=['12kHz'],
        sensor_types=['FE'],
        data_type='segment'
    )
    
    # å¦ä¸€ä¸ªç›®æ ‡åŸŸï¼š48kHzæ•°æ®ï¼ˆæ¨¡æ‹Ÿä¸åŒé‡‡æ ·é¢‘ç‡ï¼‰
    target_data_48k = loader.filter_by_criteria(
        fault_types=['N', 'B', 'IR', 'OR'],
        sampling_freqs=['48kHz'],
        data_type='raw'
    )
    
    print(f"  æºåŸŸæ•°æ® (12kHz DE): {len(source_data)} ä¸ªæ ·æœ¬")
    print(f"  ç›®æ ‡åŸŸ1 (12kHz FE): {len(target_data)} ä¸ªæ ·æœ¬")
    print(f"  ç›®æ ‡åŸŸ2 (48kHz): {len(target_data_48k)} ä¸ªæ ·æœ¬")
    
    # åˆ†æåŸŸå·®å¼‚
    analyze_domain_differences(source_data, target_data, "12kHz DE vs FE")
    
    return source_data, target_data, target_data_48k

def analyze_domain_differences(source_data, target_data, comparison_name):
    """
    åˆ†æä¸åŒåŸŸä¹‹é—´çš„æ•°æ®åˆ†å¸ƒå·®å¼‚
    """
    print(f"\n  åˆ†æåŸŸå·®å¼‚: {comparison_name}")
    
    # æ•…éšœç±»å‹åˆ†å¸ƒå¯¹æ¯”
    source_faults = {}
    target_faults = {}
    
    for data in source_data:
        fault = data['fault_type']
        source_faults[fault] = source_faults.get(fault, 0) + 1
    
    for data in target_data:
        fault = data['fault_type']
        target_faults[fault] = target_faults.get(fault, 0) + 1
    
    print(f"    æºåŸŸæ•…éšœåˆ†å¸ƒ: {source_faults}")
    print(f"    ç›®æ ‡åŸŸæ•…éšœåˆ†å¸ƒ: {target_faults}")
    
    # è½½è·åˆ†å¸ƒå¯¹æ¯”
    source_loads = {}
    target_loads = {}
    
    for data in source_data:
        load = data['load']
        source_loads[load] = source_loads.get(load, 0) + 1
    
    for data in target_data:
        load = data['load']
        target_loads[load] = target_loads.get(load, 0) + 1
    
    print(f"    æºåŸŸè½½è·åˆ†å¸ƒ: {source_loads}")
    print(f"    ç›®æ ‡åŸŸè½½è·åˆ†å¸ƒ: {target_loads}")

def create_benchmark_dataset():
    """
    åˆ›å»ºåŸºå‡†æ•°æ®é›†é…ç½®
    """
    print("\nğŸ¯ åˆ›å»ºåŸºå‡†æ•°æ®é›†é…ç½®...")
    
    # ä¸åŒçš„å®éªŒé…ç½®
    configs = {
        'config_1': {
            'name': '12kHzé©±åŠ¨ç«¯å…¨æ•°æ®',
            'filter': {
                'sampling_freqs': ['12kHz'],
                'sensor_types': ['DE'],
                'data_type': 'segment'
            }
        },
        'config_2': {
            'name': '12kHzé£æ‰‡ç«¯å…¨æ•°æ®',
            'filter': {
                'sampling_freqs': ['12kHz'],
                'sensor_types': ['FE'],
                'data_type': 'segment'
            }
        },
        'config_3': {
            'name': '48kHzå…¨æ•°æ®',
            'filter': {
                'sampling_freqs': ['48kHz'],
                'data_type': 'raw'
            }
        },
        'config_4': {
            'name': 'æ··åˆåŸŸæ•°æ®',
            'filter': {
                'data_type': 'both'
            }
        }
    }
    
    for config_name, config in configs.items():
        print(f"  {config_name}: {config['name']}")
        print(f"    ç­›é€‰æ¡ä»¶: {config['filter']}")
    
    return configs

if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    main()
    
    # åˆ›å»ºåŸºå‡†é…ç½®
    benchmark_configs = create_benchmark_dataset()
    
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ç­›é€‰æ¡ä»¶")
    print("2. å¯ä»¥ç»„åˆä½¿ç”¨ä¸åŒçš„é¢„å¤„ç†æ–¹æ³•")
    print("3. å¯¹äºè¿ç§»å­¦ä¹ ï¼Œå»ºè®®ä½¿ç”¨ä¸åŒåŸŸçš„æ•°æ®è¿›è¡Œå®éªŒ")
    print("4. ç‰¹å¾å·¥ç¨‹å¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½")
    print("5. æ•°æ®å¢å¼ºæœ‰åŠ©äºæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›")

