#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆæ•°æ®åŠ è½½å™¨æµ‹è¯•
ä¸ä¾èµ–numpyç­‰åº“ï¼Œä»…æµ‹è¯•åŸºæœ¬çš„æ–‡ä»¶æ‰«æå’Œè§£æåŠŸèƒ½
"""

import os
import re
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleBearingDataLoader:
    """
    ç®€åŒ–ç‰ˆè½´æ‰¿æ•°æ®åŠ è½½å™¨
    ä»…ç”¨äºæµ‹è¯•æ–‡ä»¶æ‰«æå’Œè§£æåŠŸèƒ½
    """
    
    def __init__(self, base_dir=None):
        if base_dir is None:
            self.base_dir = Path("/Users/gsyoung/MBP_documents/code/Matlab/ç ”ç©¶ç”Ÿæ•°å­¦å»ºæ¨¡/å»ºæ¨¡å®ç°/å¤„ç†åæ•°æ®")
        else:
            self.base_dir = Path(base_dir)
            
        self.renamed_segments_dir = self.base_dir / "renamed_segments"
        self.raw_data_dir = self.base_dir / "raw_data"
        
        # æ•…éšœç±»å‹æ˜ å°„
        self.fault_types = {
            'N': 0,   # æ­£å¸¸
            'B': 1,   # æ»šåŠ¨ä½“æ•…éšœ
            'IR': 2,  # å†…åœˆæ•…éšœ  
            'OR': 3   # å¤–åœˆæ•…éšœ
        }
        
        logger.info(f"æ•°æ®åŠ è½½å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"åˆ†æ®µæ•°æ®ç›®å½•: {self.renamed_segments_dir}")
        logger.info(f"åŸå§‹æ•°æ®ç›®å½•: {self.raw_data_dir}")
    
    def _parse_segment_filename(self, filename):
        """è§£æåˆ†æ®µæ•°æ®æ–‡ä»¶å"""
        pattern = r'^(\d+kHz)_([A-Za-z]+)_data_([NBIRO]+)(?:_(\d{4}))?_(\d+)_(\d+)$'
        match = re.match(pattern, filename)
        
        if not match:
            logger.warning(f"æ— æ³•è§£ææ–‡ä»¶å: {filename}")
            return None
        
        sampling_freq, sensor_type, fault_type, fault_size, load, segment_id = match.groups()
        
        return {
            'filename': filename,
            'sampling_freq': sampling_freq,
            'sensor_type': sensor_type,
            'fault_type': fault_type,
            'fault_size': fault_size if fault_size else '',
            'load': int(load),
            'segment_id': int(segment_id),
            'label': self.fault_types.get(fault_type, -1),
            'data_type': 'segment'
        }
    
    def _parse_raw_filename(self, filename):
        """è§£æåŸå§‹æ•°æ®æ–‡ä»¶å"""
        is_denoised = filename.endswith('_denoised')
        if is_denoised:
            filename_clean = filename[:-9]
        else:
            filename_clean = filename
        
        patterns = [
            # å¸¦RPMçš„æ•…éšœæ•°æ®: 12k_DE_B028_0_(1797rpm)
            r'^(\d+k)_([A-Za-z]+)_([BIR]+)(\d{3})_(\d+)_\(.+rpm\)$',
            # å¸¦RPMçš„å¤–åœˆæ•…éšœ: 48k_DE_OR007@3_0_(1797rpm)
            r'^(\d+k)_([A-Za-z]+)_(OR)(\d{3})@\d+_(\d+)_\(.+rpm\)$',
            # å¸¦RPMçš„æ­£å¸¸æ•°æ®: 48k_Normal_N_0_(1797rpm)
            r'^(\d+k)_([A-Za-z]+)_(N)_(\d+)_\(.+rpm\)$',
            # æ™®é€šæ•…éšœæ•°æ®: 48k_DE_B007_0
            r'^(\d+k)_([A-Za-z]+)_([BIR]+)(\d{3})_(\d+)$',
            # æ™®é€šå¤–åœˆæ•…éšœ: 48k_DE_OR007@3_0  
            r'^(\d+k)_([A-Za-z]+)_(OR)(\d{3})@\d+_(\d+)$',
            # æ™®é€šæ­£å¸¸æ•°æ®: 48k_Normal_N_0
            r'^(\d+k)_([A-Za-z]+)_(N)_(\d+)$'
        ]
        
        for pattern in patterns:
            match = re.match(pattern, filename_clean)
            if match:
                groups = match.groups()
                
                if len(groups) == 5:
                    sampling_freq, sensor_type, fault_type, fault_info, load = groups
                    if fault_type in ['B', 'IR', 'OR']:
                        fault_size = fault_info
                    else:  # fault_type == 'N'
                        fault_size = ''
                        load = fault_info
                elif len(groups) == 4:
                    sampling_freq, sensor_type, fault_type, load = groups
                    fault_size = ''
                else:
                    continue
                
                return {
                    'filename': filename,
                    'sampling_freq': sampling_freq + 'Hz',
                    'sensor_type': sensor_type,
                    'fault_type': fault_type,
                    'fault_size': fault_size,
                    'load': int(load),
                    'is_denoised': is_denoised,
                    'label': self.fault_types.get(fault_type, -1),
                    'data_type': 'raw'
                }
        
        logger.warning(f"æ— æ³•è§£æåŸå§‹æ•°æ®æ–‡ä»¶å: {filename}")
        return None
    
    def scan_datasets(self):
        """æ‰«ææ•°æ®é›†"""
        logger.info("å¼€å§‹æ‰«ææ•°æ®é›†...")
        
        segment_info = []
        if self.renamed_segments_dir.exists():
            for folder in self.renamed_segments_dir.iterdir():
                if folder.is_dir():
                    info = self._parse_segment_filename(folder.name)
                    if info:
                        info['folder_path'] = folder
                        segment_info.append(info)
        
        raw_info = []
        if self.raw_data_dir.exists():
            for folder in self.raw_data_dir.iterdir():
                if folder.is_dir():
                    info = self._parse_raw_filename(folder.name)
                    if info:
                        info['folder_path'] = folder
                        raw_info.append(info)
        
        logger.info(f"æ‰«æå®Œæˆ: åˆ†æ®µæ•°æ® {len(segment_info)} ä¸ª, åŸå§‹æ•°æ® {len(raw_info)} ä¸ª")
        return segment_info, raw_info
    
    def filter_by_criteria(self, segment_info, raw_info, **kwargs):
        """æ ¹æ®æ¡ä»¶ç­›é€‰æ•°æ®"""
        fault_types = kwargs.get('fault_types')
        sampling_freqs = kwargs.get('sampling_freqs')
        sensor_types = kwargs.get('sensor_types')
        loads = kwargs.get('loads')
        data_type = kwargs.get('data_type', 'both')
        
        filtered_data = []
        
        if data_type in ['segment', 'both']:
            for info in segment_info:
                if fault_types and info['fault_type'] not in fault_types:
                    continue
                if sampling_freqs and info['sampling_freq'] not in sampling_freqs:
                    continue
                if sensor_types and info['sensor_type'] not in sensor_types:
                    continue
                if loads and info['load'] not in loads:
                    continue
                filtered_data.append(info)
        
        if data_type in ['raw', 'both']:
            for info in raw_info:
                if fault_types and info['fault_type'] not in fault_types:
                    continue
                if sampling_freqs and info['sampling_freq'] not in sampling_freqs:
                    continue
                if sensor_types and info['sensor_type'] not in sensor_types:
                    continue
                if loads and info['load'] not in loads:
                    continue
                filtered_data.append(info)
        
        logger.info(f"ç­›é€‰ç»“æœ: {len(filtered_data)} ä¸ªæ ·æœ¬ç¬¦åˆæ¡ä»¶")
        return filtered_data
    
    def get_statistics(self, segment_info, raw_info):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        all_data = segment_info + raw_info
        
        stats = {
            'total_samples': len(all_data),
            'segment_samples': len(segment_info),
            'raw_samples': len(raw_info),
            'fault_distribution': {},
            'sampling_freq_distribution': {},
            'sensor_type_distribution': {},
            'load_distribution': {}
        }
        
        for data in all_data:
            fault_type = data['fault_type']
            stats['fault_distribution'][fault_type] = stats['fault_distribution'].get(fault_type, 0) + 1
            
            freq = data['sampling_freq']
            stats['sampling_freq_distribution'][freq] = stats['sampling_freq_distribution'].get(freq, 0) + 1
            
            sensor = data['sensor_type']
            stats['sensor_type_distribution'][sensor] = stats['sensor_type_distribution'].get(sensor, 0) + 1
            
            load = data['load']
            stats['load_distribution'][load] = stats['load_distribution'].get(load, 0) + 1
        
        return stats

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½"""
    print("=" * 60)
    print("è½´æ‰¿æ•…éšœè¯Šæ–­æ•°æ®åŠ è½½æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    loader = SimpleBearingDataLoader()
    
    # æ‰«ææ•°æ®é›†
    segment_info, raw_info = loader.scan_datasets()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = loader.get_statistics(segment_info, raw_info)
    
    print("\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # æµ‹è¯•æ–‡ä»¶åè§£æ
    print("\nğŸ” æ–‡ä»¶åè§£ææµ‹è¯•:")
    test_filenames = [
        "12kHz_DE_data_B_0007_0_1",
        "12kHz_FE_data_IR_0021_2_456",
        "48kHz_Normal_data_N_0_481",
        "12kHz_DE_data_OR_0014_1_367"
    ]
    
    for filename in test_filenames:
        parsed = loader._parse_segment_filename(filename)
        if parsed:
            print(f"  âœ… {filename}")
            print(f"     -> æ•…éšœç±»å‹: {parsed['fault_type']}, é¢‘ç‡: {parsed['sampling_freq']}, ä¼ æ„Ÿå™¨: {parsed['sensor_type']}")
        else:
            print(f"  âŒ {filename} (è§£æå¤±è´¥)")
    
    # æµ‹è¯•æ•°æ®ç­›é€‰
    print("\nğŸ¯ æ•°æ®ç­›é€‰æµ‹è¯•:")
    
    filter_configs = [
        {
            'name': '12kHz DEæ•°æ®',
            'filter': {
                'sampling_freqs': ['12kHz'],
                'sensor_types': ['DE'],
                'data_type': 'segment'
            }
        },
        {
            'name': 'æ»šåŠ¨ä½“æ•…éšœæ•°æ®',
            'filter': {
                'fault_types': ['B'],
                'data_type': 'both'
            }
        },
        {
            'name': '48kHzæ•°æ®',
            'filter': {
                'sampling_freqs': ['48kHz'],
                'data_type': 'raw'
            }
        }
    ]
    
    for config in filter_configs:
        filtered = loader.filter_by_criteria(segment_info, raw_info, **config['filter'])
        print(f"  {config['name']}: {len(filtered)} ä¸ªæ ·æœ¬")
        
        # æ˜¾ç¤ºæ•…éšœç±»å‹åˆ†å¸ƒ
        fault_dist = {}
        for data in filtered:
            fault = data['fault_type']
            fault_dist[fault] = fault_dist.get(fault, 0) + 1
        print(f"    æ•…éšœåˆ†å¸ƒ: {fault_dist}")
    
    # æ£€æŸ¥æ–‡ä»¶å†…å®¹
    print("\nğŸ“ æ–‡ä»¶å†…å®¹æ£€æŸ¥:")
    if segment_info:
        sample_folder = segment_info[0]['folder_path']
        print(f"  æ£€æŸ¥æ ·æœ¬æ–‡ä»¶å¤¹: {sample_folder.name}")
        
        expected_files = [
            f"{sample_folder.name}_features.csv",
            f"{sample_folder.name}_frequency_analysis.csv",
            f"{sample_folder.name}_frequency_domain.png",
            f"{sample_folder.name}_raw_data.npy",
            f"{sample_folder.name}_time_domain.png"
        ]
        
        for expected_file in expected_files:
            file_path = sample_folder / expected_file
            if file_path.exists():
                file_size = file_path.stat().st_size
                print(f"    âœ… {expected_file} ({file_size} bytes)")
            else:
                print(f"    âŒ {expected_file} (ç¼ºå¤±)")
    
    print("\nâœ… æ•°æ®åŠ è½½æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    
    return stats

if __name__ == "__main__":
    test_data_loading()
